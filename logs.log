2023-08-08 20:52:26,708:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-08 20:52:26,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-08 20:52:26,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-08 20:52:26,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-08 20:52:57,899:INFO:PyCaret AnomalyExperiment
2023-08-08 20:52:57,899:INFO:Logging name: anomaly-default-name
2023-08-08 20:52:57,901:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-08 20:52:57,904:INFO:version 3.0.4
2023-08-08 20:52:57,905:INFO:Initializing setup()
2023-08-08 20:52:57,905:INFO:self.USI: b780
2023-08-08 20:52:57,906:INFO:self._variable_keys: {'gpu_n_jobs_param', 'exp_name_log', 'USI', 'seed', 'gpu_param', 'html_param', 'log_plots_param', 'pipeline', '_ml_usecase', 'logging_param', 'data', 'n_jobs_param', 'X', 'idx', '_available_plots', 'memory', 'exp_id'}
2023-08-08 20:52:57,906:INFO:Checking environment
2023-08-08 20:52:57,906:INFO:python_version: 3.9.13
2023-08-08 20:52:57,906:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-08 20:52:57,906:INFO:machine: AMD64
2023-08-08 20:52:57,907:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-08 20:52:57,923:INFO:Memory: svmem(total=7480111104, available=1077575680, percent=85.6, used=6402535424, free=1077575680)
2023-08-08 20:52:57,924:INFO:Physical Core: 4
2023-08-08 20:52:57,924:INFO:Logical Core: 4
2023-08-08 20:52:57,924:INFO:Checking libraries
2023-08-08 20:52:57,925:INFO:System:
2023-08-08 20:52:57,925:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-08 20:52:57,925:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-08 20:52:57,925:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-08 20:52:57,925:INFO:PyCaret required dependencies:
2023-08-08 20:52:58,429:INFO:                 pip: 23.1.2
2023-08-08 20:52:58,429:INFO:          setuptools: 58.1.0
2023-08-08 20:52:58,429:INFO:             pycaret: 3.0.4
2023-08-08 20:52:58,429:INFO:             IPython: 8.13.2
2023-08-08 20:52:58,429:INFO:          ipywidgets: 8.0.7
2023-08-08 20:52:58,430:INFO:                tqdm: 4.65.0
2023-08-08 20:52:58,430:INFO:               numpy: 1.23.5
2023-08-08 20:52:58,430:INFO:              pandas: 1.5.3
2023-08-08 20:52:58,430:INFO:              jinja2: 3.1.2
2023-08-08 20:52:58,430:INFO:               scipy: 1.10.1
2023-08-08 20:52:58,430:INFO:              joblib: 1.2.0
2023-08-08 20:52:58,430:INFO:             sklearn: 1.2.2
2023-08-08 20:52:58,430:INFO:                pyod: 1.1.0
2023-08-08 20:52:58,431:INFO:            imblearn: 0.11.0
2023-08-08 20:52:58,431:INFO:   category_encoders: 2.6.1
2023-08-08 20:52:58,431:INFO:            lightgbm: 4.0.0
2023-08-08 20:52:58,431:INFO:               numba: 0.57.1
2023-08-08 20:52:58,431:INFO:            requests: 2.31.0
2023-08-08 20:52:58,431:INFO:          matplotlib: 3.7.1
2023-08-08 20:52:58,432:INFO:          scikitplot: 0.3.7
2023-08-08 20:52:58,432:INFO:         yellowbrick: 1.5
2023-08-08 20:52:58,432:INFO:              plotly: 5.15.0
2023-08-08 20:52:58,432:INFO:    plotly-resampler: Not installed
2023-08-08 20:52:58,432:INFO:             kaleido: 0.2.1
2023-08-08 20:52:58,432:INFO:           schemdraw: 0.15
2023-08-08 20:52:58,432:INFO:         statsmodels: 0.14.0
2023-08-08 20:52:58,432:INFO:              sktime: 0.20.1
2023-08-08 20:52:58,432:INFO:               tbats: 1.1.3
2023-08-08 20:52:58,433:INFO:            pmdarima: 2.0.3
2023-08-08 20:52:58,433:INFO:              psutil: 5.9.5
2023-08-08 20:52:58,433:INFO:          markupsafe: 2.1.3
2023-08-08 20:52:58,433:INFO:             pickle5: Not installed
2023-08-08 20:52:58,433:INFO:         cloudpickle: 2.2.1
2023-08-08 20:52:58,437:INFO:         deprecation: 2.1.0
2023-08-08 20:52:58,438:INFO:              xxhash: 3.2.0
2023-08-08 20:52:58,438:INFO:           wurlitzer: Not installed
2023-08-08 20:52:58,438:INFO:PyCaret optional dependencies:
2023-08-08 20:52:58,557:INFO:                shap: Not installed
2023-08-08 20:52:58,558:INFO:           interpret: 0.4.2
2023-08-08 20:52:58,558:INFO:                umap: 0.5.3
2023-08-08 20:52:58,558:INFO:    pandas_profiling: Not installed
2023-08-08 20:52:58,559:INFO:  explainerdashboard: Not installed
2023-08-08 20:52:58,559:INFO:             autoviz: Not installed
2023-08-08 20:52:58,560:INFO:           fairlearn: Not installed
2023-08-08 20:52:58,560:INFO:          deepchecks: Not installed
2023-08-08 20:52:58,561:INFO:             xgboost: 1.7.6
2023-08-08 20:52:58,562:INFO:            catboost: Not installed
2023-08-08 20:52:58,562:INFO:              kmodes: Not installed
2023-08-08 20:52:58,563:INFO:             mlxtend: 0.22.0
2023-08-08 20:52:58,564:INFO:       statsforecast: Not installed
2023-08-08 20:52:58,564:INFO:        tune_sklearn: Not installed
2023-08-08 20:52:58,564:INFO:                 ray: Not installed
2023-08-08 20:52:58,564:INFO:            hyperopt: Not installed
2023-08-08 20:52:58,565:INFO:              optuna: Not installed
2023-08-08 20:52:58,566:INFO:               skopt: Not installed
2023-08-08 20:52:58,566:INFO:              mlflow: 2.4.2
2023-08-08 20:52:58,567:INFO:              gradio: Not installed
2023-08-08 20:52:58,567:INFO:             fastapi: Not installed
2023-08-08 20:52:58,571:INFO:             uvicorn: Not installed
2023-08-08 20:52:58,571:INFO:              m2cgen: Not installed
2023-08-08 20:52:58,572:INFO:           evidently: Not installed
2023-08-08 20:52:58,572:INFO:               fugue: Not installed
2023-08-08 20:52:58,572:INFO:           streamlit: 1.25.0
2023-08-08 20:52:58,573:INFO:             prophet: Not installed
2023-08-08 20:52:58,573:INFO:None
2023-08-08 20:52:58,573:INFO:Set up data.
2023-08-08 20:52:58,631:INFO:Set up index.
2023-08-08 20:52:58,632:INFO:Assigning column types.
2023-08-08 20:52:58,650:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-08 20:53:03,267:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-08 20:53:03,325:INFO:Preparing preprocessing pipeline...
2023-08-08 20:53:03,326:INFO:Set up simple imputation.
2023-08-08 20:53:03,337:INFO:Set up encoding of categorical features.
2023-08-08 20:53:03,741:INFO:Finished creating preprocessing pipeline.
2023-08-08 20:53:03,765:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-08 20:53:03,766:INFO:Creating final display dataframe.
2023-08-08 20:53:04,075:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  3852
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 18)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  b780
2023-08-08 20:53:04,077:INFO:setup() successfully completed in 12.91s...............
2023-08-08 20:53:04,077:INFO:Initializing create_model()
2023-08-08 20:53:04,078:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000215D1B88DF0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-08 20:53:04,078:INFO:Checking exceptions
2023-08-08 20:53:04,161:INFO:Importing untrained model
2023-08-08 20:53:04,164:INFO:Isolation Forest Imported successfully
2023-08-08 20:53:04,172:INFO:Fitting Model
2023-08-08 20:53:07,032:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3852, verbose=0)
2023-08-08 20:53:07,033:INFO:create_models() successfully completed......................................
2023-08-08 20:53:07,035:INFO:Uploading results into container
2023-08-08 20:53:07,036:INFO:Uploading model into container now
2023-08-08 20:53:07,036:INFO:_master_model_container: 1
2023-08-08 20:53:07,036:INFO:_display_container: 1
2023-08-08 20:53:07,037:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3852, verbose=0)
2023-08-08 20:53:07,038:INFO:create_model() successfully completed......................................
2023-08-08 20:53:09,458:INFO:Initializing plot_model()
2023-08-08 20:53:09,458:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3852, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000215D1B88DF0>, system=True)
2023-08-08 20:53:09,458:INFO:Checking exceptions
2023-08-08 20:53:26,072:INFO:Preloading libraries
2023-08-08 20:53:26,130:INFO:Copying training dataset
2023-08-08 20:53:26,130:INFO:Plot type: umap
2023-08-08 20:53:26,136:INFO:SubProcess assign_model() called ==================================
2023-08-08 20:53:26,137:INFO:Initializing assign_model()
2023-08-08 20:53:26,137:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000215D1B88DF0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3852, verbose=0), transformation=True, score=False, verbose=False)
2023-08-08 20:53:26,137:INFO:Checking exceptions
2023-08-08 20:53:26,138:INFO:Determining Trained Model
2023-08-08 20:53:26,138:INFO:Trained Model : Isolation Forest
2023-08-08 20:53:26,139:INFO:Copying data
2023-08-08 20:53:26,231:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-08 20:53:26,236:INFO:(3941, 19)
2023-08-08 20:53:26,236:INFO:assign_model() successfully completed......................................
2023-08-08 20:53:26,237:INFO:SubProcess assign_model() end ==================================
2023-08-08 20:53:26,244:INFO:Soft dependency imported: umap: 0.5.3
2023-08-08 20:53:50,827:INFO:Fitting UMAP()
2023-08-09 18:33:25,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 18:33:25,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 18:33:25,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 18:33:25,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 05:54:13,740:INFO:PyCaret AnomalyExperiment
2023-08-10 05:54:13,742:INFO:Logging name: anomaly-default-name
2023-08-10 05:54:13,742:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 05:54:13,743:INFO:version 3.0.4
2023-08-10 05:54:13,743:INFO:Initializing setup()
2023-08-10 05:54:13,743:INFO:self.USI: adcc
2023-08-10 05:54:13,743:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'logging_param', 'data', 'memory', 'seed', 'html_param', 'exp_name_log', 'gpu_param', 'USI', '_available_plots', 'log_plots_param', 'idx', 'X', 'exp_id', 'gpu_n_jobs_param', '_ml_usecase'}
2023-08-10 05:54:13,743:INFO:Checking environment
2023-08-10 05:54:13,744:INFO:python_version: 3.9.13
2023-08-10 05:54:13,744:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 05:54:13,744:INFO:machine: AMD64
2023-08-10 05:54:13,744:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 05:54:13,760:INFO:Memory: svmem(total=7480111104, available=1666736128, percent=77.7, used=5813374976, free=1666736128)
2023-08-10 05:54:13,762:INFO:Physical Core: 4
2023-08-10 05:54:13,762:INFO:Logical Core: 4
2023-08-10 05:54:13,762:INFO:Checking libraries
2023-08-10 05:54:13,763:INFO:System:
2023-08-10 05:54:13,763:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 05:54:13,763:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 05:54:13,763:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 05:54:13,764:INFO:PyCaret required dependencies:
2023-08-10 05:54:14,279:INFO:                 pip: 23.1.2
2023-08-10 05:54:14,279:INFO:          setuptools: 58.1.0
2023-08-10 05:54:14,279:INFO:             pycaret: 3.0.4
2023-08-10 05:54:14,279:INFO:             IPython: 8.13.2
2023-08-10 05:54:14,279:INFO:          ipywidgets: 8.0.7
2023-08-10 05:54:14,279:INFO:                tqdm: 4.65.0
2023-08-10 05:54:14,279:INFO:               numpy: 1.23.5
2023-08-10 05:54:14,280:INFO:              pandas: 1.5.3
2023-08-10 05:54:14,280:INFO:              jinja2: 3.1.2
2023-08-10 05:54:14,280:INFO:               scipy: 1.10.1
2023-08-10 05:54:14,280:INFO:              joblib: 1.2.0
2023-08-10 05:54:14,280:INFO:             sklearn: 1.2.2
2023-08-10 05:54:14,280:INFO:                pyod: 1.1.0
2023-08-10 05:54:14,280:INFO:            imblearn: 0.11.0
2023-08-10 05:54:14,280:INFO:   category_encoders: 2.6.1
2023-08-10 05:54:14,280:INFO:            lightgbm: 4.0.0
2023-08-10 05:54:14,280:INFO:               numba: 0.57.1
2023-08-10 05:54:14,281:INFO:            requests: 2.31.0
2023-08-10 05:54:14,281:INFO:          matplotlib: 3.7.1
2023-08-10 05:54:14,281:INFO:          scikitplot: 0.3.7
2023-08-10 05:54:14,281:INFO:         yellowbrick: 1.5
2023-08-10 05:54:14,281:INFO:              plotly: 5.15.0
2023-08-10 05:54:14,281:INFO:    plotly-resampler: Not installed
2023-08-10 05:54:14,281:INFO:             kaleido: 0.2.1
2023-08-10 05:54:14,281:INFO:           schemdraw: 0.15
2023-08-10 05:54:14,281:INFO:         statsmodels: 0.14.0
2023-08-10 05:54:14,281:INFO:              sktime: 0.20.1
2023-08-10 05:54:14,283:INFO:               tbats: 1.1.3
2023-08-10 05:54:14,283:INFO:            pmdarima: 2.0.3
2023-08-10 05:54:14,283:INFO:              psutil: 5.9.5
2023-08-10 05:54:14,283:INFO:          markupsafe: 2.1.3
2023-08-10 05:54:14,283:INFO:             pickle5: Not installed
2023-08-10 05:54:14,283:INFO:         cloudpickle: 2.2.1
2023-08-10 05:54:14,283:INFO:         deprecation: 2.1.0
2023-08-10 05:54:14,284:INFO:              xxhash: 3.2.0
2023-08-10 05:54:14,284:INFO:           wurlitzer: Not installed
2023-08-10 05:54:14,284:INFO:PyCaret optional dependencies:
2023-08-10 05:54:14,375:INFO:                shap: Not installed
2023-08-10 05:54:14,375:INFO:           interpret: 0.4.2
2023-08-10 05:54:14,376:INFO:                umap: 0.5.3
2023-08-10 05:54:14,376:INFO:    pandas_profiling: Not installed
2023-08-10 05:54:14,376:INFO:  explainerdashboard: Not installed
2023-08-10 05:54:14,376:INFO:             autoviz: Not installed
2023-08-10 05:54:14,376:INFO:           fairlearn: Not installed
2023-08-10 05:54:14,376:INFO:          deepchecks: Not installed
2023-08-10 05:54:14,377:INFO:             xgboost: 1.7.6
2023-08-10 05:54:14,377:INFO:            catboost: Not installed
2023-08-10 05:54:14,377:INFO:              kmodes: Not installed
2023-08-10 05:54:14,377:INFO:             mlxtend: 0.22.0
2023-08-10 05:54:14,377:INFO:       statsforecast: Not installed
2023-08-10 05:54:14,378:INFO:        tune_sklearn: Not installed
2023-08-10 05:54:14,378:INFO:                 ray: Not installed
2023-08-10 05:54:14,378:INFO:            hyperopt: Not installed
2023-08-10 05:54:14,378:INFO:              optuna: Not installed
2023-08-10 05:54:14,378:INFO:               skopt: Not installed
2023-08-10 05:54:14,378:INFO:              mlflow: 2.4.2
2023-08-10 05:54:14,378:INFO:              gradio: Not installed
2023-08-10 05:54:14,379:INFO:             fastapi: Not installed
2023-08-10 05:54:14,379:INFO:             uvicorn: Not installed
2023-08-10 05:54:14,379:INFO:              m2cgen: Not installed
2023-08-10 05:54:14,379:INFO:           evidently: Not installed
2023-08-10 05:54:14,379:INFO:               fugue: Not installed
2023-08-10 05:54:14,380:INFO:           streamlit: 1.25.0
2023-08-10 05:54:14,380:INFO:             prophet: Not installed
2023-08-10 05:54:14,380:INFO:None
2023-08-10 05:54:14,380:INFO:Set up data.
2023-08-10 05:54:14,431:INFO:Set up index.
2023-08-10 05:54:14,432:INFO:Assigning column types.
2023-08-10 05:54:14,449:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 05:54:20,096:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 05:54:20,113:INFO:Preparing preprocessing pipeline...
2023-08-10 05:54:20,113:INFO:Set up simple imputation.
2023-08-10 05:54:20,127:INFO:Set up encoding of categorical features.
2023-08-10 05:54:20,602:INFO:Finished creating preprocessing pipeline.
2023-08-10 05:54:20,633:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 05:54:20,634:INFO:Creating final display dataframe.
2023-08-10 05:54:21,075:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  2400
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 18)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  adcc
2023-08-10 05:54:21,078:INFO:setup() successfully completed in 13.4s...............
2023-08-10 05:54:21,079:INFO:Initializing create_model()
2023-08-10 05:54:21,079:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245FA2704C0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 05:54:21,079:INFO:Checking exceptions
2023-08-10 05:54:21,184:INFO:Importing untrained model
2023-08-10 05:54:21,192:INFO:Isolation Forest Imported successfully
2023-08-10 05:54:21,197:INFO:Fitting Model
2023-08-10 05:54:23,426:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2400, verbose=0)
2023-08-10 05:54:23,427:INFO:create_models() successfully completed......................................
2023-08-10 05:54:23,427:INFO:Uploading results into container
2023-08-10 05:54:23,427:INFO:Uploading model into container now
2023-08-10 05:54:23,427:INFO:_master_model_container: 1
2023-08-10 05:54:23,427:INFO:_display_container: 1
2023-08-10 05:54:23,428:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2400, verbose=0)
2023-08-10 05:54:23,428:INFO:create_model() successfully completed......................................
2023-08-10 05:54:25,009:INFO:Initializing plot_model()
2023-08-10 05:54:25,009:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2400, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245FA2704C0>, system=True)
2023-08-10 05:54:25,010:INFO:Checking exceptions
2023-08-10 05:54:41,313:INFO:Preloading libraries
2023-08-10 05:54:41,364:INFO:Copying training dataset
2023-08-10 05:54:41,364:INFO:Plot type: umap
2023-08-10 05:54:41,367:INFO:SubProcess assign_model() called ==================================
2023-08-10 05:54:41,371:INFO:Initializing assign_model()
2023-08-10 05:54:41,372:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245FA2704C0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2400, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 05:54:41,372:INFO:Checking exceptions
2023-08-10 05:54:41,372:INFO:Determining Trained Model
2023-08-10 05:54:41,373:INFO:Trained Model : Isolation Forest
2023-08-10 05:54:41,373:INFO:Copying data
2023-08-10 05:54:41,416:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 05:54:41,418:INFO:(3941, 19)
2023-08-10 05:54:41,418:INFO:assign_model() successfully completed......................................
2023-08-10 05:54:41,420:INFO:SubProcess assign_model() end ==================================
2023-08-10 05:54:41,427:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 05:55:02,660:INFO:Fitting UMAP()
2023-08-10 05:55:59,155:INFO:Rendering Visual
2023-08-10 05:56:05,729:INFO:Visual Rendered Successfully
2023-08-10 05:56:06,219:INFO:plot_model() successfully completed......................................
2023-08-10 05:57:33,598:INFO:Initializing assign_model()
2023-08-10 05:57:33,599:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245FA2704C0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2400, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 05:57:33,599:INFO:Checking exceptions
2023-08-10 05:57:33,600:INFO:Determining Trained Model
2023-08-10 05:57:33,600:INFO:Trained Model : Isolation Forest
2023-08-10 05:57:33,601:INFO:Copying data
2023-08-10 05:57:33,606:INFO:(3941, 13)
2023-08-10 05:57:33,606:INFO:assign_model() successfully completed......................................
2023-08-10 06:03:28,560:INFO:PyCaret AnomalyExperiment
2023-08-10 06:03:28,560:INFO:Logging name: anomaly-default-name
2023-08-10 06:03:28,561:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 06:03:28,561:INFO:version 3.0.4
2023-08-10 06:03:28,561:INFO:Initializing setup()
2023-08-10 06:03:28,561:INFO:self.USI: 77fe
2023-08-10 06:03:28,562:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'logging_param', 'data', 'memory', 'seed', 'html_param', 'exp_name_log', 'gpu_param', 'USI', '_available_plots', 'log_plots_param', 'idx', 'X', 'exp_id', 'gpu_n_jobs_param', '_ml_usecase'}
2023-08-10 06:03:28,562:INFO:Checking environment
2023-08-10 06:03:28,562:INFO:python_version: 3.9.13
2023-08-10 06:03:28,562:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 06:03:28,562:INFO:machine: AMD64
2023-08-10 06:03:28,563:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 06:03:28,570:INFO:Memory: svmem(total=7480111104, available=1706041344, percent=77.2, used=5774069760, free=1706041344)
2023-08-10 06:03:28,570:INFO:Physical Core: 4
2023-08-10 06:03:28,571:INFO:Logical Core: 4
2023-08-10 06:03:28,571:INFO:Checking libraries
2023-08-10 06:03:28,571:INFO:System:
2023-08-10 06:03:28,571:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 06:03:28,571:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 06:03:28,571:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 06:03:28,572:INFO:PyCaret required dependencies:
2023-08-10 06:03:28,572:INFO:                 pip: 23.1.2
2023-08-10 06:03:28,572:INFO:          setuptools: 58.1.0
2023-08-10 06:03:28,572:INFO:             pycaret: 3.0.4
2023-08-10 06:03:28,572:INFO:             IPython: 8.13.2
2023-08-10 06:03:28,573:INFO:          ipywidgets: 8.0.7
2023-08-10 06:03:28,573:INFO:                tqdm: 4.65.0
2023-08-10 06:03:28,573:INFO:               numpy: 1.23.5
2023-08-10 06:03:28,573:INFO:              pandas: 1.5.3
2023-08-10 06:03:28,573:INFO:              jinja2: 3.1.2
2023-08-10 06:03:28,574:INFO:               scipy: 1.10.1
2023-08-10 06:03:28,577:INFO:              joblib: 1.2.0
2023-08-10 06:03:28,577:INFO:             sklearn: 1.2.2
2023-08-10 06:03:28,577:INFO:                pyod: 1.1.0
2023-08-10 06:03:28,577:INFO:            imblearn: 0.11.0
2023-08-10 06:03:28,578:INFO:   category_encoders: 2.6.1
2023-08-10 06:03:28,578:INFO:            lightgbm: 4.0.0
2023-08-10 06:03:28,578:INFO:               numba: 0.57.1
2023-08-10 06:03:28,578:INFO:            requests: 2.31.0
2023-08-10 06:03:28,578:INFO:          matplotlib: 3.7.1
2023-08-10 06:03:28,579:INFO:          scikitplot: 0.3.7
2023-08-10 06:03:28,579:INFO:         yellowbrick: 1.5
2023-08-10 06:03:28,579:INFO:              plotly: 5.15.0
2023-08-10 06:03:28,579:INFO:    plotly-resampler: Not installed
2023-08-10 06:03:28,579:INFO:             kaleido: 0.2.1
2023-08-10 06:03:28,579:INFO:           schemdraw: 0.15
2023-08-10 06:03:28,579:INFO:         statsmodels: 0.14.0
2023-08-10 06:03:28,579:INFO:              sktime: 0.20.1
2023-08-10 06:03:28,580:INFO:               tbats: 1.1.3
2023-08-10 06:03:28,580:INFO:            pmdarima: 2.0.3
2023-08-10 06:03:28,580:INFO:              psutil: 5.9.5
2023-08-10 06:03:28,580:INFO:          markupsafe: 2.1.3
2023-08-10 06:03:28,580:INFO:             pickle5: Not installed
2023-08-10 06:03:28,580:INFO:         cloudpickle: 2.2.1
2023-08-10 06:03:28,580:INFO:         deprecation: 2.1.0
2023-08-10 06:03:28,580:INFO:              xxhash: 3.2.0
2023-08-10 06:03:28,580:INFO:           wurlitzer: Not installed
2023-08-10 06:03:28,581:INFO:PyCaret optional dependencies:
2023-08-10 06:03:28,581:INFO:                shap: Not installed
2023-08-10 06:03:28,581:INFO:           interpret: 0.4.2
2023-08-10 06:03:28,582:INFO:                umap: 0.5.3
2023-08-10 06:03:28,582:INFO:    pandas_profiling: Not installed
2023-08-10 06:03:28,582:INFO:  explainerdashboard: Not installed
2023-08-10 06:03:28,582:INFO:             autoviz: Not installed
2023-08-10 06:03:28,582:INFO:           fairlearn: Not installed
2023-08-10 06:03:28,582:INFO:          deepchecks: Not installed
2023-08-10 06:03:28,582:INFO:             xgboost: 1.7.6
2023-08-10 06:03:28,583:INFO:            catboost: Not installed
2023-08-10 06:03:28,583:INFO:              kmodes: Not installed
2023-08-10 06:03:28,583:INFO:             mlxtend: 0.22.0
2023-08-10 06:03:28,583:INFO:       statsforecast: Not installed
2023-08-10 06:03:28,583:INFO:        tune_sklearn: Not installed
2023-08-10 06:03:28,583:INFO:                 ray: Not installed
2023-08-10 06:03:28,583:INFO:            hyperopt: Not installed
2023-08-10 06:03:28,583:INFO:              optuna: Not installed
2023-08-10 06:03:28,583:INFO:               skopt: Not installed
2023-08-10 06:03:28,584:INFO:              mlflow: 2.4.2
2023-08-10 06:03:28,584:INFO:              gradio: Not installed
2023-08-10 06:03:28,584:INFO:             fastapi: Not installed
2023-08-10 06:03:28,584:INFO:             uvicorn: Not installed
2023-08-10 06:03:28,584:INFO:              m2cgen: Not installed
2023-08-10 06:03:28,584:INFO:           evidently: Not installed
2023-08-10 06:03:28,584:INFO:               fugue: Not installed
2023-08-10 06:03:28,584:INFO:           streamlit: 1.25.0
2023-08-10 06:03:28,585:INFO:             prophet: Not installed
2023-08-10 06:03:28,585:INFO:None
2023-08-10 06:03:28,585:INFO:Set up data.
2023-08-10 06:03:28,619:INFO:Set up index.
2023-08-10 06:03:28,620:INFO:Assigning column types.
2023-08-10 06:03:28,632:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 06:03:28,634:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 06:03:28,642:INFO:Preparing preprocessing pipeline...
2023-08-10 06:03:28,642:INFO:Set up simple imputation.
2023-08-10 06:03:28,653:INFO:Set up encoding of categorical features.
2023-08-10 06:03:28,895:INFO:Finished creating preprocessing pipeline.
2023-08-10 06:03:28,919:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 06:03:28,919:INFO:Creating final display dataframe.
2023-08-10 06:03:28,972:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  8518
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 18)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  77fe
2023-08-10 06:03:28,978:INFO:setup() successfully completed in 4.8s...............
2023-08-10 06:03:31,516:INFO:Initializing create_model()
2023-08-10 06:03:31,516:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245F8A6A2E0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 06:03:31,516:INFO:Checking exceptions
2023-08-10 06:03:31,569:INFO:Importing untrained model
2023-08-10 06:03:31,571:INFO:Isolation Forest Imported successfully
2023-08-10 06:03:31,577:INFO:Fitting Model
2023-08-10 06:03:34,464:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8518, verbose=0)
2023-08-10 06:03:34,464:INFO:create_models() successfully completed......................................
2023-08-10 06:03:34,464:INFO:Uploading results into container
2023-08-10 06:03:34,464:INFO:Uploading model into container now
2023-08-10 06:03:34,465:INFO:_master_model_container: 1
2023-08-10 06:03:34,465:INFO:_display_container: 1
2023-08-10 06:03:34,466:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8518, verbose=0)
2023-08-10 06:03:34,466:INFO:create_model() successfully completed......................................
2023-08-10 06:03:37,434:INFO:Initializing plot_model()
2023-08-10 06:03:37,434:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8518, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245F8A6A2E0>, system=True)
2023-08-10 06:03:37,434:INFO:Checking exceptions
2023-08-10 06:03:48,285:INFO:Preloading libraries
2023-08-10 06:03:48,347:INFO:Copying training dataset
2023-08-10 06:03:48,347:INFO:Plot type: umap
2023-08-10 06:03:48,348:INFO:SubProcess assign_model() called ==================================
2023-08-10 06:03:48,349:INFO:Initializing assign_model()
2023-08-10 06:03:48,350:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245F8A6A2E0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8518, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 06:03:48,350:INFO:Checking exceptions
2023-08-10 06:03:48,350:INFO:Determining Trained Model
2023-08-10 06:03:48,351:INFO:Trained Model : Isolation Forest
2023-08-10 06:03:48,351:INFO:Copying data
2023-08-10 06:03:48,470:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 06:03:48,471:INFO:(3941, 19)
2023-08-10 06:03:48,471:INFO:assign_model() successfully completed......................................
2023-08-10 06:03:48,472:INFO:SubProcess assign_model() end ==================================
2023-08-10 06:03:48,482:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 06:03:48,482:INFO:Fitting UMAP()
2023-08-10 06:04:39,201:INFO:Rendering Visual
2023-08-10 06:04:39,489:INFO:Visual Rendered Successfully
2023-08-10 06:04:40,317:INFO:plot_model() successfully completed......................................
2023-08-10 06:11:16,631:INFO:Initializing assign_model()
2023-08-10 06:11:16,632:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000245F8A6A2E0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8518, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 06:11:16,633:INFO:Checking exceptions
2023-08-10 06:11:16,634:INFO:Determining Trained Model
2023-08-10 06:11:16,636:INFO:Trained Model : Isolation Forest
2023-08-10 06:11:16,637:INFO:Copying data
2023-08-10 06:11:16,642:INFO:(3941, 13)
2023-08-10 06:11:16,643:INFO:assign_model() successfully completed......................................
2023-08-10 06:24:23,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 06:24:23,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 06:24:23,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 06:24:23,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 06:25:36,059:INFO:PyCaret AnomalyExperiment
2023-08-10 06:25:36,060:INFO:Logging name: anomaly-default-name
2023-08-10 06:25:36,060:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 06:25:36,060:INFO:version 3.0.4
2023-08-10 06:25:36,060:INFO:Initializing setup()
2023-08-10 06:25:36,060:INFO:self.USI: b1e9
2023-08-10 06:25:36,060:INFO:self._variable_keys: {'gpu_param', 'USI', 'idx', 'X', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'html_param', 'memory', 'log_plots_param', 'seed', '_available_plots', 'gpu_n_jobs_param', '_ml_usecase', 'exp_name_log'}
2023-08-10 06:25:36,061:INFO:Checking environment
2023-08-10 06:25:36,061:INFO:python_version: 3.9.13
2023-08-10 06:25:36,061:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 06:25:36,061:INFO:machine: AMD64
2023-08-10 06:25:36,061:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 06:25:36,069:INFO:Memory: svmem(total=7480111104, available=1341669376, percent=82.1, used=6138441728, free=1341669376)
2023-08-10 06:25:36,073:INFO:Physical Core: 4
2023-08-10 06:25:36,074:INFO:Logical Core: 4
2023-08-10 06:25:36,074:INFO:Checking libraries
2023-08-10 06:25:36,074:INFO:System:
2023-08-10 06:25:36,074:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 06:25:36,075:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 06:25:36,075:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 06:25:36,075:INFO:PyCaret required dependencies:
2023-08-10 06:25:36,574:INFO:                 pip: 23.1.2
2023-08-10 06:25:36,574:INFO:          setuptools: 58.1.0
2023-08-10 06:25:36,574:INFO:             pycaret: 3.0.4
2023-08-10 06:25:36,575:INFO:             IPython: 8.13.2
2023-08-10 06:25:36,575:INFO:          ipywidgets: 8.0.7
2023-08-10 06:25:36,575:INFO:                tqdm: 4.65.0
2023-08-10 06:25:36,575:INFO:               numpy: 1.23.5
2023-08-10 06:25:36,575:INFO:              pandas: 1.5.3
2023-08-10 06:25:36,575:INFO:              jinja2: 3.1.2
2023-08-10 06:25:36,575:INFO:               scipy: 1.10.1
2023-08-10 06:25:36,576:INFO:              joblib: 1.2.0
2023-08-10 06:25:36,576:INFO:             sklearn: 1.2.2
2023-08-10 06:25:36,576:INFO:                pyod: 1.1.0
2023-08-10 06:25:36,576:INFO:            imblearn: 0.11.0
2023-08-10 06:25:36,577:INFO:   category_encoders: 2.6.1
2023-08-10 06:25:36,577:INFO:            lightgbm: 4.0.0
2023-08-10 06:25:36,577:INFO:               numba: 0.57.1
2023-08-10 06:25:36,577:INFO:            requests: 2.31.0
2023-08-10 06:25:36,577:INFO:          matplotlib: 3.7.1
2023-08-10 06:25:36,578:INFO:          scikitplot: 0.3.7
2023-08-10 06:25:36,579:INFO:         yellowbrick: 1.5
2023-08-10 06:25:36,580:INFO:              plotly: 5.15.0
2023-08-10 06:25:36,580:INFO:    plotly-resampler: Not installed
2023-08-10 06:25:36,580:INFO:             kaleido: 0.2.1
2023-08-10 06:25:36,580:INFO:           schemdraw: 0.15
2023-08-10 06:25:36,581:INFO:         statsmodels: 0.14.0
2023-08-10 06:25:36,581:INFO:              sktime: 0.20.1
2023-08-10 06:25:36,581:INFO:               tbats: 1.1.3
2023-08-10 06:25:36,581:INFO:            pmdarima: 2.0.3
2023-08-10 06:25:36,581:INFO:              psutil: 5.9.5
2023-08-10 06:25:36,582:INFO:          markupsafe: 2.1.3
2023-08-10 06:25:36,582:INFO:             pickle5: Not installed
2023-08-10 06:25:36,582:INFO:         cloudpickle: 2.2.1
2023-08-10 06:25:36,582:INFO:         deprecation: 2.1.0
2023-08-10 06:25:36,583:INFO:              xxhash: 3.2.0
2023-08-10 06:25:36,583:INFO:           wurlitzer: Not installed
2023-08-10 06:25:36,583:INFO:PyCaret optional dependencies:
2023-08-10 06:25:36,667:INFO:                shap: Not installed
2023-08-10 06:25:36,667:INFO:           interpret: 0.4.2
2023-08-10 06:25:36,667:INFO:                umap: 0.5.3
2023-08-10 06:25:36,668:INFO:    pandas_profiling: Not installed
2023-08-10 06:25:36,668:INFO:  explainerdashboard: Not installed
2023-08-10 06:25:36,668:INFO:             autoviz: Not installed
2023-08-10 06:25:36,668:INFO:           fairlearn: Not installed
2023-08-10 06:25:36,668:INFO:          deepchecks: Not installed
2023-08-10 06:25:36,668:INFO:             xgboost: 1.7.6
2023-08-10 06:25:36,668:INFO:            catboost: Not installed
2023-08-10 06:25:36,669:INFO:              kmodes: Not installed
2023-08-10 06:25:36,669:INFO:             mlxtend: 0.22.0
2023-08-10 06:25:36,669:INFO:       statsforecast: Not installed
2023-08-10 06:25:36,669:INFO:        tune_sklearn: Not installed
2023-08-10 06:25:36,669:INFO:                 ray: Not installed
2023-08-10 06:25:36,669:INFO:            hyperopt: Not installed
2023-08-10 06:25:36,669:INFO:              optuna: Not installed
2023-08-10 06:25:36,672:INFO:               skopt: Not installed
2023-08-10 06:25:36,672:INFO:              mlflow: 2.4.2
2023-08-10 06:25:36,672:INFO:              gradio: Not installed
2023-08-10 06:25:36,672:INFO:             fastapi: Not installed
2023-08-10 06:25:36,673:INFO:             uvicorn: Not installed
2023-08-10 06:25:36,673:INFO:              m2cgen: Not installed
2023-08-10 06:25:36,673:INFO:           evidently: Not installed
2023-08-10 06:25:36,673:INFO:               fugue: Not installed
2023-08-10 06:25:36,673:INFO:           streamlit: 1.25.0
2023-08-10 06:25:36,673:INFO:             prophet: Not installed
2023-08-10 06:25:36,673:INFO:None
2023-08-10 06:25:36,673:INFO:Set up data.
2023-08-10 06:25:36,696:INFO:Set up index.
2023-08-10 06:25:36,697:INFO:Assigning column types.
2023-08-10 06:25:36,708:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 06:25:42,068:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 06:25:42,080:INFO:Preparing preprocessing pipeline...
2023-08-10 06:25:42,081:INFO:Set up simple imputation.
2023-08-10 06:25:42,094:INFO:Set up encoding of categorical features.
2023-08-10 06:25:42,398:INFO:Finished creating preprocessing pipeline.
2023-08-10 06:25:42,442:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 06:25:42,443:INFO:Creating final display dataframe.
2023-08-10 06:25:42,550:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  2808
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 18)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  b1e9
2023-08-10 06:25:42,558:INFO:setup() successfully completed in 8.81s...............
2023-08-10 06:25:42,559:INFO:Initializing create_model()
2023-08-10 06:25:42,559:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002A4393CB700>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 06:25:42,559:INFO:Checking exceptions
2023-08-10 06:25:42,612:INFO:Importing untrained model
2023-08-10 06:25:42,614:INFO:Isolation Forest Imported successfully
2023-08-10 06:25:42,618:INFO:Fitting Model
2023-08-10 06:25:45,627:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2808, verbose=0)
2023-08-10 06:25:45,627:INFO:create_models() successfully completed......................................
2023-08-10 06:25:45,627:INFO:Uploading results into container
2023-08-10 06:25:45,627:INFO:Uploading model into container now
2023-08-10 06:25:45,627:INFO:_master_model_container: 1
2023-08-10 06:25:45,627:INFO:_display_container: 1
2023-08-10 06:25:45,628:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2808, verbose=0)
2023-08-10 06:25:45,628:INFO:create_model() successfully completed......................................
2023-08-10 06:25:48,251:INFO:Initializing plot_model()
2023-08-10 06:25:48,251:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2808, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002A4393CB700>, system=True)
2023-08-10 06:25:48,252:INFO:Checking exceptions
2023-08-10 06:25:57,950:INFO:Preloading libraries
2023-08-10 06:25:58,015:INFO:Copying training dataset
2023-08-10 06:25:58,015:INFO:Plot type: umap
2023-08-10 06:25:58,016:INFO:SubProcess assign_model() called ==================================
2023-08-10 06:25:58,018:INFO:Initializing assign_model()
2023-08-10 06:25:58,018:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002A4393CB700>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2808, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 06:25:58,018:INFO:Checking exceptions
2023-08-10 06:25:58,019:INFO:Determining Trained Model
2023-08-10 06:25:58,025:INFO:Trained Model : Isolation Forest
2023-08-10 06:25:58,026:INFO:Copying data
2023-08-10 06:25:58,096:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 06:25:58,098:INFO:(3941, 19)
2023-08-10 06:25:58,099:INFO:assign_model() successfully completed......................................
2023-08-10 06:25:58,101:INFO:SubProcess assign_model() end ==================================
2023-08-10 06:25:58,115:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 06:26:21,779:INFO:Fitting UMAP()
2023-08-10 06:27:21,931:INFO:Rendering Visual
2023-08-10 06:27:28,620:INFO:Visual Rendered Successfully
2023-08-10 06:27:29,116:INFO:plot_model() successfully completed......................................
2023-08-10 06:29:47,722:INFO:Initializing assign_model()
2023-08-10 06:29:47,725:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002A4393CB700>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2808, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 06:29:47,725:INFO:Checking exceptions
2023-08-10 06:29:47,726:INFO:Determining Trained Model
2023-08-10 06:29:47,727:INFO:Trained Model : Isolation Forest
2023-08-10 06:29:47,728:INFO:Copying data
2023-08-10 06:29:47,734:INFO:(3941, 13)
2023-08-10 06:29:47,734:INFO:assign_model() successfully completed......................................
2023-08-10 06:35:05,215:INFO:PyCaret ClassificationExperiment
2023-08-10 06:35:05,215:INFO:Logging name: clf-default-name
2023-08-10 06:35:05,215:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 06:35:05,216:INFO:version 3.0.4
2023-08-10 06:35:05,216:INFO:Initializing setup()
2023-08-10 06:35:05,216:INFO:self.USI: 990c
2023-08-10 06:35:05,216:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'gpu_param', 'USI', 'idx', 'y_train', 'X', 'y_test', 'fold_shuffle_param', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'html_param', 'memory', 'target_param', 'log_plots_param', 'X_test', 'seed', 'fold_generator', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'exp_name_log'}
2023-08-10 06:35:05,216:INFO:Checking environment
2023-08-10 06:35:05,217:INFO:python_version: 3.9.13
2023-08-10 06:35:05,217:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 06:35:05,217:INFO:machine: AMD64
2023-08-10 06:35:05,217:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 06:35:05,226:INFO:Memory: svmem(total=7480111104, available=890331136, percent=88.1, used=6589779968, free=890331136)
2023-08-10 06:35:05,226:INFO:Physical Core: 4
2023-08-10 06:35:05,226:INFO:Logical Core: 4
2023-08-10 06:35:05,226:INFO:Checking libraries
2023-08-10 06:35:05,227:INFO:System:
2023-08-10 06:35:05,227:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 06:35:05,227:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 06:35:05,227:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 06:35:05,227:INFO:PyCaret required dependencies:
2023-08-10 06:35:05,228:INFO:                 pip: 23.1.2
2023-08-10 06:35:05,228:INFO:          setuptools: 58.1.0
2023-08-10 06:35:05,228:INFO:             pycaret: 3.0.4
2023-08-10 06:35:05,228:INFO:             IPython: 8.13.2
2023-08-10 06:35:05,228:INFO:          ipywidgets: 8.0.7
2023-08-10 06:35:05,228:INFO:                tqdm: 4.65.0
2023-08-10 06:35:05,229:INFO:               numpy: 1.23.5
2023-08-10 06:35:05,229:INFO:              pandas: 1.5.3
2023-08-10 06:35:05,229:INFO:              jinja2: 3.1.2
2023-08-10 06:35:05,229:INFO:               scipy: 1.10.1
2023-08-10 06:35:05,229:INFO:              joblib: 1.2.0
2023-08-10 06:35:05,230:INFO:             sklearn: 1.2.2
2023-08-10 06:35:05,230:INFO:                pyod: 1.1.0
2023-08-10 06:35:05,230:INFO:            imblearn: 0.11.0
2023-08-10 06:35:05,230:INFO:   category_encoders: 2.6.1
2023-08-10 06:35:05,230:INFO:            lightgbm: 4.0.0
2023-08-10 06:35:05,230:INFO:               numba: 0.57.1
2023-08-10 06:35:05,230:INFO:            requests: 2.31.0
2023-08-10 06:35:05,230:INFO:          matplotlib: 3.7.1
2023-08-10 06:35:05,231:INFO:          scikitplot: 0.3.7
2023-08-10 06:35:05,231:INFO:         yellowbrick: 1.5
2023-08-10 06:35:05,231:INFO:              plotly: 5.15.0
2023-08-10 06:35:05,231:INFO:    plotly-resampler: Not installed
2023-08-10 06:35:05,231:INFO:             kaleido: 0.2.1
2023-08-10 06:35:05,231:INFO:           schemdraw: 0.15
2023-08-10 06:35:05,232:INFO:         statsmodels: 0.14.0
2023-08-10 06:35:05,232:INFO:              sktime: 0.20.1
2023-08-10 06:35:05,232:INFO:               tbats: 1.1.3
2023-08-10 06:35:05,232:INFO:            pmdarima: 2.0.3
2023-08-10 06:35:05,232:INFO:              psutil: 5.9.5
2023-08-10 06:35:05,232:INFO:          markupsafe: 2.1.3
2023-08-10 06:35:05,233:INFO:             pickle5: Not installed
2023-08-10 06:35:05,233:INFO:         cloudpickle: 2.2.1
2023-08-10 06:35:05,233:INFO:         deprecation: 2.1.0
2023-08-10 06:35:05,233:INFO:              xxhash: 3.2.0
2023-08-10 06:35:05,233:INFO:           wurlitzer: Not installed
2023-08-10 06:35:05,233:INFO:PyCaret optional dependencies:
2023-08-10 06:35:05,234:INFO:                shap: Not installed
2023-08-10 06:35:05,234:INFO:           interpret: 0.4.2
2023-08-10 06:35:05,234:INFO:                umap: 0.5.3
2023-08-10 06:35:05,234:INFO:    pandas_profiling: Not installed
2023-08-10 06:35:05,235:INFO:  explainerdashboard: Not installed
2023-08-10 06:35:05,235:INFO:             autoviz: Not installed
2023-08-10 06:35:05,235:INFO:           fairlearn: Not installed
2023-08-10 06:35:05,235:INFO:          deepchecks: Not installed
2023-08-10 06:35:05,235:INFO:             xgboost: 1.7.6
2023-08-10 06:35:05,236:INFO:            catboost: Not installed
2023-08-10 06:35:05,236:INFO:              kmodes: Not installed
2023-08-10 06:35:05,236:INFO:             mlxtend: 0.22.0
2023-08-10 06:35:05,236:INFO:       statsforecast: Not installed
2023-08-10 06:35:05,236:INFO:        tune_sklearn: Not installed
2023-08-10 06:35:05,236:INFO:                 ray: Not installed
2023-08-10 06:35:05,236:INFO:            hyperopt: Not installed
2023-08-10 06:35:05,237:INFO:              optuna: Not installed
2023-08-10 06:35:05,237:INFO:               skopt: Not installed
2023-08-10 06:35:05,237:INFO:              mlflow: 2.4.2
2023-08-10 06:35:05,237:INFO:              gradio: Not installed
2023-08-10 06:35:05,237:INFO:             fastapi: Not installed
2023-08-10 06:35:05,237:INFO:             uvicorn: Not installed
2023-08-10 06:35:05,238:INFO:              m2cgen: Not installed
2023-08-10 06:35:05,238:INFO:           evidently: Not installed
2023-08-10 06:35:05,238:INFO:               fugue: Not installed
2023-08-10 06:35:05,238:INFO:           streamlit: 1.25.0
2023-08-10 06:35:05,238:INFO:             prophet: Not installed
2023-08-10 06:35:05,238:INFO:None
2023-08-10 06:35:05,239:INFO:Set up data.
2023-08-10 06:35:47,298:INFO:PyCaret ClassificationExperiment
2023-08-10 06:35:47,299:INFO:Logging name: clf-default-name
2023-08-10 06:35:47,317:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 06:35:47,318:INFO:version 3.0.4
2023-08-10 06:35:47,318:INFO:Initializing setup()
2023-08-10 06:35:47,318:INFO:self.USI: 2fad
2023-08-10 06:35:47,318:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'gpu_param', 'USI', 'idx', 'y_train', 'X', 'y_test', 'fold_shuffle_param', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'html_param', 'memory', 'target_param', 'log_plots_param', 'X_test', 'seed', 'fold_generator', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'exp_name_log'}
2023-08-10 06:35:47,318:INFO:Checking environment
2023-08-10 06:35:47,319:INFO:python_version: 3.9.13
2023-08-10 06:35:47,319:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 06:35:47,319:INFO:machine: AMD64
2023-08-10 06:35:47,319:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 06:35:47,345:INFO:Memory: svmem(total=7480111104, available=907898880, percent=87.9, used=6572212224, free=907898880)
2023-08-10 06:35:47,347:INFO:Physical Core: 4
2023-08-10 06:35:47,352:INFO:Logical Core: 4
2023-08-10 06:35:47,359:INFO:Checking libraries
2023-08-10 06:35:47,363:INFO:System:
2023-08-10 06:35:47,367:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 06:35:47,379:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 06:35:47,391:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 06:35:47,392:INFO:PyCaret required dependencies:
2023-08-10 06:35:47,392:INFO:                 pip: 23.1.2
2023-08-10 06:35:47,392:INFO:          setuptools: 58.1.0
2023-08-10 06:35:47,393:INFO:             pycaret: 3.0.4
2023-08-10 06:35:47,393:INFO:             IPython: 8.13.2
2023-08-10 06:35:47,393:INFO:          ipywidgets: 8.0.7
2023-08-10 06:35:47,393:INFO:                tqdm: 4.65.0
2023-08-10 06:35:47,393:INFO:               numpy: 1.23.5
2023-08-10 06:35:47,393:INFO:              pandas: 1.5.3
2023-08-10 06:35:47,393:INFO:              jinja2: 3.1.2
2023-08-10 06:35:47,393:INFO:               scipy: 1.10.1
2023-08-10 06:35:47,394:INFO:              joblib: 1.2.0
2023-08-10 06:35:47,394:INFO:             sklearn: 1.2.2
2023-08-10 06:35:47,394:INFO:                pyod: 1.1.0
2023-08-10 06:35:47,394:INFO:            imblearn: 0.11.0
2023-08-10 06:35:47,394:INFO:   category_encoders: 2.6.1
2023-08-10 06:35:47,394:INFO:            lightgbm: 4.0.0
2023-08-10 06:35:47,394:INFO:               numba: 0.57.1
2023-08-10 06:35:47,395:INFO:            requests: 2.31.0
2023-08-10 06:35:47,395:INFO:          matplotlib: 3.7.1
2023-08-10 06:35:47,395:INFO:          scikitplot: 0.3.7
2023-08-10 06:35:47,395:INFO:         yellowbrick: 1.5
2023-08-10 06:35:47,395:INFO:              plotly: 5.15.0
2023-08-10 06:35:47,395:INFO:    plotly-resampler: Not installed
2023-08-10 06:35:47,395:INFO:             kaleido: 0.2.1
2023-08-10 06:35:47,395:INFO:           schemdraw: 0.15
2023-08-10 06:35:47,396:INFO:         statsmodels: 0.14.0
2023-08-10 06:35:47,396:INFO:              sktime: 0.20.1
2023-08-10 06:35:47,396:INFO:               tbats: 1.1.3
2023-08-10 06:35:47,396:INFO:            pmdarima: 2.0.3
2023-08-10 06:35:47,396:INFO:              psutil: 5.9.5
2023-08-10 06:35:47,396:INFO:          markupsafe: 2.1.3
2023-08-10 06:35:47,396:INFO:             pickle5: Not installed
2023-08-10 06:35:47,396:INFO:         cloudpickle: 2.2.1
2023-08-10 06:35:47,397:INFO:         deprecation: 2.1.0
2023-08-10 06:35:47,397:INFO:              xxhash: 3.2.0
2023-08-10 06:35:47,397:INFO:           wurlitzer: Not installed
2023-08-10 06:35:47,397:INFO:PyCaret optional dependencies:
2023-08-10 06:35:47,397:INFO:                shap: Not installed
2023-08-10 06:35:47,398:INFO:           interpret: 0.4.2
2023-08-10 06:35:47,398:INFO:                umap: 0.5.3
2023-08-10 06:35:47,398:INFO:    pandas_profiling: Not installed
2023-08-10 06:35:47,398:INFO:  explainerdashboard: Not installed
2023-08-10 06:35:47,398:INFO:             autoviz: Not installed
2023-08-10 06:35:47,398:INFO:           fairlearn: Not installed
2023-08-10 06:35:47,398:INFO:          deepchecks: Not installed
2023-08-10 06:35:47,398:INFO:             xgboost: 1.7.6
2023-08-10 06:35:47,398:INFO:            catboost: Not installed
2023-08-10 06:35:47,399:INFO:              kmodes: Not installed
2023-08-10 06:35:47,399:INFO:             mlxtend: 0.22.0
2023-08-10 06:35:47,399:INFO:       statsforecast: Not installed
2023-08-10 06:35:47,399:INFO:        tune_sklearn: Not installed
2023-08-10 06:35:47,399:INFO:                 ray: Not installed
2023-08-10 06:35:47,399:INFO:            hyperopt: Not installed
2023-08-10 06:35:47,399:INFO:              optuna: Not installed
2023-08-10 06:35:47,399:INFO:               skopt: Not installed
2023-08-10 06:35:47,399:INFO:              mlflow: 2.4.2
2023-08-10 06:35:47,400:INFO:              gradio: Not installed
2023-08-10 06:35:47,400:INFO:             fastapi: Not installed
2023-08-10 06:35:47,400:INFO:             uvicorn: Not installed
2023-08-10 06:35:47,400:INFO:              m2cgen: Not installed
2023-08-10 06:35:47,400:INFO:           evidently: Not installed
2023-08-10 06:35:47,400:INFO:               fugue: Not installed
2023-08-10 06:35:47,400:INFO:           streamlit: 1.25.0
2023-08-10 06:35:47,401:INFO:             prophet: Not installed
2023-08-10 06:35:47,401:INFO:None
2023-08-10 06:35:47,401:INFO:Set up data.
2023-08-10 06:35:47,551:INFO:Set up train/test split.
2023-08-10 06:35:47,584:INFO:Set up index.
2023-08-10 06:35:47,585:INFO:Set up folding strategy.
2023-08-10 06:35:47,585:INFO:Assigning column types.
2023-08-10 06:35:47,601:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 06:35:47,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:35:47,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:35:48,028:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:48,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:48,244:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:35:48,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:35:48,395:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:48,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:48,411:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 06:35:48,566:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:35:48,663:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:48,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:48,821:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:35:48,914:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:48,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:48,925:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 06:35:49,167:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:49,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:49,500:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:49,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:49,513:INFO:Preparing preprocessing pipeline...
2023-08-10 06:35:49,515:INFO:Set up simple imputation.
2023-08-10 06:35:49,526:INFO:Set up encoding of categorical features.
2023-08-10 06:35:49,741:INFO:Finished creating preprocessing pipeline.
2023-08-10 06:35:49,760:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-10 06:35:49,760:INFO:Creating final display dataframe.
2023-08-10 06:35:50,427:INFO:Setup _display_container:                     Description             Value
0                    Session id              2697
1                        Target             Churn
2                   Target type            Binary
3           Original data shape        (3941, 11)
4        Transformed data shape        (3941, 18)
5   Transformed train set shape        (2758, 18)
6    Transformed test set shape        (1183, 18)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values             14.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              2fad
2023-08-10 06:35:50,740:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:50,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:51,000:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:35:51,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:35:51,012:INFO:setup() successfully completed in 8.03s...............
2023-08-10 06:48:21,393:INFO:PyCaret ClassificationExperiment
2023-08-10 06:48:21,394:INFO:Logging name: clf-default-name
2023-08-10 06:48:21,394:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 06:48:21,394:INFO:version 3.0.4
2023-08-10 06:48:21,394:INFO:Initializing setup()
2023-08-10 06:48:21,394:INFO:self.USI: 2628
2023-08-10 06:48:21,394:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'gpu_param', 'USI', 'idx', 'y_train', 'X', 'y_test', 'fold_shuffle_param', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'html_param', 'memory', 'target_param', 'log_plots_param', 'X_test', 'seed', 'fold_generator', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'exp_name_log'}
2023-08-10 06:48:21,394:INFO:Checking environment
2023-08-10 06:48:21,394:INFO:python_version: 3.9.13
2023-08-10 06:48:21,395:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 06:48:21,395:INFO:machine: AMD64
2023-08-10 06:48:21,395:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 06:48:21,407:INFO:Memory: svmem(total=7480111104, available=996782080, percent=86.7, used=6483329024, free=996782080)
2023-08-10 06:48:21,407:INFO:Physical Core: 4
2023-08-10 06:48:21,408:INFO:Logical Core: 4
2023-08-10 06:48:21,408:INFO:Checking libraries
2023-08-10 06:48:21,408:INFO:System:
2023-08-10 06:48:21,408:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 06:48:21,408:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 06:48:21,408:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 06:48:21,408:INFO:PyCaret required dependencies:
2023-08-10 06:48:21,409:INFO:                 pip: 23.1.2
2023-08-10 06:48:21,409:INFO:          setuptools: 58.1.0
2023-08-10 06:48:21,409:INFO:             pycaret: 3.0.4
2023-08-10 06:48:21,409:INFO:             IPython: 8.13.2
2023-08-10 06:48:21,409:INFO:          ipywidgets: 8.0.7
2023-08-10 06:48:21,409:INFO:                tqdm: 4.65.0
2023-08-10 06:48:21,409:INFO:               numpy: 1.23.5
2023-08-10 06:48:21,410:INFO:              pandas: 1.5.3
2023-08-10 06:48:21,410:INFO:              jinja2: 3.1.2
2023-08-10 06:48:21,410:INFO:               scipy: 1.10.1
2023-08-10 06:48:21,410:INFO:              joblib: 1.2.0
2023-08-10 06:48:21,410:INFO:             sklearn: 1.2.2
2023-08-10 06:48:21,410:INFO:                pyod: 1.1.0
2023-08-10 06:48:21,410:INFO:            imblearn: 0.11.0
2023-08-10 06:48:21,410:INFO:   category_encoders: 2.6.1
2023-08-10 06:48:21,410:INFO:            lightgbm: 4.0.0
2023-08-10 06:48:21,410:INFO:               numba: 0.57.1
2023-08-10 06:48:21,411:INFO:            requests: 2.31.0
2023-08-10 06:48:21,411:INFO:          matplotlib: 3.7.1
2023-08-10 06:48:21,411:INFO:          scikitplot: 0.3.7
2023-08-10 06:48:21,411:INFO:         yellowbrick: 1.5
2023-08-10 06:48:21,411:INFO:              plotly: 5.15.0
2023-08-10 06:48:21,411:INFO:    plotly-resampler: Not installed
2023-08-10 06:48:21,411:INFO:             kaleido: 0.2.1
2023-08-10 06:48:21,411:INFO:           schemdraw: 0.15
2023-08-10 06:48:21,411:INFO:         statsmodels: 0.14.0
2023-08-10 06:48:21,411:INFO:              sktime: 0.20.1
2023-08-10 06:48:21,412:INFO:               tbats: 1.1.3
2023-08-10 06:48:21,412:INFO:            pmdarima: 2.0.3
2023-08-10 06:48:21,412:INFO:              psutil: 5.9.5
2023-08-10 06:48:21,412:INFO:          markupsafe: 2.1.3
2023-08-10 06:48:21,412:INFO:             pickle5: Not installed
2023-08-10 06:48:21,412:INFO:         cloudpickle: 2.2.1
2023-08-10 06:48:21,412:INFO:         deprecation: 2.1.0
2023-08-10 06:48:21,412:INFO:              xxhash: 3.2.0
2023-08-10 06:48:21,412:INFO:           wurlitzer: Not installed
2023-08-10 06:48:21,412:INFO:PyCaret optional dependencies:
2023-08-10 06:48:21,413:INFO:                shap: Not installed
2023-08-10 06:48:21,413:INFO:           interpret: 0.4.2
2023-08-10 06:48:21,413:INFO:                umap: 0.5.3
2023-08-10 06:48:21,413:INFO:    pandas_profiling: Not installed
2023-08-10 06:48:21,413:INFO:  explainerdashboard: Not installed
2023-08-10 06:48:21,413:INFO:             autoviz: Not installed
2023-08-10 06:48:21,413:INFO:           fairlearn: Not installed
2023-08-10 06:48:21,413:INFO:          deepchecks: Not installed
2023-08-10 06:48:21,413:INFO:             xgboost: 1.7.6
2023-08-10 06:48:21,413:INFO:            catboost: Not installed
2023-08-10 06:48:21,414:INFO:              kmodes: Not installed
2023-08-10 06:48:21,415:INFO:             mlxtend: 0.22.0
2023-08-10 06:48:21,415:INFO:       statsforecast: Not installed
2023-08-10 06:48:21,417:INFO:        tune_sklearn: Not installed
2023-08-10 06:48:21,417:INFO:                 ray: Not installed
2023-08-10 06:48:21,418:INFO:            hyperopt: Not installed
2023-08-10 06:48:21,418:INFO:              optuna: Not installed
2023-08-10 06:48:21,419:INFO:               skopt: Not installed
2023-08-10 06:48:21,419:INFO:              mlflow: 2.4.2
2023-08-10 06:48:21,419:INFO:              gradio: Not installed
2023-08-10 06:48:21,419:INFO:             fastapi: Not installed
2023-08-10 06:48:21,419:INFO:             uvicorn: Not installed
2023-08-10 06:48:21,420:INFO:              m2cgen: Not installed
2023-08-10 06:48:21,420:INFO:           evidently: Not installed
2023-08-10 06:48:21,420:INFO:               fugue: Not installed
2023-08-10 06:48:21,420:INFO:           streamlit: 1.25.0
2023-08-10 06:48:21,420:INFO:             prophet: Not installed
2023-08-10 06:48:21,420:INFO:None
2023-08-10 06:48:21,421:INFO:Set up data.
2023-08-10 06:48:21,453:INFO:Set up train/test split.
2023-08-10 06:48:21,476:INFO:Set up index.
2023-08-10 06:48:21,477:INFO:Set up folding strategy.
2023-08-10 06:48:21,477:INFO:Assigning column types.
2023-08-10 06:48:21,497:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 06:48:21,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:48:21,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:48:21,774:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:21,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:21,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:48:21,947:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:48:22,051:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:22,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:22,059:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 06:48:22,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:48:22,322:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:22,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:22,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:48:22,601:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:22,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:22,610:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 06:48:22,867:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:22,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:23,151:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:23,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:23,170:INFO:Preparing preprocessing pipeline...
2023-08-10 06:48:23,173:INFO:Set up simple imputation.
2023-08-10 06:48:23,185:INFO:Set up encoding of categorical features.
2023-08-10 06:48:23,186:INFO:Set up removing outliers.
2023-08-10 06:48:23,487:INFO:Finished creating preprocessing pipeline.
2023-08-10 06:48:23,511:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=4215,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 06:48:23,511:INFO:Creating final display dataframe.
2023-08-10 06:48:29,571:INFO:Setup _display_container:                     Description             Value
0                    Session id              4215
1                        Target             Churn
2                   Target type            Binary
3           Original data shape        (3941, 11)
4        Transformed data shape        (3803, 18)
5   Transformed train set shape        (2620, 18)
6    Transformed test set shape        (1183, 18)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values             14.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              2628
2023-08-10 06:48:30,095:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:30,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:30,412:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:48:30,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:48:30,425:INFO:setup() successfully completed in 11.27s...............
2023-08-10 06:51:37,335:INFO:PyCaret ClassificationExperiment
2023-08-10 06:51:37,336:INFO:Logging name: clf-default-name
2023-08-10 06:51:37,336:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 06:51:37,336:INFO:version 3.0.4
2023-08-10 06:51:37,337:INFO:Initializing setup()
2023-08-10 06:51:37,337:INFO:self.USI: 384a
2023-08-10 06:51:37,339:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'gpu_param', 'USI', 'idx', 'y_train', 'X', 'y_test', 'fold_shuffle_param', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'html_param', 'memory', 'target_param', 'log_plots_param', 'X_test', 'seed', 'fold_generator', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'exp_name_log'}
2023-08-10 06:51:37,340:INFO:Checking environment
2023-08-10 06:51:37,340:INFO:python_version: 3.9.13
2023-08-10 06:51:37,341:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 06:51:37,341:INFO:machine: AMD64
2023-08-10 06:51:37,341:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 06:51:37,349:INFO:Memory: svmem(total=7480111104, available=1122910208, percent=85.0, used=6357200896, free=1122910208)
2023-08-10 06:51:37,350:INFO:Physical Core: 4
2023-08-10 06:51:37,350:INFO:Logical Core: 4
2023-08-10 06:51:37,350:INFO:Checking libraries
2023-08-10 06:51:37,351:INFO:System:
2023-08-10 06:51:37,351:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 06:51:37,351:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 06:51:37,351:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 06:51:37,351:INFO:PyCaret required dependencies:
2023-08-10 06:51:37,352:INFO:                 pip: 23.1.2
2023-08-10 06:51:37,352:INFO:          setuptools: 58.1.0
2023-08-10 06:51:37,352:INFO:             pycaret: 3.0.4
2023-08-10 06:51:37,352:INFO:             IPython: 8.13.2
2023-08-10 06:51:37,352:INFO:          ipywidgets: 8.0.7
2023-08-10 06:51:37,353:INFO:                tqdm: 4.65.0
2023-08-10 06:51:37,353:INFO:               numpy: 1.23.5
2023-08-10 06:51:37,353:INFO:              pandas: 1.5.3
2023-08-10 06:51:37,353:INFO:              jinja2: 3.1.2
2023-08-10 06:51:37,353:INFO:               scipy: 1.10.1
2023-08-10 06:51:37,353:INFO:              joblib: 1.2.0
2023-08-10 06:51:37,353:INFO:             sklearn: 1.2.2
2023-08-10 06:51:37,354:INFO:                pyod: 1.1.0
2023-08-10 06:51:37,354:INFO:            imblearn: 0.11.0
2023-08-10 06:51:37,358:INFO:   category_encoders: 2.6.1
2023-08-10 06:51:37,358:INFO:            lightgbm: 4.0.0
2023-08-10 06:51:37,358:INFO:               numba: 0.57.1
2023-08-10 06:51:37,358:INFO:            requests: 2.31.0
2023-08-10 06:51:37,359:INFO:          matplotlib: 3.7.1
2023-08-10 06:51:37,359:INFO:          scikitplot: 0.3.7
2023-08-10 06:51:37,359:INFO:         yellowbrick: 1.5
2023-08-10 06:51:37,359:INFO:              plotly: 5.15.0
2023-08-10 06:51:37,359:INFO:    plotly-resampler: Not installed
2023-08-10 06:51:37,360:INFO:             kaleido: 0.2.1
2023-08-10 06:51:37,360:INFO:           schemdraw: 0.15
2023-08-10 06:51:37,360:INFO:         statsmodels: 0.14.0
2023-08-10 06:51:37,360:INFO:              sktime: 0.20.1
2023-08-10 06:51:37,360:INFO:               tbats: 1.1.3
2023-08-10 06:51:37,360:INFO:            pmdarima: 2.0.3
2023-08-10 06:51:37,361:INFO:              psutil: 5.9.5
2023-08-10 06:51:37,361:INFO:          markupsafe: 2.1.3
2023-08-10 06:51:37,361:INFO:             pickle5: Not installed
2023-08-10 06:51:37,361:INFO:         cloudpickle: 2.2.1
2023-08-10 06:51:37,361:INFO:         deprecation: 2.1.0
2023-08-10 06:51:37,361:INFO:              xxhash: 3.2.0
2023-08-10 06:51:37,362:INFO:           wurlitzer: Not installed
2023-08-10 06:51:37,362:INFO:PyCaret optional dependencies:
2023-08-10 06:51:37,362:INFO:                shap: Not installed
2023-08-10 06:51:37,362:INFO:           interpret: 0.4.2
2023-08-10 06:51:37,362:INFO:                umap: 0.5.3
2023-08-10 06:51:37,362:INFO:    pandas_profiling: Not installed
2023-08-10 06:51:37,362:INFO:  explainerdashboard: Not installed
2023-08-10 06:51:37,363:INFO:             autoviz: Not installed
2023-08-10 06:51:37,363:INFO:           fairlearn: Not installed
2023-08-10 06:51:37,363:INFO:          deepchecks: Not installed
2023-08-10 06:51:37,363:INFO:             xgboost: 1.7.6
2023-08-10 06:51:37,363:INFO:            catboost: Not installed
2023-08-10 06:51:37,363:INFO:              kmodes: Not installed
2023-08-10 06:51:37,364:INFO:             mlxtend: 0.22.0
2023-08-10 06:51:37,364:INFO:       statsforecast: Not installed
2023-08-10 06:51:37,364:INFO:        tune_sklearn: Not installed
2023-08-10 06:51:37,364:INFO:                 ray: Not installed
2023-08-10 06:51:37,364:INFO:            hyperopt: Not installed
2023-08-10 06:51:37,365:INFO:              optuna: Not installed
2023-08-10 06:51:37,365:INFO:               skopt: Not installed
2023-08-10 06:51:37,365:INFO:              mlflow: 2.4.2
2023-08-10 06:51:37,365:INFO:              gradio: Not installed
2023-08-10 06:51:37,365:INFO:             fastapi: Not installed
2023-08-10 06:51:37,366:INFO:             uvicorn: Not installed
2023-08-10 06:51:37,366:INFO:              m2cgen: Not installed
2023-08-10 06:51:37,366:INFO:           evidently: Not installed
2023-08-10 06:51:37,367:INFO:               fugue: Not installed
2023-08-10 06:51:37,367:INFO:           streamlit: 1.25.0
2023-08-10 06:51:37,367:INFO:             prophet: Not installed
2023-08-10 06:51:37,367:INFO:None
2023-08-10 06:51:37,367:INFO:Set up data.
2023-08-10 06:51:37,409:INFO:Set up train/test split.
2023-08-10 06:51:37,436:INFO:Set up index.
2023-08-10 06:51:37,440:INFO:Set up folding strategy.
2023-08-10 06:51:37,441:INFO:Assigning column types.
2023-08-10 06:51:37,457:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 06:51:37,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:51:37,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:51:37,778:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:37,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:37,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:51:37,941:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:51:38,038:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:38,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:38,050:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 06:51:38,208:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:51:38,298:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:38,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:38,459:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:51:38,552:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:38,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:38,564:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 06:51:38,809:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:38,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:39,061:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:39,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:39,076:INFO:Preparing preprocessing pipeline...
2023-08-10 06:51:39,078:INFO:Set up iterative imputation.
2023-08-10 06:51:39,079:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-08-10 06:51:39,094:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-08-10 06:51:39,110:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-08-10 06:51:39,307:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-08-10 06:51:39,451:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:39,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:39,702:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:39,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:39,759:INFO:Set up encoding of categorical features.
2023-08-10 06:51:39,760:INFO:Set up removing outliers.
2023-08-10 06:51:45,534:INFO:Finished creating preprocessing pipeline.
2023-08-10 06:51:45,581:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('iterative_imputer',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=IterativeImputer(add_indicator=False,
                                                                 cat_estimator=LGBMClassifier(boosting_type='gbdt',
                                                                                              class_weight=None,
                                                                                              colsample_bytree=1.0,
                                                                                              importance_type='split',
                                                                                              learning_rate=0.1,
                                                                                              max_depth=-1,
                                                                                              min_child...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6900,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 06:51:45,582:INFO:Creating final display dataframe.
2023-08-10 06:51:53,396:INFO:Setup _display_container:                         Description             Value
0                        Session id              6900
1                            Target             Churn
2                       Target type            Binary
3               Original data shape        (3941, 11)
4            Transformed data shape        (3803, 18)
5       Transformed train set shape        (2620, 18)
6        Transformed test set shape        (1183, 18)
7                  Numeric features                 8
8              Categorical features                 2
9          Rows with missing values             14.6%
10                       Preprocess              True
11                  Imputation type         iterative
12  Iterative imputation iterations                 5
13        Numeric iterative imputer          lightgbm
14    Categorical iterative imputer          lightgbm
15         Maximum one-hot encoding                25
16                  Encoding method              None
17                  Remove outliers              True
18               Outliers threshold              0.05
19                   Fold Generator   StratifiedKFold
20                      Fold Number                10
21                         CPU Jobs                -1
22                          Use GPU             False
23                   Log Experiment             False
24                  Experiment Name  clf-default-name
25                              USI              384a
2023-08-10 06:51:53,689:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:53,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:53,932:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:51:53,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:51:53,943:INFO:setup() successfully completed in 19.77s...............
2023-08-10 06:52:29,532:INFO:PyCaret ClassificationExperiment
2023-08-10 06:52:29,532:INFO:Logging name: clf-default-name
2023-08-10 06:52:29,532:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 06:52:29,533:INFO:version 3.0.4
2023-08-10 06:52:29,533:INFO:Initializing setup()
2023-08-10 06:52:29,533:INFO:self.USI: d0e8
2023-08-10 06:52:29,533:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'gpu_param', 'USI', 'idx', 'y_train', 'X', 'y_test', 'fold_shuffle_param', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'html_param', 'memory', 'target_param', 'log_plots_param', 'X_test', 'seed', 'fold_generator', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'exp_name_log'}
2023-08-10 06:52:29,534:INFO:Checking environment
2023-08-10 06:52:29,537:INFO:python_version: 3.9.13
2023-08-10 06:52:29,537:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 06:52:29,538:INFO:machine: AMD64
2023-08-10 06:52:29,539:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 06:52:29,546:INFO:Memory: svmem(total=7480111104, available=1082572800, percent=85.5, used=6397538304, free=1082572800)
2023-08-10 06:52:29,546:INFO:Physical Core: 4
2023-08-10 06:52:29,546:INFO:Logical Core: 4
2023-08-10 06:52:29,547:INFO:Checking libraries
2023-08-10 06:52:29,547:INFO:System:
2023-08-10 06:52:29,547:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 06:52:29,547:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 06:52:29,547:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 06:52:29,547:INFO:PyCaret required dependencies:
2023-08-10 06:52:29,547:INFO:                 pip: 23.1.2
2023-08-10 06:52:29,547:INFO:          setuptools: 58.1.0
2023-08-10 06:52:29,548:INFO:             pycaret: 3.0.4
2023-08-10 06:52:29,548:INFO:             IPython: 8.13.2
2023-08-10 06:52:29,548:INFO:          ipywidgets: 8.0.7
2023-08-10 06:52:29,548:INFO:                tqdm: 4.65.0
2023-08-10 06:52:29,548:INFO:               numpy: 1.23.5
2023-08-10 06:52:29,548:INFO:              pandas: 1.5.3
2023-08-10 06:52:29,548:INFO:              jinja2: 3.1.2
2023-08-10 06:52:29,548:INFO:               scipy: 1.10.1
2023-08-10 06:52:29,548:INFO:              joblib: 1.2.0
2023-08-10 06:52:29,548:INFO:             sklearn: 1.2.2
2023-08-10 06:52:29,548:INFO:                pyod: 1.1.0
2023-08-10 06:52:29,549:INFO:            imblearn: 0.11.0
2023-08-10 06:52:29,549:INFO:   category_encoders: 2.6.1
2023-08-10 06:52:29,549:INFO:            lightgbm: 4.0.0
2023-08-10 06:52:29,549:INFO:               numba: 0.57.1
2023-08-10 06:52:29,549:INFO:            requests: 2.31.0
2023-08-10 06:52:29,549:INFO:          matplotlib: 3.7.1
2023-08-10 06:52:29,549:INFO:          scikitplot: 0.3.7
2023-08-10 06:52:29,550:INFO:         yellowbrick: 1.5
2023-08-10 06:52:29,550:INFO:              plotly: 5.15.0
2023-08-10 06:52:29,550:INFO:    plotly-resampler: Not installed
2023-08-10 06:52:29,550:INFO:             kaleido: 0.2.1
2023-08-10 06:52:29,550:INFO:           schemdraw: 0.15
2023-08-10 06:52:29,550:INFO:         statsmodels: 0.14.0
2023-08-10 06:52:29,554:INFO:              sktime: 0.20.1
2023-08-10 06:52:29,554:INFO:               tbats: 1.1.3
2023-08-10 06:52:29,554:INFO:            pmdarima: 2.0.3
2023-08-10 06:52:29,555:INFO:              psutil: 5.9.5
2023-08-10 06:52:29,555:INFO:          markupsafe: 2.1.3
2023-08-10 06:52:29,555:INFO:             pickle5: Not installed
2023-08-10 06:52:29,555:INFO:         cloudpickle: 2.2.1
2023-08-10 06:52:29,555:INFO:         deprecation: 2.1.0
2023-08-10 06:52:29,555:INFO:              xxhash: 3.2.0
2023-08-10 06:52:29,556:INFO:           wurlitzer: Not installed
2023-08-10 06:52:29,556:INFO:PyCaret optional dependencies:
2023-08-10 06:52:29,556:INFO:                shap: Not installed
2023-08-10 06:52:29,556:INFO:           interpret: 0.4.2
2023-08-10 06:52:29,556:INFO:                umap: 0.5.3
2023-08-10 06:52:29,557:INFO:    pandas_profiling: Not installed
2023-08-10 06:52:29,557:INFO:  explainerdashboard: Not installed
2023-08-10 06:52:29,557:INFO:             autoviz: Not installed
2023-08-10 06:52:29,557:INFO:           fairlearn: Not installed
2023-08-10 06:52:29,557:INFO:          deepchecks: Not installed
2023-08-10 06:52:29,557:INFO:             xgboost: 1.7.6
2023-08-10 06:52:29,557:INFO:            catboost: Not installed
2023-08-10 06:52:29,557:INFO:              kmodes: Not installed
2023-08-10 06:52:29,557:INFO:             mlxtend: 0.22.0
2023-08-10 06:52:29,558:INFO:       statsforecast: Not installed
2023-08-10 06:52:29,558:INFO:        tune_sklearn: Not installed
2023-08-10 06:52:29,558:INFO:                 ray: Not installed
2023-08-10 06:52:29,558:INFO:            hyperopt: Not installed
2023-08-10 06:52:29,558:INFO:              optuna: Not installed
2023-08-10 06:52:29,558:INFO:               skopt: Not installed
2023-08-10 06:52:29,558:INFO:              mlflow: 2.4.2
2023-08-10 06:52:29,558:INFO:              gradio: Not installed
2023-08-10 06:52:29,558:INFO:             fastapi: Not installed
2023-08-10 06:52:29,558:INFO:             uvicorn: Not installed
2023-08-10 06:52:29,559:INFO:              m2cgen: Not installed
2023-08-10 06:52:29,559:INFO:           evidently: Not installed
2023-08-10 06:52:29,559:INFO:               fugue: Not installed
2023-08-10 06:52:29,559:INFO:           streamlit: 1.25.0
2023-08-10 06:52:29,559:INFO:             prophet: Not installed
2023-08-10 06:52:29,559:INFO:None
2023-08-10 06:52:29,559:INFO:Set up data.
2023-08-10 06:52:29,591:INFO:Set up train/test split.
2023-08-10 06:52:29,615:INFO:Set up index.
2023-08-10 06:52:29,615:INFO:Set up folding strategy.
2023-08-10 06:52:29,616:INFO:Assigning column types.
2023-08-10 06:52:29,643:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 06:52:29,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:52:29,826:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:52:29,924:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:29,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:30,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 06:52:30,088:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:52:30,183:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:30,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:30,194:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 06:52:30,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:52:30,439:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:30,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:30,597:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 06:52:30,690:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:30,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:30,699:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 06:52:30,941:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:30,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:31,193:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:31,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:31,212:INFO:Preparing preprocessing pipeline...
2023-08-10 06:52:31,214:INFO:Set up simple imputation.
2023-08-10 06:52:31,225:INFO:Set up encoding of categorical features.
2023-08-10 06:52:31,225:INFO:Set up removing outliers.
2023-08-10 06:52:31,498:INFO:Finished creating preprocessing pipeline.
2023-08-10 06:52:31,516:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=7402,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 06:52:31,517:INFO:Creating final display dataframe.
2023-08-10 06:52:36,319:INFO:Setup _display_container:                     Description             Value
0                    Session id              7402
1                        Target             Churn
2                   Target type            Binary
3           Original data shape        (3941, 11)
4        Transformed data shape        (3803, 18)
5   Transformed train set shape        (2620, 18)
6    Transformed test set shape        (1183, 18)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values             14.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              d0e8
2023-08-10 06:52:36,642:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:36,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:36,937:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 06:52:36,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 06:52:36,946:INFO:setup() successfully completed in 10.28s...............
2023-08-10 07:28:00,061:INFO:PyCaret ClassificationExperiment
2023-08-10 07:28:00,062:INFO:Logging name: clf-default-name
2023-08-10 07:28:00,062:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 07:28:00,062:INFO:version 3.0.4
2023-08-10 07:28:00,062:INFO:Initializing setup()
2023-08-10 07:28:00,062:INFO:self.USI: 2c3d
2023-08-10 07:28:00,063:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'gpu_param', 'USI', 'idx', 'y_train', 'X', 'y_test', 'fold_shuffle_param', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'html_param', 'memory', 'target_param', 'log_plots_param', 'X_test', 'seed', 'fold_generator', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'exp_name_log'}
2023-08-10 07:28:00,063:INFO:Checking environment
2023-08-10 07:28:00,063:INFO:python_version: 3.9.13
2023-08-10 07:28:00,063:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 07:28:00,064:INFO:machine: AMD64
2023-08-10 07:28:00,064:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 07:28:00,075:INFO:Memory: svmem(total=7480111104, available=1120391168, percent=85.0, used=6359719936, free=1120391168)
2023-08-10 07:28:00,076:INFO:Physical Core: 4
2023-08-10 07:28:00,076:INFO:Logical Core: 4
2023-08-10 07:28:00,076:INFO:Checking libraries
2023-08-10 07:28:00,076:INFO:System:
2023-08-10 07:28:00,076:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 07:28:00,077:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 07:28:00,077:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 07:28:00,077:INFO:PyCaret required dependencies:
2023-08-10 07:28:00,077:INFO:                 pip: 23.1.2
2023-08-10 07:28:00,078:INFO:          setuptools: 58.1.0
2023-08-10 07:28:00,078:INFO:             pycaret: 3.0.4
2023-08-10 07:28:00,078:INFO:             IPython: 8.13.2
2023-08-10 07:28:00,079:INFO:          ipywidgets: 8.0.7
2023-08-10 07:28:00,079:INFO:                tqdm: 4.65.0
2023-08-10 07:28:00,080:INFO:               numpy: 1.23.5
2023-08-10 07:28:00,080:INFO:              pandas: 1.5.3
2023-08-10 07:28:00,081:INFO:              jinja2: 3.1.2
2023-08-10 07:28:00,081:INFO:               scipy: 1.10.1
2023-08-10 07:28:00,081:INFO:              joblib: 1.2.0
2023-08-10 07:28:00,081:INFO:             sklearn: 1.2.2
2023-08-10 07:28:00,081:INFO:                pyod: 1.1.0
2023-08-10 07:28:00,082:INFO:            imblearn: 0.11.0
2023-08-10 07:28:00,082:INFO:   category_encoders: 2.6.1
2023-08-10 07:28:00,082:INFO:            lightgbm: 4.0.0
2023-08-10 07:28:00,082:INFO:               numba: 0.57.1
2023-08-10 07:28:00,083:INFO:            requests: 2.31.0
2023-08-10 07:28:00,083:INFO:          matplotlib: 3.7.1
2023-08-10 07:28:00,083:INFO:          scikitplot: 0.3.7
2023-08-10 07:28:00,083:INFO:         yellowbrick: 1.5
2023-08-10 07:28:00,084:INFO:              plotly: 5.15.0
2023-08-10 07:28:00,084:INFO:    plotly-resampler: Not installed
2023-08-10 07:28:00,084:INFO:             kaleido: 0.2.1
2023-08-10 07:28:00,085:INFO:           schemdraw: 0.15
2023-08-10 07:28:00,085:INFO:         statsmodels: 0.14.0
2023-08-10 07:28:00,085:INFO:              sktime: 0.20.1
2023-08-10 07:28:00,086:INFO:               tbats: 1.1.3
2023-08-10 07:28:00,086:INFO:            pmdarima: 2.0.3
2023-08-10 07:28:00,086:INFO:              psutil: 5.9.5
2023-08-10 07:28:00,086:INFO:          markupsafe: 2.1.3
2023-08-10 07:28:00,086:INFO:             pickle5: Not installed
2023-08-10 07:28:00,087:INFO:         cloudpickle: 2.2.1
2023-08-10 07:28:00,087:INFO:         deprecation: 2.1.0
2023-08-10 07:28:00,087:INFO:              xxhash: 3.2.0
2023-08-10 07:28:00,091:INFO:           wurlitzer: Not installed
2023-08-10 07:28:00,091:INFO:PyCaret optional dependencies:
2023-08-10 07:28:00,092:INFO:                shap: Not installed
2023-08-10 07:28:00,092:INFO:           interpret: 0.4.2
2023-08-10 07:28:00,092:INFO:                umap: 0.5.3
2023-08-10 07:28:00,093:INFO:    pandas_profiling: Not installed
2023-08-10 07:28:00,093:INFO:  explainerdashboard: Not installed
2023-08-10 07:28:00,093:INFO:             autoviz: Not installed
2023-08-10 07:28:00,093:INFO:           fairlearn: Not installed
2023-08-10 07:28:00,093:INFO:          deepchecks: Not installed
2023-08-10 07:28:00,093:INFO:             xgboost: 1.7.6
2023-08-10 07:28:00,093:INFO:            catboost: Not installed
2023-08-10 07:28:00,093:INFO:              kmodes: Not installed
2023-08-10 07:28:00,094:INFO:             mlxtend: 0.22.0
2023-08-10 07:28:00,094:INFO:       statsforecast: Not installed
2023-08-10 07:28:00,094:INFO:        tune_sklearn: Not installed
2023-08-10 07:28:00,094:INFO:                 ray: Not installed
2023-08-10 07:28:00,094:INFO:            hyperopt: Not installed
2023-08-10 07:28:00,095:INFO:              optuna: Not installed
2023-08-10 07:28:00,095:INFO:               skopt: Not installed
2023-08-10 07:28:00,095:INFO:              mlflow: 2.4.2
2023-08-10 07:28:00,095:INFO:              gradio: Not installed
2023-08-10 07:28:00,095:INFO:             fastapi: Not installed
2023-08-10 07:28:00,096:INFO:             uvicorn: Not installed
2023-08-10 07:28:00,096:INFO:              m2cgen: Not installed
2023-08-10 07:28:00,096:INFO:           evidently: Not installed
2023-08-10 07:28:00,096:INFO:               fugue: Not installed
2023-08-10 07:28:00,097:INFO:           streamlit: 1.25.0
2023-08-10 07:28:00,097:INFO:             prophet: Not installed
2023-08-10 07:28:00,097:INFO:None
2023-08-10 07:28:00,097:INFO:Set up data.
2023-08-10 07:28:00,142:INFO:Set up train/test split.
2023-08-10 07:28:00,165:INFO:Set up index.
2023-08-10 07:28:00,166:INFO:Set up folding strategy.
2023-08-10 07:28:00,166:INFO:Assigning column types.
2023-08-10 07:28:00,184:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 07:28:00,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 07:28:00,384:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:28:00,528:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:00,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:00,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 07:28:00,784:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:28:00,968:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:00,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:00,990:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 07:28:01,297:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:28:01,445:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:01,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:01,743:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:28:01,934:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:01,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:01,953:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 07:28:02,430:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:02,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:02,815:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:02,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:02,842:INFO:Preparing preprocessing pipeline...
2023-08-10 07:28:02,845:INFO:Set up simple imputation.
2023-08-10 07:28:02,857:INFO:Set up encoding of categorical features.
2023-08-10 07:28:02,858:INFO:Set up removing outliers.
2023-08-10 07:28:03,445:INFO:Finished creating preprocessing pipeline.
2023-08-10 07:28:03,469:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=8805,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 07:28:03,470:INFO:Creating final display dataframe.
2023-08-10 07:28:10,209:INFO:Setup _display_container:                     Description             Value
0                    Session id              8805
1                        Target             Churn
2                   Target type            Binary
3           Original data shape        (3941, 11)
4        Transformed data shape        (3803, 18)
5   Transformed train set shape        (2620, 18)
6    Transformed test set shape        (1183, 18)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values             14.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              2c3d
2023-08-10 07:28:10,846:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:10,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:11,264:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:28:11,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:28:11,283:INFO:setup() successfully completed in 16.8s...............
2023-08-10 07:29:35,302:INFO:Initializing get_config()
2023-08-10 07:29:35,303:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A4441E3AF0>, variable=pipeline)
2023-08-10 07:29:35,328:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=8805,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 07:29:35,328:INFO:get_config() successfully completed......................................
2023-08-10 07:30:36,790:INFO:Initializing get_config()
2023-08-10 07:30:36,791:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A4441E3AF0>, variable=pipeline)
2023-08-10 07:30:36,826:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=8805,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 07:30:36,826:INFO:get_config() successfully completed......................................
2023-08-10 07:34:34,508:INFO:PyCaret ClassificationExperiment
2023-08-10 07:34:34,509:INFO:Logging name: clf-default-name
2023-08-10 07:34:34,509:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 07:34:34,509:INFO:version 3.0.4
2023-08-10 07:34:34,509:INFO:Initializing setup()
2023-08-10 07:34:34,509:INFO:self.USI: 5dec
2023-08-10 07:34:34,510:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'gpu_param', 'USI', 'idx', 'y_train', 'X', 'y_test', 'fold_shuffle_param', 'logging_param', 'data', 'exp_id', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'html_param', 'memory', 'target_param', 'log_plots_param', 'X_test', 'seed', 'fold_generator', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'exp_name_log'}
2023-08-10 07:34:34,510:INFO:Checking environment
2023-08-10 07:34:34,510:INFO:python_version: 3.9.13
2023-08-10 07:34:34,510:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 07:34:34,510:INFO:machine: AMD64
2023-08-10 07:34:34,511:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 07:34:34,522:INFO:Memory: svmem(total=7480111104, available=1067913216, percent=85.7, used=6412197888, free=1067913216)
2023-08-10 07:34:34,522:INFO:Physical Core: 4
2023-08-10 07:34:34,522:INFO:Logical Core: 4
2023-08-10 07:34:34,522:INFO:Checking libraries
2023-08-10 07:34:34,523:INFO:System:
2023-08-10 07:34:34,523:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 07:34:34,523:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 07:34:34,523:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 07:34:34,523:INFO:PyCaret required dependencies:
2023-08-10 07:34:34,524:INFO:                 pip: 23.1.2
2023-08-10 07:34:34,524:INFO:          setuptools: 58.1.0
2023-08-10 07:34:34,524:INFO:             pycaret: 3.0.4
2023-08-10 07:34:34,524:INFO:             IPython: 8.13.2
2023-08-10 07:34:34,524:INFO:          ipywidgets: 8.0.7
2023-08-10 07:34:34,524:INFO:                tqdm: 4.65.0
2023-08-10 07:34:34,525:INFO:               numpy: 1.23.5
2023-08-10 07:34:34,525:INFO:              pandas: 1.5.3
2023-08-10 07:34:34,525:INFO:              jinja2: 3.1.2
2023-08-10 07:34:34,525:INFO:               scipy: 1.10.1
2023-08-10 07:34:34,525:INFO:              joblib: 1.2.0
2023-08-10 07:34:34,525:INFO:             sklearn: 1.2.2
2023-08-10 07:34:34,525:INFO:                pyod: 1.1.0
2023-08-10 07:34:34,526:INFO:            imblearn: 0.11.0
2023-08-10 07:34:34,526:INFO:   category_encoders: 2.6.1
2023-08-10 07:34:34,526:INFO:            lightgbm: 4.0.0
2023-08-10 07:34:34,526:INFO:               numba: 0.57.1
2023-08-10 07:34:34,526:INFO:            requests: 2.31.0
2023-08-10 07:34:34,526:INFO:          matplotlib: 3.7.1
2023-08-10 07:34:34,526:INFO:          scikitplot: 0.3.7
2023-08-10 07:34:34,527:INFO:         yellowbrick: 1.5
2023-08-10 07:34:34,527:INFO:              plotly: 5.15.0
2023-08-10 07:34:34,527:INFO:    plotly-resampler: Not installed
2023-08-10 07:34:34,527:INFO:             kaleido: 0.2.1
2023-08-10 07:34:34,527:INFO:           schemdraw: 0.15
2023-08-10 07:34:34,528:INFO:         statsmodels: 0.14.0
2023-08-10 07:34:34,528:INFO:              sktime: 0.20.1
2023-08-10 07:34:34,528:INFO:               tbats: 1.1.3
2023-08-10 07:34:34,528:INFO:            pmdarima: 2.0.3
2023-08-10 07:34:34,528:INFO:              psutil: 5.9.5
2023-08-10 07:34:34,528:INFO:          markupsafe: 2.1.3
2023-08-10 07:34:34,528:INFO:             pickle5: Not installed
2023-08-10 07:34:34,528:INFO:         cloudpickle: 2.2.1
2023-08-10 07:34:34,529:INFO:         deprecation: 2.1.0
2023-08-10 07:34:34,529:INFO:              xxhash: 3.2.0
2023-08-10 07:34:34,529:INFO:           wurlitzer: Not installed
2023-08-10 07:34:34,529:INFO:PyCaret optional dependencies:
2023-08-10 07:34:34,529:INFO:                shap: Not installed
2023-08-10 07:34:34,529:INFO:           interpret: 0.4.2
2023-08-10 07:34:34,530:INFO:                umap: 0.5.3
2023-08-10 07:34:34,530:INFO:    pandas_profiling: Not installed
2023-08-10 07:34:34,530:INFO:  explainerdashboard: Not installed
2023-08-10 07:34:34,530:INFO:             autoviz: Not installed
2023-08-10 07:34:34,530:INFO:           fairlearn: Not installed
2023-08-10 07:34:34,530:INFO:          deepchecks: Not installed
2023-08-10 07:34:34,530:INFO:             xgboost: 1.7.6
2023-08-10 07:34:34,531:INFO:            catboost: Not installed
2023-08-10 07:34:34,531:INFO:              kmodes: Not installed
2023-08-10 07:34:34,531:INFO:             mlxtend: 0.22.0
2023-08-10 07:34:34,531:INFO:       statsforecast: Not installed
2023-08-10 07:34:34,531:INFO:        tune_sklearn: Not installed
2023-08-10 07:34:34,531:INFO:                 ray: Not installed
2023-08-10 07:34:34,532:INFO:            hyperopt: Not installed
2023-08-10 07:34:34,532:INFO:              optuna: Not installed
2023-08-10 07:34:34,532:INFO:               skopt: Not installed
2023-08-10 07:34:34,532:INFO:              mlflow: 2.4.2
2023-08-10 07:34:34,532:INFO:              gradio: Not installed
2023-08-10 07:34:34,532:INFO:             fastapi: Not installed
2023-08-10 07:34:34,533:INFO:             uvicorn: Not installed
2023-08-10 07:34:34,533:INFO:              m2cgen: Not installed
2023-08-10 07:34:34,533:INFO:           evidently: Not installed
2023-08-10 07:34:34,533:INFO:               fugue: Not installed
2023-08-10 07:34:34,536:INFO:           streamlit: 1.25.0
2023-08-10 07:34:34,537:INFO:             prophet: Not installed
2023-08-10 07:34:34,537:INFO:None
2023-08-10 07:34:34,538:INFO:Set up data.
2023-08-10 07:34:34,565:INFO:Set up train/test split.
2023-08-10 07:34:34,611:INFO:Set up index.
2023-08-10 07:34:34,612:INFO:Set up folding strategy.
2023-08-10 07:34:34,612:INFO:Assigning column types.
2023-08-10 07:34:34,630:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 07:34:34,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 07:34:34,945:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:34:35,245:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:35,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:35,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 07:34:35,515:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:34:35,700:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:35,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:35,722:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 07:34:36,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:34:36,223:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:36,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:36,747:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 07:34:36,922:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:36,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:36,933:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 07:34:37,355:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:37,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:37,677:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:37,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:37,701:INFO:Preparing preprocessing pipeline...
2023-08-10 07:34:37,705:INFO:Set up simple imputation.
2023-08-10 07:34:37,714:INFO:Set up encoding of categorical features.
2023-08-10 07:34:37,715:INFO:Set up removing outliers.
2023-08-10 07:34:38,025:INFO:Finished creating preprocessing pipeline.
2023-08-10 07:34:38,047:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=2570,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 07:34:38,047:INFO:Creating final display dataframe.
2023-08-10 07:34:43,308:INFO:Setup _display_container:                     Description             Value
0                    Session id              2570
1                        Target             Churn
2                   Target type            Binary
3           Original data shape        (3941, 11)
4        Transformed data shape        (3804, 18)
5   Transformed train set shape        (2621, 18)
6    Transformed test set shape        (1183, 18)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values             14.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              5dec
2023-08-10 07:34:43,662:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:43,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:43,949:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 07:34:43,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 07:34:43,961:INFO:setup() successfully completed in 14.66s...............
2023-08-10 07:35:11,264:INFO:Initializing get_config()
2023-08-10 07:35:11,264:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A4441E6E80>, variable=pipeline)
2023-08-10 07:35:11,295:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=2570,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 07:35:11,295:INFO:get_config() successfully completed......................................
2023-08-10 07:40:56,023:INFO:Initializing get_config()
2023-08-10 07:40:56,024:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A4441E6E80>, variable=pipeline)
2023-08-10 07:40:56,051:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=2570,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 07:40:56,051:INFO:get_config() successfully completed......................................
2023-08-10 07:44:37,030:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:44:37,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:44:37,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:44:37,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:46:12,724:INFO:PyCaret AnomalyExperiment
2023-08-10 07:46:12,725:INFO:Logging name: anomaly-default-name
2023-08-10 07:46:12,725:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 07:46:12,725:INFO:version 3.0.4
2023-08-10 07:46:12,725:INFO:Initializing setup()
2023-08-10 07:46:12,725:INFO:self.USI: 389a
2023-08-10 07:46:12,725:INFO:self._variable_keys: {'_available_plots', 'pipeline', 'exp_id', 'data', 'idx', 'exp_name_log', 'html_param', 'memory', 'gpu_param', '_ml_usecase', 'log_plots_param', 'seed', 'logging_param', 'n_jobs_param', 'USI', 'X', 'gpu_n_jobs_param'}
2023-08-10 07:46:12,726:INFO:Checking environment
2023-08-10 07:46:12,726:INFO:python_version: 3.9.13
2023-08-10 07:46:12,726:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 07:46:12,726:INFO:machine: AMD64
2023-08-10 07:46:12,726:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 07:46:12,739:INFO:Memory: svmem(total=7480111104, available=879513600, percent=88.2, used=6600597504, free=879513600)
2023-08-10 07:46:12,739:INFO:Physical Core: 4
2023-08-10 07:46:12,739:INFO:Logical Core: 4
2023-08-10 07:46:12,739:INFO:Checking libraries
2023-08-10 07:46:12,739:INFO:System:
2023-08-10 07:46:12,740:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 07:46:12,740:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 07:46:12,740:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 07:46:12,740:INFO:PyCaret required dependencies:
2023-08-10 07:46:13,003:INFO:                 pip: 23.1.2
2023-08-10 07:46:13,003:INFO:          setuptools: 58.1.0
2023-08-10 07:46:13,003:INFO:             pycaret: 3.0.4
2023-08-10 07:46:13,004:INFO:             IPython: 8.13.2
2023-08-10 07:46:13,004:INFO:          ipywidgets: 8.0.7
2023-08-10 07:46:13,004:INFO:                tqdm: 4.65.0
2023-08-10 07:46:13,004:INFO:               numpy: 1.23.5
2023-08-10 07:46:13,004:INFO:              pandas: 1.5.3
2023-08-10 07:46:13,004:INFO:              jinja2: 3.1.2
2023-08-10 07:46:13,004:INFO:               scipy: 1.10.1
2023-08-10 07:46:13,004:INFO:              joblib: 1.2.0
2023-08-10 07:46:13,005:INFO:             sklearn: 1.2.2
2023-08-10 07:46:13,005:INFO:                pyod: 1.1.0
2023-08-10 07:46:13,005:INFO:            imblearn: 0.11.0
2023-08-10 07:46:13,005:INFO:   category_encoders: 2.6.1
2023-08-10 07:46:13,005:INFO:            lightgbm: 4.0.0
2023-08-10 07:46:13,005:INFO:               numba: 0.57.1
2023-08-10 07:46:13,005:INFO:            requests: 2.31.0
2023-08-10 07:46:13,005:INFO:          matplotlib: 3.7.1
2023-08-10 07:46:13,005:INFO:          scikitplot: 0.3.7
2023-08-10 07:46:13,006:INFO:         yellowbrick: 1.5
2023-08-10 07:46:13,006:INFO:              plotly: 5.15.0
2023-08-10 07:46:13,006:INFO:    plotly-resampler: Not installed
2023-08-10 07:46:13,006:INFO:             kaleido: 0.2.1
2023-08-10 07:46:13,006:INFO:           schemdraw: 0.15
2023-08-10 07:46:13,007:INFO:         statsmodels: 0.14.0
2023-08-10 07:46:13,007:INFO:              sktime: 0.20.1
2023-08-10 07:46:13,007:INFO:               tbats: 1.1.3
2023-08-10 07:46:13,007:INFO:            pmdarima: 2.0.3
2023-08-10 07:46:13,007:INFO:              psutil: 5.9.5
2023-08-10 07:46:13,007:INFO:          markupsafe: 2.1.3
2023-08-10 07:46:13,007:INFO:             pickle5: Not installed
2023-08-10 07:46:13,007:INFO:         cloudpickle: 2.2.1
2023-08-10 07:46:13,008:INFO:         deprecation: 2.1.0
2023-08-10 07:46:13,008:INFO:              xxhash: 3.2.0
2023-08-10 07:46:13,008:INFO:           wurlitzer: Not installed
2023-08-10 07:46:13,008:INFO:PyCaret optional dependencies:
2023-08-10 07:46:13,067:INFO:                shap: Not installed
2023-08-10 07:46:13,067:INFO:           interpret: 0.4.2
2023-08-10 07:46:13,067:INFO:                umap: 0.5.3
2023-08-10 07:46:13,068:INFO:    pandas_profiling: Not installed
2023-08-10 07:46:13,068:INFO:  explainerdashboard: Not installed
2023-08-10 07:46:13,068:INFO:             autoviz: Not installed
2023-08-10 07:46:13,068:INFO:           fairlearn: Not installed
2023-08-10 07:46:13,068:INFO:          deepchecks: Not installed
2023-08-10 07:46:13,068:INFO:             xgboost: 1.7.6
2023-08-10 07:46:13,068:INFO:            catboost: Not installed
2023-08-10 07:46:13,068:INFO:              kmodes: Not installed
2023-08-10 07:46:13,068:INFO:             mlxtend: 0.22.0
2023-08-10 07:46:13,069:INFO:       statsforecast: Not installed
2023-08-10 07:46:13,069:INFO:        tune_sklearn: Not installed
2023-08-10 07:46:13,069:INFO:                 ray: Not installed
2023-08-10 07:46:13,069:INFO:            hyperopt: Not installed
2023-08-10 07:46:13,069:INFO:              optuna: Not installed
2023-08-10 07:46:13,069:INFO:               skopt: Not installed
2023-08-10 07:46:13,069:INFO:              mlflow: 2.4.2
2023-08-10 07:46:13,069:INFO:              gradio: Not installed
2023-08-10 07:46:13,069:INFO:             fastapi: Not installed
2023-08-10 07:46:13,070:INFO:             uvicorn: Not installed
2023-08-10 07:46:13,070:INFO:              m2cgen: Not installed
2023-08-10 07:46:13,070:INFO:           evidently: Not installed
2023-08-10 07:46:13,070:INFO:               fugue: Not installed
2023-08-10 07:46:13,070:INFO:           streamlit: 1.25.0
2023-08-10 07:46:13,070:INFO:             prophet: Not installed
2023-08-10 07:46:13,070:INFO:None
2023-08-10 07:46:13,071:INFO:Set up data.
2023-08-10 07:46:13,092:INFO:Set up index.
2023-08-10 07:46:13,092:INFO:Assigning column types.
2023-08-10 07:46:13,103:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 07:46:15,835:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 07:46:15,841:INFO:Preparing preprocessing pipeline...
2023-08-10 07:46:15,841:INFO:Set up simple imputation.
2023-08-10 07:46:15,850:INFO:Set up encoding of categorical features.
2023-08-10 07:46:16,005:INFO:Finished creating preprocessing pipeline.
2023-08-10 07:46:16,032:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 07:46:16,033:INFO:Creating final display dataframe.
2023-08-10 07:46:16,088:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   810
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 18)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  389a
2023-08-10 07:46:16,090:INFO:setup() successfully completed in 8.22s...............
2023-08-10 07:46:16,090:INFO:Initializing create_model()
2023-08-10 07:46:16,091:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E878828BE0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 07:46:16,091:INFO:Checking exceptions
2023-08-10 07:46:16,138:INFO:Importing untrained model
2023-08-10 07:46:16,140:INFO:Isolation Forest Imported successfully
2023-08-10 07:46:16,144:INFO:Fitting Model
2023-08-10 07:46:18,504:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=810, verbose=0)
2023-08-10 07:46:18,504:INFO:create_models() successfully completed......................................
2023-08-10 07:46:18,505:INFO:Uploading results into container
2023-08-10 07:46:18,505:INFO:Uploading model into container now
2023-08-10 07:46:18,505:INFO:_master_model_container: 1
2023-08-10 07:46:18,505:INFO:_display_container: 1
2023-08-10 07:46:18,506:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=810, verbose=0)
2023-08-10 07:46:18,507:INFO:create_model() successfully completed......................................
2023-08-10 07:46:20,805:INFO:Initializing plot_model()
2023-08-10 07:46:20,805:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=810, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E878828BE0>, system=True)
2023-08-10 07:46:20,806:INFO:Checking exceptions
2023-08-10 07:46:29,431:INFO:Preloading libraries
2023-08-10 07:46:29,465:INFO:Copying training dataset
2023-08-10 07:46:29,466:INFO:Plot type: umap
2023-08-10 07:46:29,467:INFO:SubProcess assign_model() called ==================================
2023-08-10 07:46:29,468:INFO:Initializing assign_model()
2023-08-10 07:46:29,468:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E878828BE0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=810, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 07:46:29,469:INFO:Checking exceptions
2023-08-10 07:46:29,469:INFO:Determining Trained Model
2023-08-10 07:46:29,469:INFO:Trained Model : Isolation Forest
2023-08-10 07:46:29,470:INFO:Copying data
2023-08-10 07:46:29,509:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 07:46:29,510:INFO:(3941, 19)
2023-08-10 07:46:29,510:INFO:assign_model() successfully completed......................................
2023-08-10 07:46:29,511:INFO:SubProcess assign_model() end ==================================
2023-08-10 07:46:29,518:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 07:46:45,722:INFO:Fitting UMAP()
2023-08-10 07:47:43,189:INFO:Rendering Visual
2023-08-10 07:47:47,675:INFO:Visual Rendered Successfully
2023-08-10 07:47:48,391:INFO:plot_model() successfully completed......................................
2023-08-10 07:47:53,699:INFO:Initializing assign_model()
2023-08-10 07:47:53,700:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E878828BE0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=810, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 07:47:53,700:INFO:Checking exceptions
2023-08-10 07:47:53,700:INFO:Determining Trained Model
2023-08-10 07:47:53,701:INFO:Trained Model : Isolation Forest
2023-08-10 07:47:53,701:INFO:Copying data
2023-08-10 07:47:53,710:INFO:(3941, 13)
2023-08-10 07:47:53,710:INFO:assign_model() successfully completed......................................
2023-08-10 07:49:03,445:INFO:Initializing get_config()
2023-08-10 07:49:03,446:INFO:get_config(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E878828BE0>, variable=pipeline)
2023-08-10 07:49:03,473:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 07:49:03,474:INFO:get_config() successfully completed......................................
2023-08-10 07:49:48,793:INFO:Initializing get_config()
2023-08-10 07:49:48,794:INFO:get_config(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E878828BE0>, variable=pipeline)
2023-08-10 07:49:48,819:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 07:49:48,820:INFO:get_config() successfully completed......................................
2023-08-10 07:50:19,784:INFO:Initializing assign_model()
2023-08-10 07:50:19,785:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E878828BE0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=810, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 07:50:19,785:INFO:Checking exceptions
2023-08-10 07:50:19,786:INFO:Determining Trained Model
2023-08-10 07:50:19,787:INFO:Trained Model : Isolation Forest
2023-08-10 07:50:19,788:INFO:Copying data
2023-08-10 07:50:19,793:INFO:(3941, 13)
2023-08-10 07:50:19,793:INFO:assign_model() successfully completed......................................
2023-08-10 07:54:32,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:54:32,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:54:32,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:54:32,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 07:55:58,957:INFO:PyCaret AnomalyExperiment
2023-08-10 07:55:58,957:INFO:Logging name: anomaly-default-name
2023-08-10 07:55:58,957:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 07:55:58,957:INFO:version 3.0.4
2023-08-10 07:55:58,957:INFO:Initializing setup()
2023-08-10 07:55:58,958:INFO:self.USI: 2361
2023-08-10 07:55:58,958:INFO:self._variable_keys: {'data', 'html_param', 'log_plots_param', 'exp_name_log', 'idx', 'gpu_n_jobs_param', 'X', 'memory', '_ml_usecase', 'pipeline', 'USI', 'logging_param', 'n_jobs_param', 'gpu_param', 'exp_id', '_available_plots', 'seed'}
2023-08-10 07:55:58,958:INFO:Checking environment
2023-08-10 07:55:58,958:INFO:python_version: 3.9.13
2023-08-10 07:55:58,958:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 07:55:58,958:INFO:machine: AMD64
2023-08-10 07:55:58,958:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 07:55:58,966:INFO:Memory: svmem(total=7480111104, available=1003032576, percent=86.6, used=6477078528, free=1003032576)
2023-08-10 07:55:58,967:INFO:Physical Core: 4
2023-08-10 07:55:58,968:INFO:Logical Core: 4
2023-08-10 07:55:58,968:INFO:Checking libraries
2023-08-10 07:55:58,968:INFO:System:
2023-08-10 07:55:58,969:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 07:55:58,969:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 07:55:58,969:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 07:55:58,969:INFO:PyCaret required dependencies:
2023-08-10 07:55:59,162:INFO:                 pip: 23.1.2
2023-08-10 07:55:59,162:INFO:          setuptools: 58.1.0
2023-08-10 07:55:59,162:INFO:             pycaret: 3.0.4
2023-08-10 07:55:59,162:INFO:             IPython: 8.13.2
2023-08-10 07:55:59,163:INFO:          ipywidgets: 8.0.7
2023-08-10 07:55:59,163:INFO:                tqdm: 4.65.0
2023-08-10 07:55:59,163:INFO:               numpy: 1.23.5
2023-08-10 07:55:59,163:INFO:              pandas: 1.5.3
2023-08-10 07:55:59,163:INFO:              jinja2: 3.1.2
2023-08-10 07:55:59,163:INFO:               scipy: 1.10.1
2023-08-10 07:55:59,163:INFO:              joblib: 1.2.0
2023-08-10 07:55:59,163:INFO:             sklearn: 1.2.2
2023-08-10 07:55:59,163:INFO:                pyod: 1.1.0
2023-08-10 07:55:59,164:INFO:            imblearn: 0.11.0
2023-08-10 07:55:59,164:INFO:   category_encoders: 2.6.1
2023-08-10 07:55:59,164:INFO:            lightgbm: 4.0.0
2023-08-10 07:55:59,164:INFO:               numba: 0.57.1
2023-08-10 07:55:59,164:INFO:            requests: 2.31.0
2023-08-10 07:55:59,164:INFO:          matplotlib: 3.7.1
2023-08-10 07:55:59,164:INFO:          scikitplot: 0.3.7
2023-08-10 07:55:59,165:INFO:         yellowbrick: 1.5
2023-08-10 07:55:59,165:INFO:              plotly: 5.15.0
2023-08-10 07:55:59,165:INFO:    plotly-resampler: Not installed
2023-08-10 07:55:59,165:INFO:             kaleido: 0.2.1
2023-08-10 07:55:59,165:INFO:           schemdraw: 0.15
2023-08-10 07:55:59,165:INFO:         statsmodels: 0.14.0
2023-08-10 07:55:59,165:INFO:              sktime: 0.20.1
2023-08-10 07:55:59,165:INFO:               tbats: 1.1.3
2023-08-10 07:55:59,165:INFO:            pmdarima: 2.0.3
2023-08-10 07:55:59,165:INFO:              psutil: 5.9.5
2023-08-10 07:55:59,168:INFO:          markupsafe: 2.1.3
2023-08-10 07:55:59,168:INFO:             pickle5: Not installed
2023-08-10 07:55:59,168:INFO:         cloudpickle: 2.2.1
2023-08-10 07:55:59,168:INFO:         deprecation: 2.1.0
2023-08-10 07:55:59,168:INFO:              xxhash: 3.2.0
2023-08-10 07:55:59,169:INFO:           wurlitzer: Not installed
2023-08-10 07:55:59,169:INFO:PyCaret optional dependencies:
2023-08-10 07:55:59,209:INFO:                shap: Not installed
2023-08-10 07:55:59,210:INFO:           interpret: 0.4.2
2023-08-10 07:55:59,210:INFO:                umap: 0.5.3
2023-08-10 07:55:59,210:INFO:    pandas_profiling: Not installed
2023-08-10 07:55:59,210:INFO:  explainerdashboard: Not installed
2023-08-10 07:55:59,210:INFO:             autoviz: Not installed
2023-08-10 07:55:59,210:INFO:           fairlearn: Not installed
2023-08-10 07:55:59,210:INFO:          deepchecks: Not installed
2023-08-10 07:55:59,210:INFO:             xgboost: 1.7.6
2023-08-10 07:55:59,210:INFO:            catboost: Not installed
2023-08-10 07:55:59,210:INFO:              kmodes: Not installed
2023-08-10 07:55:59,211:INFO:             mlxtend: 0.22.0
2023-08-10 07:55:59,211:INFO:       statsforecast: Not installed
2023-08-10 07:55:59,211:INFO:        tune_sklearn: Not installed
2023-08-10 07:55:59,211:INFO:                 ray: Not installed
2023-08-10 07:55:59,211:INFO:            hyperopt: Not installed
2023-08-10 07:55:59,211:INFO:              optuna: Not installed
2023-08-10 07:55:59,211:INFO:               skopt: Not installed
2023-08-10 07:55:59,211:INFO:              mlflow: 2.4.2
2023-08-10 07:55:59,211:INFO:              gradio: Not installed
2023-08-10 07:55:59,212:INFO:             fastapi: Not installed
2023-08-10 07:55:59,212:INFO:             uvicorn: Not installed
2023-08-10 07:55:59,212:INFO:              m2cgen: Not installed
2023-08-10 07:55:59,212:INFO:           evidently: Not installed
2023-08-10 07:55:59,212:INFO:               fugue: Not installed
2023-08-10 07:55:59,212:INFO:           streamlit: 1.25.0
2023-08-10 07:55:59,212:INFO:             prophet: Not installed
2023-08-10 07:55:59,212:INFO:None
2023-08-10 07:55:59,213:INFO:Set up data.
2023-08-10 07:55:59,231:INFO:Set up index.
2023-08-10 07:55:59,231:INFO:Assigning column types.
2023-08-10 07:55:59,241:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 07:56:01,561:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 07:56:01,572:INFO:Preparing preprocessing pipeline...
2023-08-10 07:56:01,572:INFO:Set up simple imputation.
2023-08-10 07:56:01,579:INFO:Set up encoding of categorical features.
2023-08-10 07:56:01,765:INFO:Finished creating preprocessing pipeline.
2023-08-10 07:56:01,805:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 07:56:01,806:INFO:Creating final display dataframe.
2023-08-10 07:56:01,894:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   286
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 18)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  2361
2023-08-10 07:56:01,897:INFO:setup() successfully completed in 6.61s...............
2023-08-10 07:56:01,898:INFO:Initializing create_model()
2023-08-10 07:56:01,898:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001FF5EA6EC70>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 07:56:01,899:INFO:Checking exceptions
2023-08-10 07:56:01,977:INFO:Importing untrained model
2023-08-10 07:56:01,979:INFO:Isolation Forest Imported successfully
2023-08-10 07:56:01,988:INFO:Fitting Model
2023-08-10 07:56:04,247:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=286, verbose=0)
2023-08-10 07:56:04,247:INFO:create_models() successfully completed......................................
2023-08-10 07:56:04,247:INFO:Uploading results into container
2023-08-10 07:56:04,247:INFO:Uploading model into container now
2023-08-10 07:56:04,248:INFO:_master_model_container: 1
2023-08-10 07:56:04,248:INFO:_display_container: 1
2023-08-10 07:56:04,252:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=286, verbose=0)
2023-08-10 07:56:04,254:INFO:create_model() successfully completed......................................
2023-08-10 07:56:06,630:INFO:Initializing plot_model()
2023-08-10 07:56:06,631:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=286, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001FF5EA6EC70>, system=True)
2023-08-10 07:56:06,631:INFO:Checking exceptions
2023-08-10 07:56:14,273:INFO:Preloading libraries
2023-08-10 07:56:14,310:INFO:Copying training dataset
2023-08-10 07:56:14,311:INFO:Plot type: umap
2023-08-10 07:56:14,313:INFO:SubProcess assign_model() called ==================================
2023-08-10 07:56:14,314:INFO:Initializing assign_model()
2023-08-10 07:56:14,316:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001FF5EA6EC70>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=286, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 07:56:14,317:INFO:Checking exceptions
2023-08-10 07:56:14,317:INFO:Determining Trained Model
2023-08-10 07:56:14,318:INFO:Trained Model : Isolation Forest
2023-08-10 07:56:14,318:INFO:Copying data
2023-08-10 07:56:14,357:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 07:56:14,358:INFO:(3941, 19)
2023-08-10 07:56:14,359:INFO:assign_model() successfully completed......................................
2023-08-10 07:56:14,359:INFO:SubProcess assign_model() end ==================================
2023-08-10 07:56:14,363:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 07:56:39,073:INFO:Fitting UMAP()
2023-08-10 07:57:40,430:INFO:Rendering Visual
2023-08-10 07:57:44,117:INFO:Visual Rendered Successfully
2023-08-10 07:57:44,445:INFO:plot_model() successfully completed......................................
2023-08-10 08:03:13,048:INFO:PyCaret AnomalyExperiment
2023-08-10 08:03:13,049:INFO:Logging name: anomaly-default-name
2023-08-10 08:03:13,049:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 08:03:13,049:INFO:version 3.0.4
2023-08-10 08:03:13,049:INFO:Initializing setup()
2023-08-10 08:03:13,049:INFO:self.USI: 1b95
2023-08-10 08:03:13,049:INFO:self._variable_keys: {'data', 'html_param', 'log_plots_param', 'exp_name_log', 'idx', 'gpu_n_jobs_param', 'X', 'memory', '_ml_usecase', 'pipeline', 'USI', 'logging_param', 'n_jobs_param', 'gpu_param', 'exp_id', '_available_plots', 'seed'}
2023-08-10 08:03:13,050:INFO:Checking environment
2023-08-10 08:03:13,050:INFO:python_version: 3.9.13
2023-08-10 08:03:13,050:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 08:03:13,050:INFO:machine: AMD64
2023-08-10 08:03:13,050:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 08:03:13,072:INFO:Memory: svmem(total=7480111104, available=590520320, percent=92.1, used=6889590784, free=590520320)
2023-08-10 08:03:13,073:INFO:Physical Core: 4
2023-08-10 08:03:13,073:INFO:Logical Core: 4
2023-08-10 08:03:13,073:INFO:Checking libraries
2023-08-10 08:03:13,073:INFO:System:
2023-08-10 08:03:13,073:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 08:03:13,073:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 08:03:13,074:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 08:03:13,074:INFO:PyCaret required dependencies:
2023-08-10 08:03:13,074:INFO:                 pip: 23.1.2
2023-08-10 08:03:13,074:INFO:          setuptools: 58.1.0
2023-08-10 08:03:13,074:INFO:             pycaret: 3.0.4
2023-08-10 08:03:13,075:INFO:             IPython: 8.13.2
2023-08-10 08:03:13,075:INFO:          ipywidgets: 8.0.7
2023-08-10 08:03:13,075:INFO:                tqdm: 4.65.0
2023-08-10 08:03:13,075:INFO:               numpy: 1.23.5
2023-08-10 08:03:13,075:INFO:              pandas: 1.5.3
2023-08-10 08:03:13,075:INFO:              jinja2: 3.1.2
2023-08-10 08:03:13,075:INFO:               scipy: 1.10.1
2023-08-10 08:03:13,075:INFO:              joblib: 1.2.0
2023-08-10 08:03:13,076:INFO:             sklearn: 1.2.2
2023-08-10 08:03:13,076:INFO:                pyod: 1.1.0
2023-08-10 08:03:13,076:INFO:            imblearn: 0.11.0
2023-08-10 08:03:13,078:INFO:   category_encoders: 2.6.1
2023-08-10 08:03:13,079:INFO:            lightgbm: 4.0.0
2023-08-10 08:03:13,080:INFO:               numba: 0.57.1
2023-08-10 08:03:13,080:INFO:            requests: 2.31.0
2023-08-10 08:03:13,080:INFO:          matplotlib: 3.7.1
2023-08-10 08:03:13,080:INFO:          scikitplot: 0.3.7
2023-08-10 08:03:13,080:INFO:         yellowbrick: 1.5
2023-08-10 08:03:13,080:INFO:              plotly: 5.15.0
2023-08-10 08:03:13,081:INFO:    plotly-resampler: Not installed
2023-08-10 08:03:13,081:INFO:             kaleido: 0.2.1
2023-08-10 08:03:13,081:INFO:           schemdraw: 0.15
2023-08-10 08:03:13,081:INFO:         statsmodels: 0.14.0
2023-08-10 08:03:13,081:INFO:              sktime: 0.20.1
2023-08-10 08:03:13,081:INFO:               tbats: 1.1.3
2023-08-10 08:03:13,081:INFO:            pmdarima: 2.0.3
2023-08-10 08:03:13,082:INFO:              psutil: 5.9.5
2023-08-10 08:03:13,082:INFO:          markupsafe: 2.1.3
2023-08-10 08:03:13,082:INFO:             pickle5: Not installed
2023-08-10 08:03:13,083:INFO:         cloudpickle: 2.2.1
2023-08-10 08:03:13,083:INFO:         deprecation: 2.1.0
2023-08-10 08:03:13,083:INFO:              xxhash: 3.2.0
2023-08-10 08:03:13,083:INFO:           wurlitzer: Not installed
2023-08-10 08:03:13,083:INFO:PyCaret optional dependencies:
2023-08-10 08:03:13,084:INFO:                shap: Not installed
2023-08-10 08:03:13,084:INFO:           interpret: 0.4.2
2023-08-10 08:03:13,084:INFO:                umap: 0.5.3
2023-08-10 08:03:13,084:INFO:    pandas_profiling: Not installed
2023-08-10 08:03:13,084:INFO:  explainerdashboard: Not installed
2023-08-10 08:03:13,084:INFO:             autoviz: Not installed
2023-08-10 08:03:13,084:INFO:           fairlearn: Not installed
2023-08-10 08:03:13,085:INFO:          deepchecks: Not installed
2023-08-10 08:03:13,085:INFO:             xgboost: 1.7.6
2023-08-10 08:03:13,085:INFO:            catboost: Not installed
2023-08-10 08:03:13,085:INFO:              kmodes: Not installed
2023-08-10 08:03:13,085:INFO:             mlxtend: 0.22.0
2023-08-10 08:03:13,085:INFO:       statsforecast: Not installed
2023-08-10 08:03:13,085:INFO:        tune_sklearn: Not installed
2023-08-10 08:03:13,086:INFO:                 ray: Not installed
2023-08-10 08:03:13,086:INFO:            hyperopt: Not installed
2023-08-10 08:03:13,086:INFO:              optuna: Not installed
2023-08-10 08:03:13,086:INFO:               skopt: Not installed
2023-08-10 08:03:13,086:INFO:              mlflow: 2.4.2
2023-08-10 08:03:13,086:INFO:              gradio: Not installed
2023-08-10 08:03:13,086:INFO:             fastapi: Not installed
2023-08-10 08:03:13,086:INFO:             uvicorn: Not installed
2023-08-10 08:03:13,087:INFO:              m2cgen: Not installed
2023-08-10 08:03:13,087:INFO:           evidently: Not installed
2023-08-10 08:03:13,087:INFO:               fugue: Not installed
2023-08-10 08:03:13,087:INFO:           streamlit: 1.25.0
2023-08-10 08:03:13,087:INFO:             prophet: Not installed
2023-08-10 08:03:13,087:INFO:None
2023-08-10 08:03:13,088:INFO:Set up data.
2023-08-10 08:03:13,139:INFO:Set up index.
2023-08-10 08:03:13,140:INFO:Assigning column types.
2023-08-10 08:03:13,158:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 08:03:13,163:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 08:03:13,168:INFO:Preparing preprocessing pipeline...
2023-08-10 08:03:13,168:INFO:Set up simple imputation.
2023-08-10 08:03:13,174:INFO:Set up encoding of categorical features.
2023-08-10 08:03:13,432:INFO:Finished creating preprocessing pipeline.
2023-08-10 08:03:13,457:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 08:03:13,457:INFO:Creating final display dataframe.
2023-08-10 08:03:13,725:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  5123
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  1b95
2023-08-10 08:03:13,730:INFO:setup() successfully completed in 2.82s...............
2023-08-10 08:03:15,554:INFO:Initializing create_model()
2023-08-10 08:03:15,554:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001FF5E377190>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 08:03:15,555:INFO:Checking exceptions
2023-08-10 08:03:15,634:INFO:Importing untrained model
2023-08-10 08:03:15,636:INFO:Isolation Forest Imported successfully
2023-08-10 08:03:15,639:INFO:Fitting Model
2023-08-10 08:03:17,892:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=5123, verbose=0)
2023-08-10 08:03:17,892:INFO:create_models() successfully completed......................................
2023-08-10 08:03:17,892:INFO:Uploading results into container
2023-08-10 08:03:17,892:INFO:Uploading model into container now
2023-08-10 08:03:17,895:INFO:_master_model_container: 1
2023-08-10 08:03:17,896:INFO:_display_container: 1
2023-08-10 08:03:17,897:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=5123, verbose=0)
2023-08-10 08:03:17,897:INFO:create_model() successfully completed......................................
2023-08-10 08:03:20,079:INFO:Initializing plot_model()
2023-08-10 08:03:20,080:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=5123, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001FF5E377190>, system=True)
2023-08-10 08:03:20,080:INFO:Checking exceptions
2023-08-10 08:03:26,973:INFO:Preloading libraries
2023-08-10 08:03:27,014:INFO:Copying training dataset
2023-08-10 08:03:27,014:INFO:Plot type: umap
2023-08-10 08:03:27,015:INFO:SubProcess assign_model() called ==================================
2023-08-10 08:03:27,017:INFO:Initializing assign_model()
2023-08-10 08:03:27,017:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001FF5E377190>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=5123, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 08:03:27,017:INFO:Checking exceptions
2023-08-10 08:03:27,018:INFO:Determining Trained Model
2023-08-10 08:03:27,018:INFO:Trained Model : Isolation Forest
2023-08-10 08:03:27,019:INFO:Copying data
2023-08-10 08:03:27,055:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 08:03:27,057:INFO:(3941, 18)
2023-08-10 08:03:27,057:INFO:assign_model() successfully completed......................................
2023-08-10 08:03:27,058:INFO:SubProcess assign_model() end ==================================
2023-08-10 08:03:27,069:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 08:03:27,071:INFO:Fitting UMAP()
2023-08-10 08:04:07,467:INFO:Rendering Visual
2023-08-10 08:04:07,665:INFO:Visual Rendered Successfully
2023-08-10 08:04:08,106:INFO:plot_model() successfully completed......................................
2023-08-10 08:04:18,688:INFO:Initializing assign_model()
2023-08-10 08:04:18,688:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001FF5E377190>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=5123, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 08:04:18,689:INFO:Checking exceptions
2023-08-10 08:04:18,690:INFO:Determining Trained Model
2023-08-10 08:04:18,691:INFO:Trained Model : Isolation Forest
2023-08-10 08:04:18,692:INFO:Copying data
2023-08-10 08:04:18,698:INFO:(3941, 13)
2023-08-10 08:04:18,699:INFO:assign_model() successfully completed......................................
2023-08-10 08:18:10,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 08:18:10,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 08:18:10,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 08:18:10,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 08:27:11,788:INFO:PyCaret AnomalyExperiment
2023-08-10 08:27:11,789:INFO:Logging name: anomaly-default-name
2023-08-10 08:27:11,789:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 08:27:11,789:INFO:version 3.0.4
2023-08-10 08:27:11,789:INFO:Initializing setup()
2023-08-10 08:27:11,789:INFO:self.USI: 07f1
2023-08-10 08:27:11,789:INFO:self._variable_keys: {'gpu_n_jobs_param', '_available_plots', 'pipeline', 'memory', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'seed', 'html_param', 'USI', 'n_jobs_param', 'logging_param', 'exp_id', 'X', 'data', 'gpu_param'}
2023-08-10 08:27:11,789:INFO:Checking environment
2023-08-10 08:27:11,790:INFO:python_version: 3.9.13
2023-08-10 08:27:11,790:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 08:27:11,790:INFO:machine: AMD64
2023-08-10 08:27:11,790:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 08:27:11,797:INFO:Memory: svmem(total=7480111104, available=1223323648, percent=83.6, used=6256787456, free=1223323648)
2023-08-10 08:27:11,797:INFO:Physical Core: 4
2023-08-10 08:27:11,797:INFO:Logical Core: 4
2023-08-10 08:27:11,798:INFO:Checking libraries
2023-08-10 08:27:11,798:INFO:System:
2023-08-10 08:27:11,798:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 08:27:11,798:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 08:27:11,798:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 08:27:11,798:INFO:PyCaret required dependencies:
2023-08-10 08:27:12,011:INFO:                 pip: 23.1.2
2023-08-10 08:27:12,011:INFO:          setuptools: 58.1.0
2023-08-10 08:27:12,012:INFO:             pycaret: 3.0.4
2023-08-10 08:27:12,012:INFO:             IPython: 8.13.2
2023-08-10 08:27:12,012:INFO:          ipywidgets: 8.0.7
2023-08-10 08:27:12,012:INFO:                tqdm: 4.65.0
2023-08-10 08:27:12,012:INFO:               numpy: 1.23.5
2023-08-10 08:27:12,012:INFO:              pandas: 1.5.3
2023-08-10 08:27:12,012:INFO:              jinja2: 3.1.2
2023-08-10 08:27:12,012:INFO:               scipy: 1.10.1
2023-08-10 08:27:12,012:INFO:              joblib: 1.2.0
2023-08-10 08:27:12,012:INFO:             sklearn: 1.2.2
2023-08-10 08:27:12,013:INFO:                pyod: 1.1.0
2023-08-10 08:27:12,013:INFO:            imblearn: 0.11.0
2023-08-10 08:27:12,013:INFO:   category_encoders: 2.6.1
2023-08-10 08:27:12,013:INFO:            lightgbm: 4.0.0
2023-08-10 08:27:12,013:INFO:               numba: 0.57.1
2023-08-10 08:27:12,013:INFO:            requests: 2.31.0
2023-08-10 08:27:12,013:INFO:          matplotlib: 3.7.1
2023-08-10 08:27:12,013:INFO:          scikitplot: 0.3.7
2023-08-10 08:27:12,013:INFO:         yellowbrick: 1.5
2023-08-10 08:27:12,013:INFO:              plotly: 5.15.0
2023-08-10 08:27:12,014:INFO:    plotly-resampler: Not installed
2023-08-10 08:27:12,014:INFO:             kaleido: 0.2.1
2023-08-10 08:27:12,014:INFO:           schemdraw: 0.15
2023-08-10 08:27:12,014:INFO:         statsmodels: 0.14.0
2023-08-10 08:27:12,014:INFO:              sktime: 0.20.1
2023-08-10 08:27:12,014:INFO:               tbats: 1.1.3
2023-08-10 08:27:12,014:INFO:            pmdarima: 2.0.3
2023-08-10 08:27:12,014:INFO:              psutil: 5.9.5
2023-08-10 08:27:12,014:INFO:          markupsafe: 2.1.3
2023-08-10 08:27:12,014:INFO:             pickle5: Not installed
2023-08-10 08:27:12,015:INFO:         cloudpickle: 2.2.1
2023-08-10 08:27:12,015:INFO:         deprecation: 2.1.0
2023-08-10 08:27:12,015:INFO:              xxhash: 3.2.0
2023-08-10 08:27:12,015:INFO:           wurlitzer: Not installed
2023-08-10 08:27:12,015:INFO:PyCaret optional dependencies:
2023-08-10 08:27:12,058:INFO:                shap: Not installed
2023-08-10 08:27:12,059:INFO:           interpret: 0.4.2
2023-08-10 08:27:12,059:INFO:                umap: 0.5.3
2023-08-10 08:27:12,059:INFO:    pandas_profiling: Not installed
2023-08-10 08:27:12,059:INFO:  explainerdashboard: Not installed
2023-08-10 08:27:12,059:INFO:             autoviz: Not installed
2023-08-10 08:27:12,059:INFO:           fairlearn: Not installed
2023-08-10 08:27:12,059:INFO:          deepchecks: Not installed
2023-08-10 08:27:12,060:INFO:             xgboost: 1.7.6
2023-08-10 08:27:12,060:INFO:            catboost: Not installed
2023-08-10 08:27:12,060:INFO:              kmodes: Not installed
2023-08-10 08:27:12,060:INFO:             mlxtend: 0.22.0
2023-08-10 08:27:12,060:INFO:       statsforecast: Not installed
2023-08-10 08:27:12,060:INFO:        tune_sklearn: Not installed
2023-08-10 08:27:12,060:INFO:                 ray: Not installed
2023-08-10 08:27:12,060:INFO:            hyperopt: Not installed
2023-08-10 08:27:12,060:INFO:              optuna: Not installed
2023-08-10 08:27:12,060:INFO:               skopt: Not installed
2023-08-10 08:27:12,061:INFO:              mlflow: 2.4.2
2023-08-10 08:27:12,061:INFO:              gradio: Not installed
2023-08-10 08:27:12,061:INFO:             fastapi: Not installed
2023-08-10 08:27:12,061:INFO:             uvicorn: Not installed
2023-08-10 08:27:12,061:INFO:              m2cgen: Not installed
2023-08-10 08:27:12,061:INFO:           evidently: Not installed
2023-08-10 08:27:12,061:INFO:               fugue: Not installed
2023-08-10 08:27:12,061:INFO:           streamlit: 1.25.0
2023-08-10 08:27:12,061:INFO:             prophet: Not installed
2023-08-10 08:27:12,061:INFO:None
2023-08-10 08:27:12,062:INFO:Set up data.
2023-08-10 08:27:12,086:INFO:Set up index.
2023-08-10 08:27:12,086:INFO:Assigning column types.
2023-08-10 08:27:12,093:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 08:27:14,206:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 08:27:14,212:INFO:Preparing preprocessing pipeline...
2023-08-10 08:27:14,213:INFO:Set up simple imputation.
2023-08-10 08:27:14,221:INFO:Set up encoding of categorical features.
2023-08-10 08:27:14,434:INFO:Finished creating preprocessing pipeline.
2023-08-10 08:27:14,461:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 08:27:14,462:INFO:Creating final display dataframe.
2023-08-10 08:27:14,514:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  8843
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  07f1
2023-08-10 08:27:14,519:INFO:setup() successfully completed in 6.06s...............
2023-08-10 08:27:14,520:INFO:Initializing create_model()
2023-08-10 08:27:14,520:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E6C1980A90>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 08:27:14,520:INFO:Checking exceptions
2023-08-10 08:27:14,560:INFO:Importing untrained model
2023-08-10 08:27:14,562:INFO:Isolation Forest Imported successfully
2023-08-10 08:27:14,566:INFO:Fitting Model
2023-08-10 08:27:16,820:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8843, verbose=0)
2023-08-10 08:27:16,820:INFO:create_models() successfully completed......................................
2023-08-10 08:27:16,820:INFO:Uploading results into container
2023-08-10 08:27:16,820:INFO:Uploading model into container now
2023-08-10 08:27:16,820:INFO:_master_model_container: 1
2023-08-10 08:27:16,821:INFO:_display_container: 1
2023-08-10 08:27:16,821:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8843, verbose=0)
2023-08-10 08:27:16,822:INFO:create_model() successfully completed......................................
2023-08-10 08:27:18,862:INFO:Initializing plot_model()
2023-08-10 08:27:18,862:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8843, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E6C1980A90>, system=True)
2023-08-10 08:27:18,862:INFO:Checking exceptions
2023-08-10 08:27:25,945:INFO:Preloading libraries
2023-08-10 08:27:25,986:INFO:Copying training dataset
2023-08-10 08:27:25,986:INFO:Plot type: umap
2023-08-10 08:27:25,987:INFO:SubProcess assign_model() called ==================================
2023-08-10 08:27:25,988:INFO:Initializing assign_model()
2023-08-10 08:27:25,988:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E6C1980A90>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8843, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 08:27:25,988:INFO:Checking exceptions
2023-08-10 08:27:25,989:INFO:Determining Trained Model
2023-08-10 08:27:25,989:INFO:Trained Model : Isolation Forest
2023-08-10 08:27:25,989:INFO:Copying data
2023-08-10 08:27:26,027:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 08:27:26,029:INFO:(3941, 18)
2023-08-10 08:27:26,029:INFO:assign_model() successfully completed......................................
2023-08-10 08:27:26,030:INFO:SubProcess assign_model() end ==================================
2023-08-10 08:27:26,038:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 08:27:41,563:INFO:Fitting UMAP()
2023-08-10 08:28:38,499:INFO:Rendering Visual
2023-08-10 08:28:42,059:INFO:Visual Rendered Successfully
2023-08-10 08:28:42,417:INFO:plot_model() successfully completed......................................
2023-08-10 08:28:51,803:INFO:Initializing assign_model()
2023-08-10 08:28:51,803:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000001E6C1980A90>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8843, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 08:28:51,804:INFO:Checking exceptions
2023-08-10 08:28:51,805:INFO:Determining Trained Model
2023-08-10 08:28:51,805:INFO:Trained Model : Isolation Forest
2023-08-10 08:28:51,806:INFO:Copying data
2023-08-10 08:28:51,812:INFO:(3941, 13)
2023-08-10 08:28:51,812:INFO:assign_model() successfully completed......................................
2023-08-10 09:01:23,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:01:23,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:01:23,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:01:23,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:01:54,154:INFO:PyCaret AnomalyExperiment
2023-08-10 09:01:54,154:INFO:Logging name: anomaly-default-name
2023-08-10 09:01:54,155:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 09:01:54,155:INFO:version 3.0.4
2023-08-10 09:01:54,155:INFO:Initializing setup()
2023-08-10 09:01:54,155:INFO:self.USI: 3b00
2023-08-10 09:01:54,155:INFO:self._variable_keys: {'_available_plots', 'USI', 'log_plots_param', '_ml_usecase', 'exp_id', 'idx', 'seed', 'html_param', 'gpu_param', 'X', 'logging_param', 'data', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_name_log', 'memory', 'pipeline'}
2023-08-10 09:01:54,155:INFO:Checking environment
2023-08-10 09:01:54,155:INFO:python_version: 3.9.13
2023-08-10 09:01:54,155:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 09:01:54,155:INFO:machine: AMD64
2023-08-10 09:01:54,156:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 09:01:54,165:INFO:Memory: svmem(total=7480111104, available=1191243776, percent=84.1, used=6288867328, free=1191243776)
2023-08-10 09:01:54,165:INFO:Physical Core: 4
2023-08-10 09:01:54,165:INFO:Logical Core: 4
2023-08-10 09:01:54,165:INFO:Checking libraries
2023-08-10 09:01:54,165:INFO:System:
2023-08-10 09:01:54,165:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 09:01:54,165:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 09:01:54,166:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 09:01:54,166:INFO:PyCaret required dependencies:
2023-08-10 09:01:54,348:INFO:                 pip: 23.1.2
2023-08-10 09:01:54,349:INFO:          setuptools: 58.1.0
2023-08-10 09:01:54,349:INFO:             pycaret: 3.0.4
2023-08-10 09:01:54,349:INFO:             IPython: 8.13.2
2023-08-10 09:01:54,349:INFO:          ipywidgets: 8.0.7
2023-08-10 09:01:54,349:INFO:                tqdm: 4.65.0
2023-08-10 09:01:54,349:INFO:               numpy: 1.23.5
2023-08-10 09:01:54,349:INFO:              pandas: 1.5.3
2023-08-10 09:01:54,349:INFO:              jinja2: 3.1.2
2023-08-10 09:01:54,350:INFO:               scipy: 1.10.1
2023-08-10 09:01:54,350:INFO:              joblib: 1.2.0
2023-08-10 09:01:54,350:INFO:             sklearn: 1.2.2
2023-08-10 09:01:54,350:INFO:                pyod: 1.1.0
2023-08-10 09:01:54,350:INFO:            imblearn: 0.11.0
2023-08-10 09:01:54,350:INFO:   category_encoders: 2.6.1
2023-08-10 09:01:54,350:INFO:            lightgbm: 4.0.0
2023-08-10 09:01:54,350:INFO:               numba: 0.57.1
2023-08-10 09:01:54,350:INFO:            requests: 2.31.0
2023-08-10 09:01:54,351:INFO:          matplotlib: 3.7.1
2023-08-10 09:01:54,351:INFO:          scikitplot: 0.3.7
2023-08-10 09:01:54,351:INFO:         yellowbrick: 1.5
2023-08-10 09:01:54,351:INFO:              plotly: 5.15.0
2023-08-10 09:01:54,351:INFO:    plotly-resampler: Not installed
2023-08-10 09:01:54,351:INFO:             kaleido: 0.2.1
2023-08-10 09:01:54,351:INFO:           schemdraw: 0.15
2023-08-10 09:01:54,351:INFO:         statsmodels: 0.14.0
2023-08-10 09:01:54,351:INFO:              sktime: 0.20.1
2023-08-10 09:01:54,352:INFO:               tbats: 1.1.3
2023-08-10 09:01:54,352:INFO:            pmdarima: 2.0.3
2023-08-10 09:01:54,352:INFO:              psutil: 5.9.5
2023-08-10 09:01:54,352:INFO:          markupsafe: 2.1.3
2023-08-10 09:01:54,352:INFO:             pickle5: Not installed
2023-08-10 09:01:54,352:INFO:         cloudpickle: 2.2.1
2023-08-10 09:01:54,352:INFO:         deprecation: 2.1.0
2023-08-10 09:01:54,352:INFO:              xxhash: 3.2.0
2023-08-10 09:01:54,352:INFO:           wurlitzer: Not installed
2023-08-10 09:01:54,353:INFO:PyCaret optional dependencies:
2023-08-10 09:01:54,395:INFO:                shap: Not installed
2023-08-10 09:01:54,395:INFO:           interpret: 0.4.2
2023-08-10 09:01:54,395:INFO:                umap: 0.5.3
2023-08-10 09:01:54,395:INFO:    pandas_profiling: Not installed
2023-08-10 09:01:54,396:INFO:  explainerdashboard: Not installed
2023-08-10 09:01:54,396:INFO:             autoviz: Not installed
2023-08-10 09:01:54,396:INFO:           fairlearn: Not installed
2023-08-10 09:01:54,396:INFO:          deepchecks: Not installed
2023-08-10 09:01:54,396:INFO:             xgboost: 1.7.6
2023-08-10 09:01:54,396:INFO:            catboost: Not installed
2023-08-10 09:01:54,396:INFO:              kmodes: Not installed
2023-08-10 09:01:54,396:INFO:             mlxtend: 0.22.0
2023-08-10 09:01:54,396:INFO:       statsforecast: Not installed
2023-08-10 09:01:54,396:INFO:        tune_sklearn: Not installed
2023-08-10 09:01:54,397:INFO:                 ray: Not installed
2023-08-10 09:01:54,397:INFO:            hyperopt: Not installed
2023-08-10 09:01:54,397:INFO:              optuna: Not installed
2023-08-10 09:01:54,397:INFO:               skopt: Not installed
2023-08-10 09:01:54,397:INFO:              mlflow: 2.4.2
2023-08-10 09:01:54,397:INFO:              gradio: Not installed
2023-08-10 09:01:54,397:INFO:             fastapi: Not installed
2023-08-10 09:01:54,397:INFO:             uvicorn: Not installed
2023-08-10 09:01:54,397:INFO:              m2cgen: Not installed
2023-08-10 09:01:54,397:INFO:           evidently: Not installed
2023-08-10 09:01:54,398:INFO:               fugue: Not installed
2023-08-10 09:01:54,398:INFO:           streamlit: 1.25.0
2023-08-10 09:01:54,398:INFO:             prophet: Not installed
2023-08-10 09:01:54,398:INFO:None
2023-08-10 09:01:54,398:INFO:Set up data.
2023-08-10 09:01:54,415:INFO:Set up index.
2023-08-10 09:01:54,416:INFO:Assigning column types.
2023-08-10 09:01:54,427:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 09:01:56,493:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 09:01:56,499:INFO:Preparing preprocessing pipeline...
2023-08-10 09:01:56,499:INFO:Set up simple imputation.
2023-08-10 09:01:56,504:INFO:Set up encoding of categorical features.
2023-08-10 09:01:56,889:INFO:Finished creating preprocessing pipeline.
2023-08-10 09:01:56,913:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 09:01:56,914:INFO:Creating final display dataframe.
2023-08-10 09:01:56,963:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   320
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  3b00
2023-08-10 09:01:56,965:INFO:setup() successfully completed in 4.93s...............
2023-08-10 09:01:56,966:INFO:Initializing create_model()
2023-08-10 09:01:56,966:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000024495FFE220>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 09:01:56,966:INFO:Checking exceptions
2023-08-10 09:01:57,010:INFO:Importing untrained model
2023-08-10 09:01:57,011:INFO:Isolation Forest Imported successfully
2023-08-10 09:01:57,015:INFO:Fitting Model
2023-08-10 09:01:59,065:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=320, verbose=0)
2023-08-10 09:01:59,066:INFO:create_models() successfully completed......................................
2023-08-10 09:01:59,066:INFO:Uploading results into container
2023-08-10 09:01:59,066:INFO:Uploading model into container now
2023-08-10 09:01:59,066:INFO:_master_model_container: 1
2023-08-10 09:01:59,066:INFO:_display_container: 1
2023-08-10 09:01:59,067:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=320, verbose=0)
2023-08-10 09:01:59,067:INFO:create_model() successfully completed......................................
2023-08-10 09:02:01,048:INFO:Initializing plot_model()
2023-08-10 09:02:01,049:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=320, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000024495FFE220>, system=True)
2023-08-10 09:02:01,049:INFO:Checking exceptions
2023-08-10 09:02:07,752:INFO:Preloading libraries
2023-08-10 09:02:07,792:INFO:Copying training dataset
2023-08-10 09:02:07,793:INFO:Plot type: umap
2023-08-10 09:02:07,794:INFO:SubProcess assign_model() called ==================================
2023-08-10 09:02:07,795:INFO:Initializing assign_model()
2023-08-10 09:02:07,795:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000024495FFE220>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=320, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 09:02:07,795:INFO:Checking exceptions
2023-08-10 09:02:07,795:INFO:Determining Trained Model
2023-08-10 09:02:07,796:INFO:Trained Model : Isolation Forest
2023-08-10 09:02:07,796:INFO:Copying data
2023-08-10 09:02:07,834:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 09:02:07,835:INFO:(3941, 18)
2023-08-10 09:02:07,836:INFO:assign_model() successfully completed......................................
2023-08-10 09:02:07,836:INFO:SubProcess assign_model() end ==================================
2023-08-10 09:02:07,844:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 09:02:23,358:INFO:Fitting UMAP()
2023-08-10 09:03:15,640:INFO:Rendering Visual
2023-08-10 09:03:19,530:INFO:Visual Rendered Successfully
2023-08-10 09:03:19,871:INFO:plot_model() successfully completed......................................
2023-08-10 09:03:19,912:INFO:Initializing assign_model()
2023-08-10 09:03:19,913:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000024495FFE220>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=320, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 09:03:19,913:INFO:Checking exceptions
2023-08-10 09:03:19,914:INFO:Determining Trained Model
2023-08-10 09:03:19,915:INFO:Trained Model : Isolation Forest
2023-08-10 09:03:19,915:INFO:Copying data
2023-08-10 09:03:19,922:INFO:(3941, 13)
2023-08-10 09:03:19,923:INFO:assign_model() successfully completed......................................
2023-08-10 09:08:28,297:INFO:PyCaret ClassificationExperiment
2023-08-10 09:08:28,297:INFO:Logging name: clf-default-name
2023-08-10 09:08:28,297:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 09:08:28,297:INFO:version 3.0.4
2023-08-10 09:08:28,298:INFO:Initializing setup()
2023-08-10 09:08:28,298:INFO:self.USI: 9c2f
2023-08-10 09:08:28,298:INFO:self._variable_keys: {'_available_plots', 'target_param', 'X_train', 'USI', 'log_plots_param', 'y', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'idx', 'seed', 'y_test', 'html_param', 'gpu_param', 'X', 'logging_param', 'fold_groups_param', 'data', 'gpu_n_jobs_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'exp_name_log', 'memory', 'is_multiclass', 'X_test', 'fold_generator', 'pipeline'}
2023-08-10 09:08:28,298:INFO:Checking environment
2023-08-10 09:08:28,298:INFO:python_version: 3.9.13
2023-08-10 09:08:28,298:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 09:08:28,299:INFO:machine: AMD64
2023-08-10 09:08:28,299:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 09:08:28,309:INFO:Memory: svmem(total=7480111104, available=1002917888, percent=86.6, used=6477193216, free=1002917888)
2023-08-10 09:08:28,309:INFO:Physical Core: 4
2023-08-10 09:08:28,309:INFO:Logical Core: 4
2023-08-10 09:08:28,309:INFO:Checking libraries
2023-08-10 09:08:28,310:INFO:System:
2023-08-10 09:08:28,310:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 09:08:28,310:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 09:08:28,310:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 09:08:28,310:INFO:PyCaret required dependencies:
2023-08-10 09:08:28,310:INFO:                 pip: 23.1.2
2023-08-10 09:08:28,310:INFO:          setuptools: 58.1.0
2023-08-10 09:08:28,311:INFO:             pycaret: 3.0.4
2023-08-10 09:08:28,311:INFO:             IPython: 8.13.2
2023-08-10 09:08:28,311:INFO:          ipywidgets: 8.0.7
2023-08-10 09:08:28,311:INFO:                tqdm: 4.65.0
2023-08-10 09:08:28,311:INFO:               numpy: 1.23.5
2023-08-10 09:08:28,311:INFO:              pandas: 1.5.3
2023-08-10 09:08:28,311:INFO:              jinja2: 3.1.2
2023-08-10 09:08:28,311:INFO:               scipy: 1.10.1
2023-08-10 09:08:28,311:INFO:              joblib: 1.2.0
2023-08-10 09:08:28,311:INFO:             sklearn: 1.2.2
2023-08-10 09:08:28,312:INFO:                pyod: 1.1.0
2023-08-10 09:08:28,312:INFO:            imblearn: 0.11.0
2023-08-10 09:08:28,312:INFO:   category_encoders: 2.6.1
2023-08-10 09:08:28,312:INFO:            lightgbm: 4.0.0
2023-08-10 09:08:28,312:INFO:               numba: 0.57.1
2023-08-10 09:08:28,312:INFO:            requests: 2.31.0
2023-08-10 09:08:28,312:INFO:          matplotlib: 3.7.1
2023-08-10 09:08:28,312:INFO:          scikitplot: 0.3.7
2023-08-10 09:08:28,312:INFO:         yellowbrick: 1.5
2023-08-10 09:08:28,312:INFO:              plotly: 5.15.0
2023-08-10 09:08:28,313:INFO:    plotly-resampler: Not installed
2023-08-10 09:08:28,313:INFO:             kaleido: 0.2.1
2023-08-10 09:08:28,313:INFO:           schemdraw: 0.15
2023-08-10 09:08:28,313:INFO:         statsmodels: 0.14.0
2023-08-10 09:08:28,313:INFO:              sktime: 0.20.1
2023-08-10 09:08:28,313:INFO:               tbats: 1.1.3
2023-08-10 09:08:28,313:INFO:            pmdarima: 2.0.3
2023-08-10 09:08:28,313:INFO:              psutil: 5.9.5
2023-08-10 09:08:28,313:INFO:          markupsafe: 2.1.3
2023-08-10 09:08:28,313:INFO:             pickle5: Not installed
2023-08-10 09:08:28,313:INFO:         cloudpickle: 2.2.1
2023-08-10 09:08:28,314:INFO:         deprecation: 2.1.0
2023-08-10 09:08:28,314:INFO:              xxhash: 3.2.0
2023-08-10 09:08:28,314:INFO:           wurlitzer: Not installed
2023-08-10 09:08:28,314:INFO:PyCaret optional dependencies:
2023-08-10 09:08:28,314:INFO:                shap: Not installed
2023-08-10 09:08:28,314:INFO:           interpret: 0.4.2
2023-08-10 09:08:28,314:INFO:                umap: 0.5.3
2023-08-10 09:08:28,314:INFO:    pandas_profiling: Not installed
2023-08-10 09:08:28,315:INFO:  explainerdashboard: Not installed
2023-08-10 09:08:28,315:INFO:             autoviz: Not installed
2023-08-10 09:08:28,315:INFO:           fairlearn: Not installed
2023-08-10 09:08:28,315:INFO:          deepchecks: Not installed
2023-08-10 09:08:28,315:INFO:             xgboost: 1.7.6
2023-08-10 09:08:28,315:INFO:            catboost: Not installed
2023-08-10 09:08:28,315:INFO:              kmodes: Not installed
2023-08-10 09:08:28,315:INFO:             mlxtend: 0.22.0
2023-08-10 09:08:28,315:INFO:       statsforecast: Not installed
2023-08-10 09:08:28,315:INFO:        tune_sklearn: Not installed
2023-08-10 09:08:28,315:INFO:                 ray: Not installed
2023-08-10 09:08:28,316:INFO:            hyperopt: Not installed
2023-08-10 09:08:28,316:INFO:              optuna: Not installed
2023-08-10 09:08:28,316:INFO:               skopt: Not installed
2023-08-10 09:08:28,316:INFO:              mlflow: 2.4.2
2023-08-10 09:08:28,316:INFO:              gradio: Not installed
2023-08-10 09:08:28,316:INFO:             fastapi: Not installed
2023-08-10 09:08:28,316:INFO:             uvicorn: Not installed
2023-08-10 09:08:28,316:INFO:              m2cgen: Not installed
2023-08-10 09:08:28,317:INFO:           evidently: Not installed
2023-08-10 09:08:28,317:INFO:               fugue: Not installed
2023-08-10 09:08:28,317:INFO:           streamlit: 1.25.0
2023-08-10 09:08:28,317:INFO:             prophet: Not installed
2023-08-10 09:08:28,317:INFO:None
2023-08-10 09:08:28,317:INFO:Set up data.
2023-08-10 09:09:08,888:INFO:PyCaret ClassificationExperiment
2023-08-10 09:09:08,889:INFO:Logging name: bank loan
2023-08-10 09:09:08,889:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 09:09:08,890:INFO:version 3.0.4
2023-08-10 09:09:08,890:INFO:Initializing setup()
2023-08-10 09:09:08,891:INFO:self.USI: 6ac2
2023-08-10 09:09:08,891:INFO:self._variable_keys: {'_available_plots', 'target_param', 'X_train', 'USI', 'log_plots_param', 'y', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'idx', 'seed', 'y_test', 'html_param', 'gpu_param', 'X', 'logging_param', 'fold_groups_param', 'data', 'gpu_n_jobs_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'exp_name_log', 'memory', 'is_multiclass', 'X_test', 'fold_generator', 'pipeline'}
2023-08-10 09:09:08,891:INFO:Checking environment
2023-08-10 09:09:08,892:INFO:python_version: 3.9.13
2023-08-10 09:09:08,892:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 09:09:08,892:INFO:machine: AMD64
2023-08-10 09:09:08,892:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 09:09:08,902:INFO:Memory: svmem(total=7480111104, available=1050255360, percent=86.0, used=6429855744, free=1050255360)
2023-08-10 09:09:08,902:INFO:Physical Core: 4
2023-08-10 09:09:08,902:INFO:Logical Core: 4
2023-08-10 09:09:08,902:INFO:Checking libraries
2023-08-10 09:09:08,903:INFO:System:
2023-08-10 09:09:08,903:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 09:09:08,903:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 09:09:08,903:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 09:09:08,903:INFO:PyCaret required dependencies:
2023-08-10 09:09:08,904:INFO:                 pip: 23.1.2
2023-08-10 09:09:08,904:INFO:          setuptools: 58.1.0
2023-08-10 09:09:08,904:INFO:             pycaret: 3.0.4
2023-08-10 09:09:08,904:INFO:             IPython: 8.13.2
2023-08-10 09:09:08,904:INFO:          ipywidgets: 8.0.7
2023-08-10 09:09:08,905:INFO:                tqdm: 4.65.0
2023-08-10 09:09:08,905:INFO:               numpy: 1.23.5
2023-08-10 09:09:08,905:INFO:              pandas: 1.5.3
2023-08-10 09:09:08,905:INFO:              jinja2: 3.1.2
2023-08-10 09:09:08,905:INFO:               scipy: 1.10.1
2023-08-10 09:09:08,905:INFO:              joblib: 1.2.0
2023-08-10 09:09:08,905:INFO:             sklearn: 1.2.2
2023-08-10 09:09:08,905:INFO:                pyod: 1.1.0
2023-08-10 09:09:08,905:INFO:            imblearn: 0.11.0
2023-08-10 09:09:08,905:INFO:   category_encoders: 2.6.1
2023-08-10 09:09:08,906:INFO:            lightgbm: 4.0.0
2023-08-10 09:09:08,906:INFO:               numba: 0.57.1
2023-08-10 09:09:08,906:INFO:            requests: 2.31.0
2023-08-10 09:09:08,906:INFO:          matplotlib: 3.7.1
2023-08-10 09:09:08,906:INFO:          scikitplot: 0.3.7
2023-08-10 09:09:08,906:INFO:         yellowbrick: 1.5
2023-08-10 09:09:08,906:INFO:              plotly: 5.15.0
2023-08-10 09:09:08,906:INFO:    plotly-resampler: Not installed
2023-08-10 09:09:08,906:INFO:             kaleido: 0.2.1
2023-08-10 09:09:08,907:INFO:           schemdraw: 0.15
2023-08-10 09:09:08,907:INFO:         statsmodels: 0.14.0
2023-08-10 09:09:08,907:INFO:              sktime: 0.20.1
2023-08-10 09:09:08,907:INFO:               tbats: 1.1.3
2023-08-10 09:09:08,907:INFO:            pmdarima: 2.0.3
2023-08-10 09:09:08,907:INFO:              psutil: 5.9.5
2023-08-10 09:09:08,907:INFO:          markupsafe: 2.1.3
2023-08-10 09:09:08,907:INFO:             pickle5: Not installed
2023-08-10 09:09:08,907:INFO:         cloudpickle: 2.2.1
2023-08-10 09:09:08,908:INFO:         deprecation: 2.1.0
2023-08-10 09:09:08,908:INFO:              xxhash: 3.2.0
2023-08-10 09:09:08,908:INFO:           wurlitzer: Not installed
2023-08-10 09:09:08,908:INFO:PyCaret optional dependencies:
2023-08-10 09:09:08,908:INFO:                shap: Not installed
2023-08-10 09:09:08,908:INFO:           interpret: 0.4.2
2023-08-10 09:09:08,908:INFO:                umap: 0.5.3
2023-08-10 09:09:08,908:INFO:    pandas_profiling: Not installed
2023-08-10 09:09:08,908:INFO:  explainerdashboard: Not installed
2023-08-10 09:09:08,909:INFO:             autoviz: Not installed
2023-08-10 09:09:08,909:INFO:           fairlearn: Not installed
2023-08-10 09:09:08,909:INFO:          deepchecks: Not installed
2023-08-10 09:09:08,909:INFO:             xgboost: 1.7.6
2023-08-10 09:09:08,909:INFO:            catboost: Not installed
2023-08-10 09:09:08,909:INFO:              kmodes: Not installed
2023-08-10 09:09:08,909:INFO:             mlxtend: 0.22.0
2023-08-10 09:09:08,909:INFO:       statsforecast: Not installed
2023-08-10 09:09:08,910:INFO:        tune_sklearn: Not installed
2023-08-10 09:09:08,910:INFO:                 ray: Not installed
2023-08-10 09:09:08,910:INFO:            hyperopt: Not installed
2023-08-10 09:09:08,910:INFO:              optuna: Not installed
2023-08-10 09:09:08,910:INFO:               skopt: Not installed
2023-08-10 09:09:08,910:INFO:              mlflow: 2.4.2
2023-08-10 09:09:08,910:INFO:              gradio: Not installed
2023-08-10 09:09:08,910:INFO:             fastapi: Not installed
2023-08-10 09:09:08,910:INFO:             uvicorn: Not installed
2023-08-10 09:09:08,911:INFO:              m2cgen: Not installed
2023-08-10 09:09:08,911:INFO:           evidently: Not installed
2023-08-10 09:09:08,911:INFO:               fugue: Not installed
2023-08-10 09:09:08,911:INFO:           streamlit: 1.25.0
2023-08-10 09:09:08,911:INFO:             prophet: Not installed
2023-08-10 09:09:08,911:INFO:None
2023-08-10 09:09:08,911:INFO:Set up data.
2023-08-10 09:09:08,938:INFO:Set up train/test split.
2023-08-10 09:09:08,957:INFO:Set up index.
2023-08-10 09:09:08,958:INFO:Set up folding strategy.
2023-08-10 09:09:08,958:INFO:Assigning column types.
2023-08-10 09:09:08,974:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 09:09:09,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 09:09:09,259:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:09:09,397:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:09:09,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:09:09,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 09:09:09,578:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:09:09,692:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:09:09,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:09:09,704:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 09:09:09,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:09:09,978:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:09:09,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:09:10,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:09:10,265:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:09:10,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:09:10,277:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 09:09:10,562:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:09:10,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:09:10,853:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:09:10,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:09:10,864:INFO:Set up custom pipeline.
2023-08-10 09:09:10,899:INFO:Finished creating preprocessing pipeline.
2023-08-10 09:09:10,910:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('remove outlier',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=TransformerWrapper(exclude=None,
                                                                   include=None,
                                                                   transformer=RemoveOutliers(method='iforest',
                                                                                              n_jobs=1,
                                                                                              random_state=42,
                                                                                              threshold=0.05))))],
         verbose=False)
2023-08-10 09:09:10,910:INFO:Creating final display dataframe.
2023-08-10 09:12:03,136:INFO:PyCaret ClassificationExperiment
2023-08-10 09:12:03,136:INFO:Logging name: bank loan
2023-08-10 09:12:03,137:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 09:12:03,137:INFO:version 3.0.4
2023-08-10 09:12:03,137:INFO:Initializing setup()
2023-08-10 09:12:03,137:INFO:self.USI: 8827
2023-08-10 09:12:03,137:INFO:self._variable_keys: {'_available_plots', 'target_param', 'X_train', 'USI', 'log_plots_param', 'y', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'idx', 'seed', 'y_test', 'html_param', 'gpu_param', 'X', 'logging_param', 'fold_groups_param', 'data', 'gpu_n_jobs_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'exp_name_log', 'memory', 'is_multiclass', 'X_test', 'fold_generator', 'pipeline'}
2023-08-10 09:12:03,137:INFO:Checking environment
2023-08-10 09:12:03,138:INFO:python_version: 3.9.13
2023-08-10 09:12:03,138:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 09:12:03,138:INFO:machine: AMD64
2023-08-10 09:12:03,138:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 09:12:03,149:INFO:Memory: svmem(total=7480111104, available=999776256, percent=86.6, used=6480334848, free=999776256)
2023-08-10 09:12:03,150:INFO:Physical Core: 4
2023-08-10 09:12:03,150:INFO:Logical Core: 4
2023-08-10 09:12:03,150:INFO:Checking libraries
2023-08-10 09:12:03,150:INFO:System:
2023-08-10 09:12:03,150:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 09:12:03,150:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 09:12:03,150:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 09:12:03,151:INFO:PyCaret required dependencies:
2023-08-10 09:12:03,151:INFO:                 pip: 23.1.2
2023-08-10 09:12:03,151:INFO:          setuptools: 58.1.0
2023-08-10 09:12:03,151:INFO:             pycaret: 3.0.4
2023-08-10 09:12:03,151:INFO:             IPython: 8.13.2
2023-08-10 09:12:03,151:INFO:          ipywidgets: 8.0.7
2023-08-10 09:12:03,151:INFO:                tqdm: 4.65.0
2023-08-10 09:12:03,151:INFO:               numpy: 1.23.5
2023-08-10 09:12:03,152:INFO:              pandas: 1.5.3
2023-08-10 09:12:03,152:INFO:              jinja2: 3.1.2
2023-08-10 09:12:03,152:INFO:               scipy: 1.10.1
2023-08-10 09:12:03,152:INFO:              joblib: 1.2.0
2023-08-10 09:12:03,152:INFO:             sklearn: 1.2.2
2023-08-10 09:12:03,153:INFO:                pyod: 1.1.0
2023-08-10 09:12:03,153:INFO:            imblearn: 0.11.0
2023-08-10 09:12:03,153:INFO:   category_encoders: 2.6.1
2023-08-10 09:12:03,153:INFO:            lightgbm: 4.0.0
2023-08-10 09:12:03,153:INFO:               numba: 0.57.1
2023-08-10 09:12:03,153:INFO:            requests: 2.31.0
2023-08-10 09:12:03,153:INFO:          matplotlib: 3.7.1
2023-08-10 09:12:03,153:INFO:          scikitplot: 0.3.7
2023-08-10 09:12:03,154:INFO:         yellowbrick: 1.5
2023-08-10 09:12:03,154:INFO:              plotly: 5.15.0
2023-08-10 09:12:03,154:INFO:    plotly-resampler: Not installed
2023-08-10 09:12:03,154:INFO:             kaleido: 0.2.1
2023-08-10 09:12:03,154:INFO:           schemdraw: 0.15
2023-08-10 09:12:03,154:INFO:         statsmodels: 0.14.0
2023-08-10 09:12:03,154:INFO:              sktime: 0.20.1
2023-08-10 09:12:03,154:INFO:               tbats: 1.1.3
2023-08-10 09:12:03,154:INFO:            pmdarima: 2.0.3
2023-08-10 09:12:03,155:INFO:              psutil: 5.9.5
2023-08-10 09:12:03,155:INFO:          markupsafe: 2.1.3
2023-08-10 09:12:03,155:INFO:             pickle5: Not installed
2023-08-10 09:12:03,155:INFO:         cloudpickle: 2.2.1
2023-08-10 09:12:03,155:INFO:         deprecation: 2.1.0
2023-08-10 09:12:03,155:INFO:              xxhash: 3.2.0
2023-08-10 09:12:03,155:INFO:           wurlitzer: Not installed
2023-08-10 09:12:03,155:INFO:PyCaret optional dependencies:
2023-08-10 09:12:03,156:INFO:                shap: Not installed
2023-08-10 09:12:03,159:INFO:           interpret: 0.4.2
2023-08-10 09:12:03,160:INFO:                umap: 0.5.3
2023-08-10 09:12:03,160:INFO:    pandas_profiling: Not installed
2023-08-10 09:12:03,160:INFO:  explainerdashboard: Not installed
2023-08-10 09:12:03,160:INFO:             autoviz: Not installed
2023-08-10 09:12:03,160:INFO:           fairlearn: Not installed
2023-08-10 09:12:03,161:INFO:          deepchecks: Not installed
2023-08-10 09:12:03,161:INFO:             xgboost: 1.7.6
2023-08-10 09:12:03,161:INFO:            catboost: Not installed
2023-08-10 09:12:03,161:INFO:              kmodes: Not installed
2023-08-10 09:12:03,161:INFO:             mlxtend: 0.22.0
2023-08-10 09:12:03,161:INFO:       statsforecast: Not installed
2023-08-10 09:12:03,161:INFO:        tune_sklearn: Not installed
2023-08-10 09:12:03,161:INFO:                 ray: Not installed
2023-08-10 09:12:03,161:INFO:            hyperopt: Not installed
2023-08-10 09:12:03,161:INFO:              optuna: Not installed
2023-08-10 09:12:03,162:INFO:               skopt: Not installed
2023-08-10 09:12:03,162:INFO:              mlflow: 2.4.2
2023-08-10 09:12:03,162:INFO:              gradio: Not installed
2023-08-10 09:12:03,162:INFO:             fastapi: Not installed
2023-08-10 09:12:03,162:INFO:             uvicorn: Not installed
2023-08-10 09:12:03,162:INFO:              m2cgen: Not installed
2023-08-10 09:12:03,162:INFO:           evidently: Not installed
2023-08-10 09:12:03,162:INFO:               fugue: Not installed
2023-08-10 09:12:03,162:INFO:           streamlit: 1.25.0
2023-08-10 09:12:03,163:INFO:             prophet: Not installed
2023-08-10 09:12:03,163:INFO:None
2023-08-10 09:12:03,163:INFO:Set up data.
2023-08-10 09:12:03,186:INFO:Set up train/test split.
2023-08-10 09:12:03,204:INFO:Set up index.
2023-08-10 09:12:03,205:INFO:Set up folding strategy.
2023-08-10 09:12:03,205:INFO:Assigning column types.
2023-08-10 09:12:03,219:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 09:12:03,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 09:12:03,397:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:12:03,505:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:03,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:03,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 09:12:03,669:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:12:03,766:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:03,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:03,778:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 09:12:03,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:12:04,033:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:04,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:04,210:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:12:04,304:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:04,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:04,317:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 09:12:04,568:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:04,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:04,828:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:04,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:04,844:INFO:Preparing preprocessing pipeline...
2023-08-10 09:12:04,847:INFO:Set up simple imputation.
2023-08-10 09:12:04,855:INFO:Set up encoding of categorical features.
2023-08-10 09:12:05,062:INFO:Finished creating preprocessing pipeline.
2023-08-10 09:12:05,081:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-10 09:12:05,081:INFO:Creating final display dataframe.
2023-08-10 09:12:05,705:INFO:Setup _display_container:                     Description            Value
0                    Session id               42
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2615, 17)
5   Transformed train set shape       (2092, 17)
6    Transformed test set shape        (523, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment    DagshubLogger
20              Experiment Name        bank loan
21                          USI             8827
2023-08-10 09:12:06,015:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:06,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:06,278:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:12:06,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:12:06,288:INFO:Logging experiment in loggers
2023-08-10 09:24:05,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:24:05,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:24:05,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:24:05,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 09:24:31,133:INFO:PyCaret AnomalyExperiment
2023-08-10 09:24:31,135:INFO:Logging name: anomaly-default-name
2023-08-10 09:24:31,135:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 09:24:31,136:INFO:version 3.0.4
2023-08-10 09:24:31,136:INFO:Initializing setup()
2023-08-10 09:24:31,136:INFO:self.USI: e555
2023-08-10 09:24:31,137:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'logging_param', 'exp_name_log', '_available_plots', 'n_jobs_param', 'X', 'USI', 'log_plots_param', 'data', 'seed', 'gpu_param', 'idx', 'pipeline', 'memory', 'gpu_n_jobs_param', 'exp_id'}
2023-08-10 09:24:31,137:INFO:Checking environment
2023-08-10 09:24:31,137:INFO:python_version: 3.9.13
2023-08-10 09:24:31,137:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 09:24:31,137:INFO:machine: AMD64
2023-08-10 09:24:31,137:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 09:24:31,145:INFO:Memory: svmem(total=7480111104, available=1143877632, percent=84.7, used=6336233472, free=1143877632)
2023-08-10 09:24:31,145:INFO:Physical Core: 4
2023-08-10 09:24:31,145:INFO:Logical Core: 4
2023-08-10 09:24:31,145:INFO:Checking libraries
2023-08-10 09:24:31,145:INFO:System:
2023-08-10 09:24:31,146:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 09:24:31,146:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 09:24:31,146:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 09:24:31,146:INFO:PyCaret required dependencies:
2023-08-10 09:24:31,327:INFO:                 pip: 23.1.2
2023-08-10 09:24:31,328:INFO:          setuptools: 58.1.0
2023-08-10 09:24:31,328:INFO:             pycaret: 3.0.4
2023-08-10 09:24:31,328:INFO:             IPython: 8.13.2
2023-08-10 09:24:31,328:INFO:          ipywidgets: 8.0.7
2023-08-10 09:24:31,328:INFO:                tqdm: 4.65.0
2023-08-10 09:24:31,328:INFO:               numpy: 1.23.5
2023-08-10 09:24:31,328:INFO:              pandas: 1.5.3
2023-08-10 09:24:31,328:INFO:              jinja2: 3.1.2
2023-08-10 09:24:31,329:INFO:               scipy: 1.10.1
2023-08-10 09:24:31,329:INFO:              joblib: 1.2.0
2023-08-10 09:24:31,329:INFO:             sklearn: 1.2.2
2023-08-10 09:24:31,329:INFO:                pyod: 1.1.0
2023-08-10 09:24:31,329:INFO:            imblearn: 0.11.0
2023-08-10 09:24:31,329:INFO:   category_encoders: 2.6.1
2023-08-10 09:24:31,329:INFO:            lightgbm: 4.0.0
2023-08-10 09:24:31,329:INFO:               numba: 0.57.1
2023-08-10 09:24:31,329:INFO:            requests: 2.31.0
2023-08-10 09:24:31,329:INFO:          matplotlib: 3.7.1
2023-08-10 09:24:31,329:INFO:          scikitplot: 0.3.7
2023-08-10 09:24:31,330:INFO:         yellowbrick: 1.5
2023-08-10 09:24:31,330:INFO:              plotly: 5.15.0
2023-08-10 09:24:31,330:INFO:    plotly-resampler: Not installed
2023-08-10 09:24:31,330:INFO:             kaleido: 0.2.1
2023-08-10 09:24:31,330:INFO:           schemdraw: 0.15
2023-08-10 09:24:31,330:INFO:         statsmodels: 0.14.0
2023-08-10 09:24:31,330:INFO:              sktime: 0.20.1
2023-08-10 09:24:31,330:INFO:               tbats: 1.1.3
2023-08-10 09:24:31,330:INFO:            pmdarima: 2.0.3
2023-08-10 09:24:31,330:INFO:              psutil: 5.9.5
2023-08-10 09:24:31,331:INFO:          markupsafe: 2.1.3
2023-08-10 09:24:31,331:INFO:             pickle5: Not installed
2023-08-10 09:24:31,331:INFO:         cloudpickle: 2.2.1
2023-08-10 09:24:31,331:INFO:         deprecation: 2.1.0
2023-08-10 09:24:31,331:INFO:              xxhash: 3.2.0
2023-08-10 09:24:31,331:INFO:           wurlitzer: Not installed
2023-08-10 09:24:31,331:INFO:PyCaret optional dependencies:
2023-08-10 09:24:31,372:INFO:                shap: Not installed
2023-08-10 09:24:31,372:INFO:           interpret: 0.4.2
2023-08-10 09:24:31,372:INFO:                umap: 0.5.3
2023-08-10 09:24:31,372:INFO:    pandas_profiling: Not installed
2023-08-10 09:24:31,373:INFO:  explainerdashboard: Not installed
2023-08-10 09:24:31,373:INFO:             autoviz: Not installed
2023-08-10 09:24:31,373:INFO:           fairlearn: Not installed
2023-08-10 09:24:31,373:INFO:          deepchecks: Not installed
2023-08-10 09:24:31,373:INFO:             xgboost: 1.7.6
2023-08-10 09:24:31,373:INFO:            catboost: Not installed
2023-08-10 09:24:31,373:INFO:              kmodes: Not installed
2023-08-10 09:24:31,373:INFO:             mlxtend: 0.22.0
2023-08-10 09:24:31,373:INFO:       statsforecast: Not installed
2023-08-10 09:24:31,373:INFO:        tune_sklearn: Not installed
2023-08-10 09:24:31,374:INFO:                 ray: Not installed
2023-08-10 09:24:31,374:INFO:            hyperopt: Not installed
2023-08-10 09:24:31,374:INFO:              optuna: Not installed
2023-08-10 09:24:31,374:INFO:               skopt: Not installed
2023-08-10 09:24:31,374:INFO:              mlflow: 2.4.2
2023-08-10 09:24:31,374:INFO:              gradio: Not installed
2023-08-10 09:24:31,374:INFO:             fastapi: Not installed
2023-08-10 09:24:31,374:INFO:             uvicorn: Not installed
2023-08-10 09:24:31,374:INFO:              m2cgen: Not installed
2023-08-10 09:24:31,375:INFO:           evidently: Not installed
2023-08-10 09:24:31,375:INFO:               fugue: Not installed
2023-08-10 09:24:31,375:INFO:           streamlit: 1.25.0
2023-08-10 09:24:31,375:INFO:             prophet: Not installed
2023-08-10 09:24:31,375:INFO:None
2023-08-10 09:24:31,375:INFO:Set up data.
2023-08-10 09:24:31,392:INFO:Set up index.
2023-08-10 09:24:31,393:INFO:Assigning column types.
2023-08-10 09:24:31,400:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 09:24:33,419:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 09:24:33,424:INFO:Preparing preprocessing pipeline...
2023-08-10 09:24:33,425:INFO:Set up simple imputation.
2023-08-10 09:24:33,429:INFO:Set up encoding of categorical features.
2023-08-10 09:24:33,562:INFO:Finished creating preprocessing pipeline.
2023-08-10 09:24:33,585:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 09:24:33,586:INFO:Creating final display dataframe.
2023-08-10 09:24:33,826:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  3229
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  e555
2023-08-10 09:24:33,828:INFO:setup() successfully completed in 4.5s...............
2023-08-10 09:24:33,828:INFO:Initializing create_model()
2023-08-10 09:24:33,828:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273C4CD7EB0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 09:24:33,828:INFO:Checking exceptions
2023-08-10 09:24:33,891:INFO:Importing untrained model
2023-08-10 09:24:33,893:INFO:Isolation Forest Imported successfully
2023-08-10 09:24:33,896:INFO:Fitting Model
2023-08-10 09:24:35,854:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3229, verbose=0)
2023-08-10 09:24:35,854:INFO:create_models() successfully completed......................................
2023-08-10 09:24:35,854:INFO:Uploading results into container
2023-08-10 09:24:35,854:INFO:Uploading model into container now
2023-08-10 09:24:35,855:INFO:_master_model_container: 1
2023-08-10 09:24:35,855:INFO:_display_container: 1
2023-08-10 09:24:35,855:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3229, verbose=0)
2023-08-10 09:24:35,856:INFO:create_model() successfully completed......................................
2023-08-10 09:24:37,622:INFO:Initializing plot_model()
2023-08-10 09:24:37,622:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3229, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273C4CD7EB0>, system=True)
2023-08-10 09:24:37,622:INFO:Checking exceptions
2023-08-10 09:24:43,077:INFO:Preloading libraries
2023-08-10 09:24:43,110:INFO:Copying training dataset
2023-08-10 09:24:43,110:INFO:Plot type: umap
2023-08-10 09:24:43,111:INFO:SubProcess assign_model() called ==================================
2023-08-10 09:24:43,112:INFO:Initializing assign_model()
2023-08-10 09:24:43,112:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273C4CD7EB0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3229, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 09:24:43,112:INFO:Checking exceptions
2023-08-10 09:24:43,112:INFO:Determining Trained Model
2023-08-10 09:24:43,113:INFO:Trained Model : Isolation Forest
2023-08-10 09:24:43,113:INFO:Copying data
2023-08-10 09:24:43,151:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 09:24:43,153:INFO:(3941, 18)
2023-08-10 09:24:43,153:INFO:assign_model() successfully completed......................................
2023-08-10 09:24:43,153:INFO:SubProcess assign_model() end ==================================
2023-08-10 09:24:43,158:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 09:24:56,999:INFO:Fitting UMAP()
2023-08-10 09:25:51,557:INFO:Rendering Visual
2023-08-10 09:25:57,659:INFO:Visual Rendered Successfully
2023-08-10 09:25:58,072:INFO:plot_model() successfully completed......................................
2023-08-10 09:25:58,373:INFO:Initializing assign_model()
2023-08-10 09:25:58,373:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273C4CD7EB0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=3229, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 09:25:58,374:INFO:Checking exceptions
2023-08-10 09:25:58,374:INFO:Determining Trained Model
2023-08-10 09:25:58,375:INFO:Trained Model : Isolation Forest
2023-08-10 09:25:58,376:INFO:Copying data
2023-08-10 09:25:58,382:INFO:(3941, 13)
2023-08-10 09:25:58,383:INFO:assign_model() successfully completed......................................
2023-08-10 09:27:33,440:INFO:PyCaret AnomalyExperiment
2023-08-10 09:27:33,440:INFO:Logging name: anomaly-default-name
2023-08-10 09:27:33,441:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 09:27:33,442:INFO:version 3.0.4
2023-08-10 09:27:33,442:INFO:Initializing setup()
2023-08-10 09:27:33,443:INFO:self.USI: d105
2023-08-10 09:27:33,443:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'logging_param', 'exp_name_log', '_available_plots', 'n_jobs_param', 'X', 'USI', 'log_plots_param', 'data', 'seed', 'gpu_param', 'idx', 'pipeline', 'memory', 'gpu_n_jobs_param', 'exp_id'}
2023-08-10 09:27:33,444:INFO:Checking environment
2023-08-10 09:27:33,444:INFO:python_version: 3.9.13
2023-08-10 09:27:33,444:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 09:27:33,444:INFO:machine: AMD64
2023-08-10 09:27:33,444:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 09:27:33,452:INFO:Memory: svmem(total=7480111104, available=685568000, percent=90.8, used=6794543104, free=685568000)
2023-08-10 09:27:33,452:INFO:Physical Core: 4
2023-08-10 09:27:33,452:INFO:Logical Core: 4
2023-08-10 09:27:33,453:INFO:Checking libraries
2023-08-10 09:27:33,453:INFO:System:
2023-08-10 09:27:33,453:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 09:27:33,453:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 09:27:33,453:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 09:27:33,453:INFO:PyCaret required dependencies:
2023-08-10 09:27:33,453:INFO:                 pip: 23.1.2
2023-08-10 09:27:33,453:INFO:          setuptools: 58.1.0
2023-08-10 09:27:33,454:INFO:             pycaret: 3.0.4
2023-08-10 09:27:33,454:INFO:             IPython: 8.13.2
2023-08-10 09:27:33,454:INFO:          ipywidgets: 8.0.7
2023-08-10 09:27:33,454:INFO:                tqdm: 4.65.0
2023-08-10 09:27:33,454:INFO:               numpy: 1.23.5
2023-08-10 09:27:33,454:INFO:              pandas: 1.5.3
2023-08-10 09:27:33,454:INFO:              jinja2: 3.1.2
2023-08-10 09:27:33,454:INFO:               scipy: 1.10.1
2023-08-10 09:27:33,454:INFO:              joblib: 1.2.0
2023-08-10 09:27:33,454:INFO:             sklearn: 1.2.2
2023-08-10 09:27:33,455:INFO:                pyod: 1.1.0
2023-08-10 09:27:33,455:INFO:            imblearn: 0.11.0
2023-08-10 09:27:33,455:INFO:   category_encoders: 2.6.1
2023-08-10 09:27:33,455:INFO:            lightgbm: 4.0.0
2023-08-10 09:27:33,455:INFO:               numba: 0.57.1
2023-08-10 09:27:33,455:INFO:            requests: 2.31.0
2023-08-10 09:27:33,455:INFO:          matplotlib: 3.7.1
2023-08-10 09:27:33,455:INFO:          scikitplot: 0.3.7
2023-08-10 09:27:33,455:INFO:         yellowbrick: 1.5
2023-08-10 09:27:33,455:INFO:              plotly: 5.15.0
2023-08-10 09:27:33,456:INFO:    plotly-resampler: Not installed
2023-08-10 09:27:33,456:INFO:             kaleido: 0.2.1
2023-08-10 09:27:33,456:INFO:           schemdraw: 0.15
2023-08-10 09:27:33,456:INFO:         statsmodels: 0.14.0
2023-08-10 09:27:33,456:INFO:              sktime: 0.20.1
2023-08-10 09:27:33,456:INFO:               tbats: 1.1.3
2023-08-10 09:27:33,456:INFO:            pmdarima: 2.0.3
2023-08-10 09:27:33,456:INFO:              psutil: 5.9.5
2023-08-10 09:27:33,457:INFO:          markupsafe: 2.1.3
2023-08-10 09:27:33,457:INFO:             pickle5: Not installed
2023-08-10 09:27:33,457:INFO:         cloudpickle: 2.2.1
2023-08-10 09:27:33,457:INFO:         deprecation: 2.1.0
2023-08-10 09:27:33,457:INFO:              xxhash: 3.2.0
2023-08-10 09:27:33,457:INFO:           wurlitzer: Not installed
2023-08-10 09:27:33,457:INFO:PyCaret optional dependencies:
2023-08-10 09:27:33,457:INFO:                shap: Not installed
2023-08-10 09:27:33,457:INFO:           interpret: 0.4.2
2023-08-10 09:27:33,457:INFO:                umap: 0.5.3
2023-08-10 09:27:33,458:INFO:    pandas_profiling: Not installed
2023-08-10 09:27:33,459:INFO:  explainerdashboard: Not installed
2023-08-10 09:27:33,460:INFO:             autoviz: Not installed
2023-08-10 09:27:33,460:INFO:           fairlearn: Not installed
2023-08-10 09:27:33,460:INFO:          deepchecks: Not installed
2023-08-10 09:27:33,460:INFO:             xgboost: 1.7.6
2023-08-10 09:27:33,461:INFO:            catboost: Not installed
2023-08-10 09:27:33,461:INFO:              kmodes: Not installed
2023-08-10 09:27:33,461:INFO:             mlxtend: 0.22.0
2023-08-10 09:27:33,461:INFO:       statsforecast: Not installed
2023-08-10 09:27:33,461:INFO:        tune_sklearn: Not installed
2023-08-10 09:27:33,461:INFO:                 ray: Not installed
2023-08-10 09:27:33,461:INFO:            hyperopt: Not installed
2023-08-10 09:27:33,461:INFO:              optuna: Not installed
2023-08-10 09:27:33,461:INFO:               skopt: Not installed
2023-08-10 09:27:33,462:INFO:              mlflow: 2.4.2
2023-08-10 09:27:33,462:INFO:              gradio: Not installed
2023-08-10 09:27:33,462:INFO:             fastapi: Not installed
2023-08-10 09:27:33,462:INFO:             uvicorn: Not installed
2023-08-10 09:27:33,462:INFO:              m2cgen: Not installed
2023-08-10 09:27:33,462:INFO:           evidently: Not installed
2023-08-10 09:27:33,462:INFO:               fugue: Not installed
2023-08-10 09:27:33,462:INFO:           streamlit: 1.25.0
2023-08-10 09:27:33,463:INFO:             prophet: Not installed
2023-08-10 09:27:33,463:INFO:None
2023-08-10 09:27:33,463:INFO:Set up data.
2023-08-10 09:27:33,481:INFO:Set up index.
2023-08-10 09:27:33,482:INFO:Assigning column types.
2023-08-10 09:27:33,489:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 09:27:33,493:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 09:27:33,497:INFO:Preparing preprocessing pipeline...
2023-08-10 09:27:33,498:INFO:Set up simple imputation.
2023-08-10 09:27:33,503:INFO:Set up encoding of categorical features.
2023-08-10 09:27:33,629:INFO:Finished creating preprocessing pipeline.
2023-08-10 09:27:33,648:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 09:27:33,649:INFO:Creating final display dataframe.
2023-08-10 09:27:33,693:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   399
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  d105
2023-08-10 09:27:33,695:INFO:setup() successfully completed in 2.77s...............
2023-08-10 09:27:35,657:INFO:Initializing create_model()
2023-08-10 09:27:35,657:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CB258A30>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 09:27:35,659:INFO:Checking exceptions
2023-08-10 09:27:35,702:INFO:Importing untrained model
2023-08-10 09:27:35,704:INFO:Isolation Forest Imported successfully
2023-08-10 09:27:35,707:INFO:Fitting Model
2023-08-10 09:27:37,741:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=399, verbose=0)
2023-08-10 09:27:37,743:INFO:create_models() successfully completed......................................
2023-08-10 09:27:37,743:INFO:Uploading results into container
2023-08-10 09:27:37,744:INFO:Uploading model into container now
2023-08-10 09:27:37,744:INFO:_master_model_container: 1
2023-08-10 09:27:37,744:INFO:_display_container: 1
2023-08-10 09:27:37,745:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=399, verbose=0)
2023-08-10 09:27:37,745:INFO:create_model() successfully completed......................................
2023-08-10 09:27:39,798:INFO:Initializing plot_model()
2023-08-10 09:27:39,799:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=399, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CB258A30>, system=True)
2023-08-10 09:27:39,799:INFO:Checking exceptions
2023-08-10 09:27:39,984:INFO:Preloading libraries
2023-08-10 09:27:40,018:INFO:Copying training dataset
2023-08-10 09:27:40,019:INFO:Plot type: umap
2023-08-10 09:27:40,019:INFO:SubProcess assign_model() called ==================================
2023-08-10 09:27:40,020:INFO:Initializing assign_model()
2023-08-10 09:27:40,020:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CB258A30>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=399, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 09:27:40,021:INFO:Checking exceptions
2023-08-10 09:27:40,021:INFO:Determining Trained Model
2023-08-10 09:27:40,021:INFO:Trained Model : Isolation Forest
2023-08-10 09:27:40,021:INFO:Copying data
2023-08-10 09:27:40,072:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 09:27:40,074:INFO:(3941, 18)
2023-08-10 09:27:40,081:INFO:assign_model() successfully completed......................................
2023-08-10 09:27:40,082:INFO:SubProcess assign_model() end ==================================
2023-08-10 09:27:40,090:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 09:27:40,090:INFO:Fitting UMAP()
2023-08-10 09:28:16,318:INFO:Rendering Visual
2023-08-10 09:28:16,511:INFO:Visual Rendered Successfully
2023-08-10 09:28:17,064:INFO:plot_model() successfully completed......................................
2023-08-10 09:28:17,932:INFO:Initializing assign_model()
2023-08-10 09:28:17,932:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CB258A30>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=399, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 09:28:17,932:INFO:Checking exceptions
2023-08-10 09:28:17,933:INFO:Determining Trained Model
2023-08-10 09:28:17,933:INFO:Trained Model : Isolation Forest
2023-08-10 09:28:17,934:INFO:Copying data
2023-08-10 09:28:17,940:INFO:(3941, 13)
2023-08-10 09:28:17,940:INFO:assign_model() successfully completed......................................
2023-08-10 09:38:29,817:INFO:PyCaret ClassificationExperiment
2023-08-10 09:38:29,818:INFO:Logging name: Customer Churn
2023-08-10 09:38:29,818:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 09:38:29,818:INFO:version 3.0.4
2023-08-10 09:38:29,818:INFO:Initializing setup()
2023-08-10 09:38:29,818:INFO:self.USI: 08d1
2023-08-10 09:38:29,818:INFO:self._variable_keys: {'is_multiclass', '_ml_usecase', 'html_param', 'logging_param', 'y', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'y_test', 'target_param', '_available_plots', 'n_jobs_param', 'X', 'X_train', 'fold_generator', 'USI', 'log_plots_param', 'data', 'y_train', 'seed', 'gpu_param', 'X_test', 'idx', 'pipeline', 'memory', 'gpu_n_jobs_param', 'exp_id'}
2023-08-10 09:38:29,818:INFO:Checking environment
2023-08-10 09:38:29,819:INFO:python_version: 3.9.13
2023-08-10 09:38:29,819:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 09:38:29,819:INFO:machine: AMD64
2023-08-10 09:38:29,819:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 09:38:29,829:INFO:Memory: svmem(total=7480111104, available=930439168, percent=87.6, used=6549671936, free=930439168)
2023-08-10 09:38:29,829:INFO:Physical Core: 4
2023-08-10 09:38:29,829:INFO:Logical Core: 4
2023-08-10 09:38:29,829:INFO:Checking libraries
2023-08-10 09:38:29,830:INFO:System:
2023-08-10 09:38:29,830:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 09:38:29,830:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 09:38:29,830:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 09:38:29,830:INFO:PyCaret required dependencies:
2023-08-10 09:38:29,830:INFO:                 pip: 23.1.2
2023-08-10 09:38:29,830:INFO:          setuptools: 58.1.0
2023-08-10 09:38:29,830:INFO:             pycaret: 3.0.4
2023-08-10 09:38:29,831:INFO:             IPython: 8.13.2
2023-08-10 09:38:29,831:INFO:          ipywidgets: 8.0.7
2023-08-10 09:38:29,831:INFO:                tqdm: 4.65.0
2023-08-10 09:38:29,831:INFO:               numpy: 1.23.5
2023-08-10 09:38:29,831:INFO:              pandas: 1.5.3
2023-08-10 09:38:29,831:INFO:              jinja2: 3.1.2
2023-08-10 09:38:29,831:INFO:               scipy: 1.10.1
2023-08-10 09:38:29,831:INFO:              joblib: 1.2.0
2023-08-10 09:38:29,831:INFO:             sklearn: 1.2.2
2023-08-10 09:38:29,831:INFO:                pyod: 1.1.0
2023-08-10 09:38:29,832:INFO:            imblearn: 0.11.0
2023-08-10 09:38:29,832:INFO:   category_encoders: 2.6.1
2023-08-10 09:38:29,832:INFO:            lightgbm: 4.0.0
2023-08-10 09:38:29,832:INFO:               numba: 0.57.1
2023-08-10 09:38:29,832:INFO:            requests: 2.31.0
2023-08-10 09:38:29,832:INFO:          matplotlib: 3.7.1
2023-08-10 09:38:29,832:INFO:          scikitplot: 0.3.7
2023-08-10 09:38:29,832:INFO:         yellowbrick: 1.5
2023-08-10 09:38:29,832:INFO:              plotly: 5.15.0
2023-08-10 09:38:29,832:INFO:    plotly-resampler: Not installed
2023-08-10 09:38:29,833:INFO:             kaleido: 0.2.1
2023-08-10 09:38:29,833:INFO:           schemdraw: 0.15
2023-08-10 09:38:29,833:INFO:         statsmodels: 0.14.0
2023-08-10 09:38:29,833:INFO:              sktime: 0.20.1
2023-08-10 09:38:29,833:INFO:               tbats: 1.1.3
2023-08-10 09:38:29,833:INFO:            pmdarima: 2.0.3
2023-08-10 09:38:29,833:INFO:              psutil: 5.9.5
2023-08-10 09:38:29,833:INFO:          markupsafe: 2.1.3
2023-08-10 09:38:29,833:INFO:             pickle5: Not installed
2023-08-10 09:38:29,833:INFO:         cloudpickle: 2.2.1
2023-08-10 09:38:29,833:INFO:         deprecation: 2.1.0
2023-08-10 09:38:29,834:INFO:              xxhash: 3.2.0
2023-08-10 09:38:29,834:INFO:           wurlitzer: Not installed
2023-08-10 09:38:29,834:INFO:PyCaret optional dependencies:
2023-08-10 09:38:29,834:INFO:                shap: Not installed
2023-08-10 09:38:29,834:INFO:           interpret: 0.4.2
2023-08-10 09:38:29,834:INFO:                umap: 0.5.3
2023-08-10 09:38:29,834:INFO:    pandas_profiling: Not installed
2023-08-10 09:38:29,835:INFO:  explainerdashboard: Not installed
2023-08-10 09:38:29,835:INFO:             autoviz: Not installed
2023-08-10 09:38:29,835:INFO:           fairlearn: Not installed
2023-08-10 09:38:29,835:INFO:          deepchecks: Not installed
2023-08-10 09:38:29,835:INFO:             xgboost: 1.7.6
2023-08-10 09:38:29,835:INFO:            catboost: Not installed
2023-08-10 09:38:29,835:INFO:              kmodes: Not installed
2023-08-10 09:38:29,835:INFO:             mlxtend: 0.22.0
2023-08-10 09:38:29,835:INFO:       statsforecast: Not installed
2023-08-10 09:38:29,835:INFO:        tune_sklearn: Not installed
2023-08-10 09:38:29,836:INFO:                 ray: Not installed
2023-08-10 09:38:29,836:INFO:            hyperopt: Not installed
2023-08-10 09:38:29,836:INFO:              optuna: Not installed
2023-08-10 09:38:29,836:INFO:               skopt: Not installed
2023-08-10 09:38:29,836:INFO:              mlflow: 2.4.2
2023-08-10 09:38:29,837:INFO:              gradio: Not installed
2023-08-10 09:38:29,837:INFO:             fastapi: Not installed
2023-08-10 09:38:29,837:INFO:             uvicorn: Not installed
2023-08-10 09:38:29,837:INFO:              m2cgen: Not installed
2023-08-10 09:38:29,837:INFO:           evidently: Not installed
2023-08-10 09:38:29,837:INFO:               fugue: Not installed
2023-08-10 09:38:29,837:INFO:           streamlit: 1.25.0
2023-08-10 09:38:29,837:INFO:             prophet: Not installed
2023-08-10 09:38:29,838:INFO:None
2023-08-10 09:38:29,838:INFO:Set up data.
2023-08-10 09:38:29,870:INFO:Set up train/test split.
2023-08-10 09:38:29,891:INFO:Set up index.
2023-08-10 09:38:29,892:INFO:Set up folding strategy.
2023-08-10 09:38:29,892:INFO:Assigning column types.
2023-08-10 09:38:29,904:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 09:38:30,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 09:38:30,060:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:38:30,180:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:30,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:30,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 09:38:30,337:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:38:30,430:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:30,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:30,438:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 09:38:30,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:38:30,677:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:30,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:30,835:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 09:38:30,928:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:30,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:30,936:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 09:38:31,178:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:31,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:31,430:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:31,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:31,444:INFO:Preparing preprocessing pipeline...
2023-08-10 09:38:31,448:INFO:Set up simple imputation.
2023-08-10 09:38:31,455:INFO:Set up encoding of categorical features.
2023-08-10 09:38:31,456:INFO:Set up removing outliers.
2023-08-10 09:38:31,737:INFO:Finished creating preprocessing pipeline.
2023-08-10 09:38:31,756:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=451,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 09:38:31,756:INFO:Creating final display dataframe.
2023-08-10 09:38:36,268:INFO:Setup _display_container:                     Description            Value
0                    Session id              451
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2510, 17)
5   Transformed train set shape       (1987, 17)
6    Transformed test set shape        (523, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15              Remove outliers          iforest
16           Outliers threshold             0.05
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment    DagshubLogger
22              Experiment Name   Customer Churn
23                          USI             08d1
2023-08-10 09:38:36,582:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:36,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:36,838:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 09:38:36,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 09:38:36,851:INFO:Logging experiment in loggers
2023-08-10 09:39:25,972:INFO:SubProcess save_model() called ==================================
2023-08-10 09:39:26,010:INFO:Initializing save_model()
2023-08-10 09:39:26,010:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=451,
                                                               threshold=0.05)))],
         verbose=False), model_name=C:\Users\HP\AppData\Local\Temp\tmpkifftwgf\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=451,
                                                               threshold=0.05)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-10 09:39:26,011:INFO:Adding model into prep_pipe
2023-08-10 09:39:26,011:WARNING:Only Model saved as it was a pipeline.
2023-08-10 09:39:26,159:INFO:C:\Users\HP\AppData\Local\Temp\tmpkifftwgf\Transformation Pipeline.pkl saved in current working directory
2023-08-10 09:39:26,177:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=451,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 09:39:26,178:INFO:save_model() successfully completed......................................
2023-08-10 09:39:26,535:INFO:SubProcess save_model() end ==================================
2023-08-10 09:39:40,886:INFO:setup() successfully completed in 9.24s...............
2023-08-10 09:42:55,435:INFO:Initializing get_config()
2023-08-10 09:42:55,435:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, variable=pipeline)
2023-08-10 09:42:55,462:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=451,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 09:42:55,462:INFO:get_config() successfully completed......................................
2023-08-10 09:45:14,793:INFO:Initializing compare_models()
2023-08-10 09:45:14,793:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, include=['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, 'include': ['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 09:45:14,794:INFO:Checking exceptions
2023-08-10 09:45:14,811:INFO:Preparing display monitor
2023-08-10 09:45:14,905:INFO:Initializing Ada Boost Classifier
2023-08-10 09:45:14,905:INFO:Total runtime is 1.6645590464274088e-05 minutes
2023-08-10 09:45:14,916:INFO:SubProcess create_model() called ==================================
2023-08-10 09:45:14,917:INFO:Initializing create_model()
2023-08-10 09:45:14,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273CD1582B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:45:14,919:INFO:Checking exceptions
2023-08-10 09:45:14,919:INFO:Importing libraries
2023-08-10 09:45:14,920:INFO:Copying training dataset
2023-08-10 09:45:14,937:INFO:Defining folds
2023-08-10 09:45:14,938:INFO:Declaring metric variables
2023-08-10 09:45:14,956:INFO:Importing untrained model
2023-08-10 09:45:14,973:INFO:Ada Boost Classifier Imported successfully
2023-08-10 09:45:15,001:INFO:Starting cross validation
2023-08-10 09:45:15,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:45:31,422:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:32,870:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:32,924:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:33,007:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:36,491:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:45:36,544:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:45:36,706:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:45:41,293:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:42,981:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:43,136:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:43,512:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:45,737:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:45:47,190:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:45:47,358:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:45:47,881:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:45:52,239:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:53,927:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 09:45:57,215:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:46:04,436:INFO:Calculating mean and std
2023-08-10 09:46:04,441:INFO:Creating metrics dataframe
2023-08-10 09:46:07,373:INFO:Uploading results into container
2023-08-10 09:46:07,375:INFO:Uploading model into container now
2023-08-10 09:46:07,377:INFO:_master_model_container: 1
2023-08-10 09:46:07,377:INFO:_display_container: 2
2023-08-10 09:46:07,379:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=451)
2023-08-10 09:46:07,381:INFO:create_model() successfully completed......................................
2023-08-10 09:46:07,809:INFO:SubProcess create_model() end ==================================
2023-08-10 09:46:07,810:INFO:Creating metrics dataframe
2023-08-10 09:46:07,846:INFO:Initializing Gradient Boosting Classifier
2023-08-10 09:46:07,847:INFO:Total runtime is 0.8823759158452352 minutes
2023-08-10 09:46:07,864:INFO:SubProcess create_model() called ==================================
2023-08-10 09:46:07,868:INFO:Initializing create_model()
2023-08-10 09:46:07,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273CD1582B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:46:07,870:INFO:Checking exceptions
2023-08-10 09:46:07,871:INFO:Importing libraries
2023-08-10 09:46:07,871:INFO:Copying training dataset
2023-08-10 09:46:07,897:INFO:Defining folds
2023-08-10 09:46:07,897:INFO:Declaring metric variables
2023-08-10 09:46:07,910:INFO:Importing untrained model
2023-08-10 09:46:07,930:INFO:Gradient Boosting Classifier Imported successfully
2023-08-10 09:46:07,971:INFO:Starting cross validation
2023-08-10 09:46:08,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:46:34,477:INFO:Calculating mean and std
2023-08-10 09:46:34,483:INFO:Creating metrics dataframe
2023-08-10 09:46:37,792:INFO:Uploading results into container
2023-08-10 09:46:37,794:INFO:Uploading model into container now
2023-08-10 09:46:37,795:INFO:_master_model_container: 2
2023-08-10 09:46:37,796:INFO:_display_container: 2
2023-08-10 09:46:37,797:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=451, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-10 09:46:37,801:INFO:create_model() successfully completed......................................
2023-08-10 09:46:38,170:INFO:SubProcess create_model() end ==================================
2023-08-10 09:46:38,170:INFO:Creating metrics dataframe
2023-08-10 09:46:38,207:INFO:Initializing Extreme Gradient Boosting
2023-08-10 09:46:38,207:INFO:Total runtime is 1.3883779486020407 minutes
2023-08-10 09:46:38,220:INFO:SubProcess create_model() called ==================================
2023-08-10 09:46:38,221:INFO:Initializing create_model()
2023-08-10 09:46:38,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273CD1582B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:46:38,224:INFO:Checking exceptions
2023-08-10 09:46:38,224:INFO:Importing libraries
2023-08-10 09:46:38,225:INFO:Copying training dataset
2023-08-10 09:46:38,249:INFO:Defining folds
2023-08-10 09:46:38,250:INFO:Declaring metric variables
2023-08-10 09:46:38,268:INFO:Importing untrained model
2023-08-10 09:46:38,284:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 09:46:38,325:INFO:Starting cross validation
2023-08-10 09:46:38,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:47:03,110:INFO:Calculating mean and std
2023-08-10 09:47:03,118:INFO:Creating metrics dataframe
2023-08-10 09:47:06,087:INFO:Uploading results into container
2023-08-10 09:47:06,090:INFO:Uploading model into container now
2023-08-10 09:47:06,094:INFO:_master_model_container: 3
2023-08-10 09:47:06,094:INFO:_display_container: 2
2023-08-10 09:47:06,098:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 09:47:06,099:INFO:create_model() successfully completed......................................
2023-08-10 09:47:06,467:INFO:SubProcess create_model() end ==================================
2023-08-10 09:47:06,467:INFO:Creating metrics dataframe
2023-08-10 09:47:06,505:INFO:Initializing Random Forest Classifier
2023-08-10 09:47:06,505:INFO:Total runtime is 1.8600091695785523 minutes
2023-08-10 09:47:06,519:INFO:SubProcess create_model() called ==================================
2023-08-10 09:47:06,520:INFO:Initializing create_model()
2023-08-10 09:47:06,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273CD1582B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:47:06,521:INFO:Checking exceptions
2023-08-10 09:47:06,522:INFO:Importing libraries
2023-08-10 09:47:06,522:INFO:Copying training dataset
2023-08-10 09:47:06,557:INFO:Defining folds
2023-08-10 09:47:06,557:INFO:Declaring metric variables
2023-08-10 09:47:06,572:INFO:Importing untrained model
2023-08-10 09:47:06,588:INFO:Random Forest Classifier Imported successfully
2023-08-10 09:47:06,628:INFO:Starting cross validation
2023-08-10 09:47:06,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:47:09,284:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 09:47:09,360:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 09:47:10,801:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:47:19,799:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:47:19,924:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:47:19,978:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:47:20,244:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 09:47:21,814:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:47:39,739:INFO:Calculating mean and std
2023-08-10 09:47:39,743:INFO:Creating metrics dataframe
2023-08-10 09:47:42,764:INFO:Uploading results into container
2023-08-10 09:47:42,766:INFO:Uploading model into container now
2023-08-10 09:47:42,768:INFO:_master_model_container: 4
2023-08-10 09:47:42,768:INFO:_display_container: 2
2023-08-10 09:47:42,769:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=451, verbose=0, warm_start=False)
2023-08-10 09:47:42,769:INFO:create_model() successfully completed......................................
2023-08-10 09:47:43,138:INFO:SubProcess create_model() end ==================================
2023-08-10 09:47:43,139:INFO:Creating metrics dataframe
2023-08-10 09:47:43,191:INFO:Initializing Logistic Regression
2023-08-10 09:47:43,191:INFO:Total runtime is 2.471442524592082 minutes
2023-08-10 09:47:43,207:INFO:SubProcess create_model() called ==================================
2023-08-10 09:47:43,208:INFO:Initializing create_model()
2023-08-10 09:47:43,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273CD1582B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:47:43,209:INFO:Checking exceptions
2023-08-10 09:47:43,209:INFO:Importing libraries
2023-08-10 09:47:43,209:INFO:Copying training dataset
2023-08-10 09:47:43,232:INFO:Defining folds
2023-08-10 09:47:43,232:INFO:Declaring metric variables
2023-08-10 09:47:43,246:INFO:Importing untrained model
2023-08-10 09:47:43,264:INFO:Logistic Regression Imported successfully
2023-08-10 09:47:43,325:INFO:Starting cross validation
2023-08-10 09:47:43,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:47:52,757:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 09:48:09,829:INFO:Calculating mean and std
2023-08-10 09:48:09,833:INFO:Creating metrics dataframe
2023-08-10 09:48:12,840:INFO:Uploading results into container
2023-08-10 09:48:12,845:INFO:Uploading model into container now
2023-08-10 09:48:12,847:INFO:_master_model_container: 5
2023-08-10 09:48:12,848:INFO:_display_container: 2
2023-08-10 09:48:12,850:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 09:48:12,851:INFO:create_model() successfully completed......................................
2023-08-10 09:48:13,213:INFO:SubProcess create_model() end ==================================
2023-08-10 09:48:13,213:INFO:Creating metrics dataframe
2023-08-10 09:48:13,252:INFO:Initializing K Neighbors Classifier
2023-08-10 09:48:13,252:INFO:Total runtime is 2.9724611878395084 minutes
2023-08-10 09:48:13,264:INFO:SubProcess create_model() called ==================================
2023-08-10 09:48:13,266:INFO:Initializing create_model()
2023-08-10 09:48:13,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273CD1582B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:48:13,267:INFO:Checking exceptions
2023-08-10 09:48:13,267:INFO:Importing libraries
2023-08-10 09:48:13,267:INFO:Copying training dataset
2023-08-10 09:48:13,294:INFO:Defining folds
2023-08-10 09:48:13,295:INFO:Declaring metric variables
2023-08-10 09:48:13,312:INFO:Importing untrained model
2023-08-10 09:48:13,327:INFO:K Neighbors Classifier Imported successfully
2023-08-10 09:48:13,378:INFO:Starting cross validation
2023-08-10 09:48:13,441:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:48:37,210:INFO:Calculating mean and std
2023-08-10 09:48:37,215:INFO:Creating metrics dataframe
2023-08-10 09:48:40,240:INFO:Uploading results into container
2023-08-10 09:48:40,244:INFO:Uploading model into container now
2023-08-10 09:48:40,247:INFO:_master_model_container: 6
2023-08-10 09:48:40,247:INFO:_display_container: 2
2023-08-10 09:48:40,248:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-10 09:48:40,249:INFO:create_model() successfully completed......................................
2023-08-10 09:48:40,614:INFO:SubProcess create_model() end ==================================
2023-08-10 09:48:40,614:INFO:Creating metrics dataframe
2023-08-10 09:48:40,654:INFO:Initializing Decision Tree Classifier
2023-08-10 09:48:40,654:INFO:Total runtime is 3.42916271686554 minutes
2023-08-10 09:48:40,671:INFO:SubProcess create_model() called ==================================
2023-08-10 09:48:40,672:INFO:Initializing create_model()
2023-08-10 09:48:40,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273CD1582B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:48:40,673:INFO:Checking exceptions
2023-08-10 09:48:40,673:INFO:Importing libraries
2023-08-10 09:48:40,674:INFO:Copying training dataset
2023-08-10 09:48:40,690:INFO:Defining folds
2023-08-10 09:48:40,691:INFO:Declaring metric variables
2023-08-10 09:48:40,703:INFO:Importing untrained model
2023-08-10 09:48:40,715:INFO:Decision Tree Classifier Imported successfully
2023-08-10 09:48:40,741:INFO:Starting cross validation
2023-08-10 09:48:40,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:49:05,647:INFO:Calculating mean and std
2023-08-10 09:49:05,651:INFO:Creating metrics dataframe
2023-08-10 09:49:08,627:INFO:Uploading results into container
2023-08-10 09:49:08,629:INFO:Uploading model into container now
2023-08-10 09:49:08,630:INFO:_master_model_container: 7
2023-08-10 09:49:08,631:INFO:_display_container: 2
2023-08-10 09:49:08,631:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=451, splitter='best')
2023-08-10 09:49:08,633:INFO:create_model() successfully completed......................................
2023-08-10 09:49:09,000:INFO:SubProcess create_model() end ==================================
2023-08-10 09:49:09,001:INFO:Creating metrics dataframe
2023-08-10 09:49:09,100:INFO:Initializing create_model()
2023-08-10 09:49:09,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:49:09,101:INFO:Checking exceptions
2023-08-10 09:49:09,108:INFO:Importing libraries
2023-08-10 09:49:09,108:INFO:Copying training dataset
2023-08-10 09:49:09,137:INFO:Defining folds
2023-08-10 09:49:09,138:INFO:Declaring metric variables
2023-08-10 09:49:09,141:INFO:Importing untrained model
2023-08-10 09:49:09,142:INFO:Declaring custom model
2023-08-10 09:49:09,146:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 09:49:09,188:INFO:Cross validation set to False
2023-08-10 09:49:09,189:INFO:Fitting Model
2023-08-10 09:49:12,217:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 09:49:12,217:INFO:create_model() successfully completed......................................
2023-08-10 09:49:12,604:INFO:Creating Dashboard logs
2023-08-10 09:49:12,622:INFO:Model: Extreme Gradient Boosting
2023-08-10 09:49:13,541:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 451, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-08-10 09:49:18,988:INFO:Initializing predict_model()
2023-08-10 09:49:18,989:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000273C7C97AF0>)
2023-08-10 09:49:18,990:INFO:Checking exceptions
2023-08-10 09:49:18,990:INFO:Preloading libraries
2023-08-10 09:49:21,794:INFO:SubProcess plot_model() called ==================================
2023-08-10 09:49:21,797:INFO:Initializing plot_model()
2023-08-10 09:49:21,797:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpe3zngti1, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, system=False)
2023-08-10 09:49:21,797:INFO:Checking exceptions
2023-08-10 09:49:21,803:INFO:Preloading libraries
2023-08-10 09:49:21,818:INFO:Copying training dataset
2023-08-10 09:49:21,819:INFO:Plot type: auc
2023-08-10 09:49:22,640:INFO:Fitting Model
2023-08-10 09:49:22,644:INFO:Scoring test/hold-out set
2023-08-10 09:49:22,730:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpe3zngti1\AUC.png'
2023-08-10 09:49:23,610:INFO:Visual Rendered Successfully
2023-08-10 09:49:23,987:INFO:plot_model() successfully completed......................................
2023-08-10 09:49:24,777:INFO:Initializing plot_model()
2023-08-10 09:49:24,777:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpe3zngti1, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, system=False)
2023-08-10 09:49:24,778:INFO:Checking exceptions
2023-08-10 09:49:24,784:INFO:Preloading libraries
2023-08-10 09:49:24,798:INFO:Copying training dataset
2023-08-10 09:49:24,799:INFO:Plot type: confusion_matrix
2023-08-10 09:49:25,603:INFO:Fitting Model
2023-08-10 09:49:25,608:INFO:Scoring test/hold-out set
2023-08-10 09:49:25,678:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpe3zngti1\Confusion Matrix.png'
2023-08-10 09:49:26,092:INFO:Visual Rendered Successfully
2023-08-10 09:49:26,457:INFO:plot_model() successfully completed......................................
2023-08-10 09:49:27,010:INFO:Initializing plot_model()
2023-08-10 09:49:27,010:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpe3zngti1, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, system=False)
2023-08-10 09:49:27,010:INFO:Checking exceptions
2023-08-10 09:49:27,016:INFO:Preloading libraries
2023-08-10 09:49:27,031:INFO:Copying training dataset
2023-08-10 09:49:27,031:INFO:Plot type: feature
2023-08-10 09:49:27,033:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 09:49:27,316:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpe3zngti1\Feature Importance.png'
2023-08-10 09:49:27,996:INFO:Visual Rendered Successfully
2023-08-10 09:49:28,364:INFO:plot_model() successfully completed......................................
2023-08-10 09:49:28,941:INFO:SubProcess plot_model() end ==================================
2023-08-10 09:49:41,427:INFO:Creating Dashboard logs
2023-08-10 09:49:41,437:INFO:Model: Gradient Boosting Classifier
2023-08-10 09:49:42,275:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 451, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-08-10 09:49:58,774:INFO:Creating Dashboard logs
2023-08-10 09:49:58,784:INFO:Model: Decision Tree Classifier
2023-08-10 09:49:59,613:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 451, 'splitter': 'best'}
2023-08-10 09:50:15,210:INFO:Creating Dashboard logs
2023-08-10 09:50:15,224:INFO:Model: Random Forest Classifier
2023-08-10 09:50:16,058:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 451, 'verbose': 0, 'warm_start': False}
2023-08-10 09:50:34,811:INFO:Creating Dashboard logs
2023-08-10 09:50:34,823:INFO:Model: Ada Boost Classifier
2023-08-10 09:50:35,721:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 451}
2023-08-10 09:50:49,538:INFO:Creating Dashboard logs
2023-08-10 09:50:49,548:INFO:Model: Logistic Regression
2023-08-10 09:50:50,411:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 09:51:04,127:INFO:Creating Dashboard logs
2023-08-10 09:51:04,139:INFO:Model: K Neighbors Classifier
2023-08-10 09:51:04,947:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-08-10 09:51:18,736:INFO:_master_model_container: 7
2023-08-10 09:51:18,737:INFO:_display_container: 2
2023-08-10 09:51:18,743:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 09:51:18,744:INFO:compare_models() successfully completed......................................
2023-08-10 09:52:08,779:INFO:Initializing compare_models()
2023-08-10 09:52:08,780:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, include=['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, 'include': ['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 09:52:08,782:INFO:Checking exceptions
2023-08-10 09:52:08,791:INFO:Preparing display monitor
2023-08-10 09:52:08,881:INFO:Initializing Ada Boost Classifier
2023-08-10 09:52:08,882:INFO:Total runtime is 1.685619354248047e-05 minutes
2023-08-10 09:52:08,893:INFO:SubProcess create_model() called ==================================
2023-08-10 09:52:08,894:INFO:Initializing create_model()
2023-08-10 09:52:08,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273C717E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:52:08,895:INFO:Checking exceptions
2023-08-10 09:52:08,897:INFO:Importing libraries
2023-08-10 09:52:08,898:INFO:Copying training dataset
2023-08-10 09:52:08,916:INFO:Defining folds
2023-08-10 09:52:08,916:INFO:Declaring metric variables
2023-08-10 09:52:08,930:INFO:Importing untrained model
2023-08-10 09:52:08,950:INFO:Ada Boost Classifier Imported successfully
2023-08-10 09:52:08,977:INFO:Starting cross validation
2023-08-10 09:52:09,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:52:19,641:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 09:52:21,074:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:52:21,199:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:52:21,625:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:52:22,201:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 09:52:47,534:INFO:Calculating mean and std
2023-08-10 09:52:47,537:INFO:Creating metrics dataframe
2023-08-10 09:52:51,330:INFO:Uploading results into container
2023-08-10 09:52:51,333:INFO:Uploading model into container now
2023-08-10 09:52:51,334:INFO:_master_model_container: 8
2023-08-10 09:52:51,335:INFO:_display_container: 3
2023-08-10 09:52:51,336:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=451)
2023-08-10 09:52:51,338:INFO:create_model() successfully completed......................................
2023-08-10 09:52:52,052:INFO:SubProcess create_model() end ==================================
2023-08-10 09:52:52,053:INFO:Creating metrics dataframe
2023-08-10 09:52:52,086:INFO:Initializing Gradient Boosting Classifier
2023-08-10 09:52:52,087:INFO:Total runtime is 0.720100220044454 minutes
2023-08-10 09:52:52,101:INFO:SubProcess create_model() called ==================================
2023-08-10 09:52:52,102:INFO:Initializing create_model()
2023-08-10 09:52:52,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273C717E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:52:52,103:INFO:Checking exceptions
2023-08-10 09:52:52,103:INFO:Importing libraries
2023-08-10 09:52:52,103:INFO:Copying training dataset
2023-08-10 09:52:52,125:INFO:Defining folds
2023-08-10 09:52:52,125:INFO:Declaring metric variables
2023-08-10 09:52:52,142:INFO:Importing untrained model
2023-08-10 09:52:52,180:INFO:Gradient Boosting Classifier Imported successfully
2023-08-10 09:52:52,218:INFO:Starting cross validation
2023-08-10 09:52:52,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:53:18,011:INFO:Calculating mean and std
2023-08-10 09:53:18,014:INFO:Creating metrics dataframe
2023-08-10 09:53:20,549:INFO:Uploading results into container
2023-08-10 09:53:20,552:INFO:Uploading model into container now
2023-08-10 09:53:20,555:INFO:_master_model_container: 9
2023-08-10 09:53:20,555:INFO:_display_container: 3
2023-08-10 09:53:20,558:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=451, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-10 09:53:20,560:INFO:create_model() successfully completed......................................
2023-08-10 09:53:20,928:INFO:SubProcess create_model() end ==================================
2023-08-10 09:53:20,928:INFO:Creating metrics dataframe
2023-08-10 09:53:20,963:INFO:Initializing Extreme Gradient Boosting
2023-08-10 09:53:20,963:INFO:Total runtime is 1.2013668656349181 minutes
2023-08-10 09:53:20,980:INFO:SubProcess create_model() called ==================================
2023-08-10 09:53:20,981:INFO:Initializing create_model()
2023-08-10 09:53:20,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273C717E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:53:20,981:INFO:Checking exceptions
2023-08-10 09:53:20,982:INFO:Importing libraries
2023-08-10 09:53:20,982:INFO:Copying training dataset
2023-08-10 09:53:21,013:INFO:Defining folds
2023-08-10 09:53:21,014:INFO:Declaring metric variables
2023-08-10 09:53:21,034:INFO:Importing untrained model
2023-08-10 09:53:21,056:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 09:53:21,098:INFO:Starting cross validation
2023-08-10 09:53:21,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:53:44,167:INFO:Calculating mean and std
2023-08-10 09:53:44,170:INFO:Creating metrics dataframe
2023-08-10 09:53:46,921:INFO:Uploading results into container
2023-08-10 09:53:46,923:INFO:Uploading model into container now
2023-08-10 09:53:46,927:INFO:_master_model_container: 10
2023-08-10 09:53:46,929:INFO:_display_container: 3
2023-08-10 09:53:46,932:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 09:53:46,933:INFO:create_model() successfully completed......................................
2023-08-10 09:53:47,299:INFO:SubProcess create_model() end ==================================
2023-08-10 09:53:47,300:INFO:Creating metrics dataframe
2023-08-10 09:53:47,336:INFO:Initializing Random Forest Classifier
2023-08-10 09:53:47,336:INFO:Total runtime is 1.6409167925516763 minutes
2023-08-10 09:53:47,349:INFO:SubProcess create_model() called ==================================
2023-08-10 09:53:47,350:INFO:Initializing create_model()
2023-08-10 09:53:47,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273C717E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:53:47,351:INFO:Checking exceptions
2023-08-10 09:53:47,352:INFO:Importing libraries
2023-08-10 09:53:47,352:INFO:Copying training dataset
2023-08-10 09:53:47,380:INFO:Defining folds
2023-08-10 09:53:47,380:INFO:Declaring metric variables
2023-08-10 09:53:47,400:INFO:Importing untrained model
2023-08-10 09:53:47,420:INFO:Random Forest Classifier Imported successfully
2023-08-10 09:53:47,468:INFO:Starting cross validation
2023-08-10 09:53:47,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:54:13,180:INFO:Calculating mean and std
2023-08-10 09:54:13,184:INFO:Creating metrics dataframe
2023-08-10 09:54:16,126:INFO:Uploading results into container
2023-08-10 09:54:16,128:INFO:Uploading model into container now
2023-08-10 09:54:16,129:INFO:_master_model_container: 11
2023-08-10 09:54:16,130:INFO:_display_container: 3
2023-08-10 09:54:16,131:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=451, verbose=0, warm_start=False)
2023-08-10 09:54:16,132:INFO:create_model() successfully completed......................................
2023-08-10 09:54:16,501:INFO:SubProcess create_model() end ==================================
2023-08-10 09:54:16,501:INFO:Creating metrics dataframe
2023-08-10 09:54:16,547:INFO:Initializing Logistic Regression
2023-08-10 09:54:16,548:INFO:Total runtime is 2.1277832627296447 minutes
2023-08-10 09:54:16,562:INFO:SubProcess create_model() called ==================================
2023-08-10 09:54:16,563:INFO:Initializing create_model()
2023-08-10 09:54:16,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273C717E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:54:16,564:INFO:Checking exceptions
2023-08-10 09:54:16,565:INFO:Importing libraries
2023-08-10 09:54:16,565:INFO:Copying training dataset
2023-08-10 09:54:16,585:INFO:Defining folds
2023-08-10 09:54:16,585:INFO:Declaring metric variables
2023-08-10 09:54:16,610:INFO:Importing untrained model
2023-08-10 09:54:16,627:INFO:Logistic Regression Imported successfully
2023-08-10 09:54:16,670:INFO:Starting cross validation
2023-08-10 09:54:16,710:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:54:41,535:INFO:Calculating mean and std
2023-08-10 09:54:41,540:INFO:Creating metrics dataframe
2023-08-10 09:54:44,166:INFO:Uploading results into container
2023-08-10 09:54:44,168:INFO:Uploading model into container now
2023-08-10 09:54:44,169:INFO:_master_model_container: 12
2023-08-10 09:54:44,169:INFO:_display_container: 3
2023-08-10 09:54:44,170:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=451, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 09:54:44,171:INFO:create_model() successfully completed......................................
2023-08-10 09:54:44,531:INFO:SubProcess create_model() end ==================================
2023-08-10 09:54:44,531:INFO:Creating metrics dataframe
2023-08-10 09:54:44,576:INFO:Initializing K Neighbors Classifier
2023-08-10 09:54:44,577:INFO:Total runtime is 2.5949332912762957 minutes
2023-08-10 09:54:44,595:INFO:SubProcess create_model() called ==================================
2023-08-10 09:54:44,596:INFO:Initializing create_model()
2023-08-10 09:54:44,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273C717E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:54:44,598:INFO:Checking exceptions
2023-08-10 09:54:44,598:INFO:Importing libraries
2023-08-10 09:54:44,598:INFO:Copying training dataset
2023-08-10 09:54:44,617:INFO:Defining folds
2023-08-10 09:54:44,618:INFO:Declaring metric variables
2023-08-10 09:54:44,632:INFO:Importing untrained model
2023-08-10 09:54:44,680:INFO:K Neighbors Classifier Imported successfully
2023-08-10 09:54:44,711:INFO:Starting cross validation
2023-08-10 09:54:44,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:55:08,184:INFO:Calculating mean and std
2023-08-10 09:55:08,191:INFO:Creating metrics dataframe
2023-08-10 09:55:11,258:INFO:Uploading results into container
2023-08-10 09:55:11,259:INFO:Uploading model into container now
2023-08-10 09:55:11,261:INFO:_master_model_container: 13
2023-08-10 09:55:11,261:INFO:_display_container: 3
2023-08-10 09:55:11,262:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-10 09:55:11,262:INFO:create_model() successfully completed......................................
2023-08-10 09:55:11,617:INFO:SubProcess create_model() end ==================================
2023-08-10 09:55:11,618:INFO:Creating metrics dataframe
2023-08-10 09:55:11,668:INFO:Initializing Decision Tree Classifier
2023-08-10 09:55:11,668:INFO:Total runtime is 3.0464515050252277 minutes
2023-08-10 09:55:11,681:INFO:SubProcess create_model() called ==================================
2023-08-10 09:55:11,683:INFO:Initializing create_model()
2023-08-10 09:55:11,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000273C717E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:55:11,684:INFO:Checking exceptions
2023-08-10 09:55:11,684:INFO:Importing libraries
2023-08-10 09:55:11,685:INFO:Copying training dataset
2023-08-10 09:55:11,706:INFO:Defining folds
2023-08-10 09:55:11,707:INFO:Declaring metric variables
2023-08-10 09:55:11,721:INFO:Importing untrained model
2023-08-10 09:55:11,732:INFO:Decision Tree Classifier Imported successfully
2023-08-10 09:55:11,772:INFO:Starting cross validation
2023-08-10 09:55:11,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 09:55:34,902:INFO:Calculating mean and std
2023-08-10 09:55:34,907:INFO:Creating metrics dataframe
2023-08-10 09:55:38,029:INFO:Uploading results into container
2023-08-10 09:55:38,032:INFO:Uploading model into container now
2023-08-10 09:55:38,034:INFO:_master_model_container: 14
2023-08-10 09:55:38,037:INFO:_display_container: 3
2023-08-10 09:55:38,038:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=451, splitter='best')
2023-08-10 09:55:38,038:INFO:create_model() successfully completed......................................
2023-08-10 09:55:38,398:INFO:SubProcess create_model() end ==================================
2023-08-10 09:55:38,398:INFO:Creating metrics dataframe
2023-08-10 09:55:38,483:INFO:Initializing create_model()
2023-08-10 09:55:38,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 09:55:38,484:INFO:Checking exceptions
2023-08-10 09:55:38,493:INFO:Importing libraries
2023-08-10 09:55:38,493:INFO:Copying training dataset
2023-08-10 09:55:38,510:INFO:Defining folds
2023-08-10 09:55:38,511:INFO:Declaring metric variables
2023-08-10 09:55:38,511:INFO:Importing untrained model
2023-08-10 09:55:38,511:INFO:Declaring custom model
2023-08-10 09:55:38,515:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 09:55:38,646:INFO:Cross validation set to False
2023-08-10 09:55:38,646:INFO:Fitting Model
2023-08-10 09:55:40,896:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 09:55:40,896:INFO:create_model() successfully completed......................................
2023-08-10 09:55:41,277:INFO:Creating Dashboard logs
2023-08-10 09:55:41,294:INFO:Model: Extreme Gradient Boosting
2023-08-10 09:55:42,159:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 451, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-08-10 09:55:47,559:INFO:Initializing predict_model()
2023-08-10 09:55:47,560:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000273CD210280>)
2023-08-10 09:55:47,560:INFO:Checking exceptions
2023-08-10 09:55:47,560:INFO:Preloading libraries
2023-08-10 09:55:49,514:INFO:SubProcess plot_model() called ==================================
2023-08-10 09:55:49,517:INFO:Initializing plot_model()
2023-08-10 09:55:49,519:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp1q84g5i9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, system=False)
2023-08-10 09:55:49,519:INFO:Checking exceptions
2023-08-10 09:55:49,528:INFO:Preloading libraries
2023-08-10 09:55:49,544:INFO:Copying training dataset
2023-08-10 09:55:49,544:INFO:Plot type: auc
2023-08-10 09:55:50,304:INFO:Fitting Model
2023-08-10 09:55:50,308:INFO:Scoring test/hold-out set
2023-08-10 09:55:50,383:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp1q84g5i9\AUC.png'
2023-08-10 09:55:51,207:INFO:Visual Rendered Successfully
2023-08-10 09:55:51,573:INFO:plot_model() successfully completed......................................
2023-08-10 09:55:52,260:INFO:Initializing plot_model()
2023-08-10 09:55:52,261:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp1q84g5i9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, system=False)
2023-08-10 09:55:52,261:INFO:Checking exceptions
2023-08-10 09:55:52,268:INFO:Preloading libraries
2023-08-10 09:55:52,282:INFO:Copying training dataset
2023-08-10 09:55:52,282:INFO:Plot type: confusion_matrix
2023-08-10 09:55:53,042:INFO:Fitting Model
2023-08-10 09:55:53,045:INFO:Scoring test/hold-out set
2023-08-10 09:55:53,115:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp1q84g5i9\Confusion Matrix.png'
2023-08-10 09:55:53,520:INFO:Visual Rendered Successfully
2023-08-10 09:55:53,890:INFO:plot_model() successfully completed......................................
2023-08-10 09:55:54,446:INFO:Initializing plot_model()
2023-08-10 09:55:54,446:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp1q84g5i9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, system=False)
2023-08-10 09:55:54,446:INFO:Checking exceptions
2023-08-10 09:55:54,454:INFO:Preloading libraries
2023-08-10 09:55:54,468:INFO:Copying training dataset
2023-08-10 09:55:54,469:INFO:Plot type: feature
2023-08-10 09:55:54,472:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 09:55:54,749:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp1q84g5i9\Feature Importance.png'
2023-08-10 09:55:55,425:INFO:Visual Rendered Successfully
2023-08-10 09:55:55,783:INFO:plot_model() successfully completed......................................
2023-08-10 09:55:56,428:INFO:SubProcess plot_model() end ==================================
2023-08-10 09:56:07,571:INFO:Creating Dashboard logs
2023-08-10 09:56:07,581:INFO:Model: Gradient Boosting Classifier
2023-08-10 09:56:08,477:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 451, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-08-10 09:56:26,587:INFO:Creating Dashboard logs
2023-08-10 09:56:26,596:INFO:Model: Decision Tree Classifier
2023-08-10 09:56:27,456:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 451, 'splitter': 'best'}
2023-08-10 09:56:44,356:INFO:Creating Dashboard logs
2023-08-10 09:56:44,367:INFO:Model: Random Forest Classifier
2023-08-10 09:56:45,271:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 451, 'verbose': 0, 'warm_start': False}
2023-08-10 09:56:58,772:INFO:Creating Dashboard logs
2023-08-10 09:56:58,787:INFO:Model: Ada Boost Classifier
2023-08-10 09:56:59,619:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 451}
2023-08-10 09:57:20,074:INFO:Creating Dashboard logs
2023-08-10 09:57:20,087:INFO:Model: Logistic Regression
2023-08-10 09:57:20,934:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 451, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 09:57:34,384:INFO:Creating Dashboard logs
2023-08-10 09:57:34,394:INFO:Model: K Neighbors Classifier
2023-08-10 09:57:35,240:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-08-10 09:57:51,276:INFO:_master_model_container: 14
2023-08-10 09:57:51,277:INFO:_display_container: 3
2023-08-10 09:57:51,283:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 09:57:51,283:INFO:compare_models() successfully completed......................................
2023-08-10 11:20:50,249:INFO:Initializing create_model()
2023-08-10 11:20:50,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=xgboost, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 11:20:50,254:INFO:Checking exceptions
2023-08-10 11:20:50,460:INFO:Importing libraries
2023-08-10 11:20:50,461:INFO:Copying training dataset
2023-08-10 11:20:50,517:INFO:Defining folds
2023-08-10 11:20:50,518:INFO:Declaring metric variables
2023-08-10 11:20:50,539:INFO:Importing untrained model
2023-08-10 11:20:50,571:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 11:20:50,774:INFO:Cross validation set to False
2023-08-10 11:20:50,775:INFO:Fitting Model
2023-08-10 11:20:51,235:INFO:Initializing predict_model()
2023-08-10 11:20:51,235:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000273CD214940>)
2023-08-10 11:20:51,235:INFO:Checking exceptions
2023-08-10 11:20:51,235:INFO:Preloading libraries
2023-08-10 11:20:51,237:INFO:Set up data.
2023-08-10 11:20:51,259:INFO:Set up index.
2023-08-10 11:20:52,801:INFO:Initializing predict_model()
2023-08-10 11:20:52,802:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000273CCE805E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000273CD214940>)
2023-08-10 11:20:52,802:INFO:Checking exceptions
2023-08-10 11:20:52,802:INFO:Preloading libraries
2023-08-10 11:20:53,724:INFO:_display_container: 4
2023-08-10 11:20:56,347:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 11:20:56,348:INFO:create_model() successfully completed......................................
2023-08-10 11:34:45,381:INFO:PyCaret AnomalyExperiment
2023-08-10 11:34:45,381:INFO:Logging name: anomaly-default-name
2023-08-10 11:34:45,381:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 11:34:45,381:INFO:version 3.0.4
2023-08-10 11:34:45,382:INFO:Initializing setup()
2023-08-10 11:34:45,382:INFO:self.USI: e280
2023-08-10 11:34:45,382:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'logging_param', 'exp_name_log', '_available_plots', 'n_jobs_param', 'X', 'USI', 'log_plots_param', 'data', 'seed', 'gpu_param', 'idx', 'pipeline', 'memory', 'gpu_n_jobs_param', 'exp_id'}
2023-08-10 11:34:45,382:INFO:Checking environment
2023-08-10 11:34:45,382:INFO:python_version: 3.9.13
2023-08-10 11:34:45,382:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 11:34:45,382:INFO:machine: AMD64
2023-08-10 11:34:45,383:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 11:34:45,393:INFO:Memory: svmem(total=7480111104, available=1320267776, percent=82.3, used=6159843328, free=1320267776)
2023-08-10 11:34:45,393:INFO:Physical Core: 4
2023-08-10 11:34:45,394:INFO:Logical Core: 4
2023-08-10 11:34:45,394:INFO:Checking libraries
2023-08-10 11:34:45,394:INFO:System:
2023-08-10 11:34:45,394:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 11:34:45,394:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 11:34:45,394:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 11:34:45,394:INFO:PyCaret required dependencies:
2023-08-10 11:34:45,395:INFO:                 pip: 23.1.2
2023-08-10 11:34:45,395:INFO:          setuptools: 58.1.0
2023-08-10 11:34:45,395:INFO:             pycaret: 3.0.4
2023-08-10 11:34:45,395:INFO:             IPython: 8.13.2
2023-08-10 11:34:45,395:INFO:          ipywidgets: 8.0.7
2023-08-10 11:34:45,395:INFO:                tqdm: 4.65.0
2023-08-10 11:34:45,395:INFO:               numpy: 1.23.5
2023-08-10 11:34:45,395:INFO:              pandas: 1.5.3
2023-08-10 11:34:45,395:INFO:              jinja2: 3.1.2
2023-08-10 11:34:45,396:INFO:               scipy: 1.10.1
2023-08-10 11:34:45,396:INFO:              joblib: 1.2.0
2023-08-10 11:34:45,396:INFO:             sklearn: 1.2.2
2023-08-10 11:34:45,396:INFO:                pyod: 1.1.0
2023-08-10 11:34:45,396:INFO:            imblearn: 0.11.0
2023-08-10 11:34:45,396:INFO:   category_encoders: 2.6.1
2023-08-10 11:34:45,396:INFO:            lightgbm: 4.0.0
2023-08-10 11:34:45,396:INFO:               numba: 0.57.1
2023-08-10 11:34:45,396:INFO:            requests: 2.31.0
2023-08-10 11:34:45,397:INFO:          matplotlib: 3.7.1
2023-08-10 11:34:45,397:INFO:          scikitplot: 0.3.7
2023-08-10 11:34:45,397:INFO:         yellowbrick: 1.5
2023-08-10 11:34:45,397:INFO:              plotly: 5.15.0
2023-08-10 11:34:45,397:INFO:    plotly-resampler: Not installed
2023-08-10 11:34:45,397:INFO:             kaleido: 0.2.1
2023-08-10 11:34:45,397:INFO:           schemdraw: 0.15
2023-08-10 11:34:45,397:INFO:         statsmodels: 0.14.0
2023-08-10 11:34:45,397:INFO:              sktime: 0.20.1
2023-08-10 11:34:45,398:INFO:               tbats: 1.1.3
2023-08-10 11:34:45,398:INFO:            pmdarima: 2.0.3
2023-08-10 11:34:45,398:INFO:              psutil: 5.9.5
2023-08-10 11:34:45,398:INFO:          markupsafe: 2.1.3
2023-08-10 11:34:45,398:INFO:             pickle5: Not installed
2023-08-10 11:34:45,398:INFO:         cloudpickle: 2.2.1
2023-08-10 11:34:45,398:INFO:         deprecation: 2.1.0
2023-08-10 11:34:45,398:INFO:              xxhash: 3.2.0
2023-08-10 11:34:45,398:INFO:           wurlitzer: Not installed
2023-08-10 11:34:45,398:INFO:PyCaret optional dependencies:
2023-08-10 11:34:45,399:INFO:                shap: Not installed
2023-08-10 11:34:45,399:INFO:           interpret: 0.4.2
2023-08-10 11:34:45,399:INFO:                umap: 0.5.3
2023-08-10 11:34:45,399:INFO:    pandas_profiling: Not installed
2023-08-10 11:34:45,399:INFO:  explainerdashboard: Not installed
2023-08-10 11:34:45,399:INFO:             autoviz: Not installed
2023-08-10 11:34:45,399:INFO:           fairlearn: Not installed
2023-08-10 11:34:45,399:INFO:          deepchecks: Not installed
2023-08-10 11:34:45,400:INFO:             xgboost: 1.7.6
2023-08-10 11:34:45,400:INFO:            catboost: Not installed
2023-08-10 11:34:45,400:INFO:              kmodes: Not installed
2023-08-10 11:34:45,400:INFO:             mlxtend: 0.22.0
2023-08-10 11:34:45,400:INFO:       statsforecast: Not installed
2023-08-10 11:34:45,400:INFO:        tune_sklearn: Not installed
2023-08-10 11:34:45,400:INFO:                 ray: Not installed
2023-08-10 11:34:45,400:INFO:            hyperopt: Not installed
2023-08-10 11:34:45,400:INFO:              optuna: Not installed
2023-08-10 11:34:45,400:INFO:               skopt: Not installed
2023-08-10 11:34:45,401:INFO:              mlflow: 2.4.2
2023-08-10 11:34:45,401:INFO:              gradio: Not installed
2023-08-10 11:34:45,401:INFO:             fastapi: Not installed
2023-08-10 11:34:45,401:INFO:             uvicorn: Not installed
2023-08-10 11:34:45,401:INFO:              m2cgen: Not installed
2023-08-10 11:34:45,401:INFO:           evidently: Not installed
2023-08-10 11:34:45,401:INFO:               fugue: Not installed
2023-08-10 11:34:45,401:INFO:           streamlit: 1.25.0
2023-08-10 11:34:45,402:INFO:             prophet: Not installed
2023-08-10 11:34:45,402:INFO:None
2023-08-10 11:34:45,402:INFO:Set up data.
2023-08-10 11:34:45,419:INFO:Set up index.
2023-08-10 11:34:45,421:INFO:Assigning column types.
2023-08-10 11:34:45,429:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 11:34:45,430:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 11:34:45,434:INFO:Preparing preprocessing pipeline...
2023-08-10 11:34:45,435:INFO:Set up simple imputation.
2023-08-10 11:34:45,441:INFO:Set up encoding of categorical features.
2023-08-10 11:34:45,565:INFO:Finished creating preprocessing pipeline.
2023-08-10 11:34:45,581:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              f...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-10 11:34:45,581:INFO:Creating final display dataframe.
2023-08-10 11:34:45,630:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  1698
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  e280
2023-08-10 11:34:45,632:INFO:setup() successfully completed in 2.12s...............
2023-08-10 11:34:47,330:INFO:Initializing create_model()
2023-08-10 11:34:47,330:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFD39760>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 11:34:47,331:INFO:Checking exceptions
2023-08-10 11:34:47,376:INFO:Importing untrained model
2023-08-10 11:34:47,378:INFO:Isolation Forest Imported successfully
2023-08-10 11:34:47,381:INFO:Fitting Model
2023-08-10 11:34:49,406:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=1698, verbose=0)
2023-08-10 11:34:49,406:INFO:create_models() successfully completed......................................
2023-08-10 11:34:49,406:INFO:Uploading results into container
2023-08-10 11:34:49,407:INFO:Uploading model into container now
2023-08-10 11:34:49,407:INFO:_master_model_container: 1
2023-08-10 11:34:49,407:INFO:_display_container: 1
2023-08-10 11:34:49,408:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=1698, verbose=0)
2023-08-10 11:34:49,408:INFO:create_model() successfully completed......................................
2023-08-10 11:34:51,642:INFO:Initializing plot_model()
2023-08-10 11:34:51,642:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=1698, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFD39760>, system=True)
2023-08-10 11:34:51,642:INFO:Checking exceptions
2023-08-10 11:34:57,697:INFO:Preloading libraries
2023-08-10 11:34:57,755:INFO:Copying training dataset
2023-08-10 11:34:57,755:INFO:Plot type: umap
2023-08-10 11:34:57,757:INFO:SubProcess assign_model() called ==================================
2023-08-10 11:34:57,758:INFO:Initializing assign_model()
2023-08-10 11:34:57,758:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFD39760>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=1698, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 11:34:57,758:INFO:Checking exceptions
2023-08-10 11:34:57,758:INFO:Determining Trained Model
2023-08-10 11:34:57,759:INFO:Trained Model : Isolation Forest
2023-08-10 11:34:57,759:INFO:Copying data
2023-08-10 11:34:57,796:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 11:34:57,798:INFO:(3941, 18)
2023-08-10 11:34:57,798:INFO:assign_model() successfully completed......................................
2023-08-10 11:34:57,799:INFO:SubProcess assign_model() end ==================================
2023-08-10 11:34:57,806:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 11:34:57,807:INFO:Fitting UMAP()
2023-08-10 11:35:36,122:INFO:Rendering Visual
2023-08-10 11:35:36,332:INFO:Visual Rendered Successfully
2023-08-10 11:35:36,875:INFO:plot_model() successfully completed......................................
2023-08-10 11:35:37,056:INFO:Initializing assign_model()
2023-08-10 11:35:37,056:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFD39760>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=1698, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 11:35:37,056:INFO:Checking exceptions
2023-08-10 11:35:37,057:INFO:Determining Trained Model
2023-08-10 11:35:37,057:INFO:Trained Model : Isolation Forest
2023-08-10 11:35:37,058:INFO:Copying data
2023-08-10 11:35:37,064:INFO:(3941, 13)
2023-08-10 11:35:37,065:INFO:assign_model() successfully completed......................................
2023-08-10 12:28:19,840:INFO:PyCaret AnomalyExperiment
2023-08-10 12:28:19,848:INFO:Logging name: anomaly-default-name
2023-08-10 12:28:19,848:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 12:28:19,848:INFO:version 3.0.4
2023-08-10 12:28:19,848:INFO:Initializing setup()
2023-08-10 12:28:19,848:INFO:self.USI: 21cd
2023-08-10 12:28:19,848:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'logging_param', 'exp_name_log', '_available_plots', 'n_jobs_param', 'X', 'USI', 'log_plots_param', 'data', 'seed', 'gpu_param', 'idx', 'pipeline', 'memory', 'gpu_n_jobs_param', 'exp_id'}
2023-08-10 12:28:19,848:INFO:Checking environment
2023-08-10 12:28:19,848:INFO:python_version: 3.9.13
2023-08-10 12:28:19,848:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:28:19,848:INFO:machine: AMD64
2023-08-10 12:28:19,848:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:28:19,864:INFO:Memory: svmem(total=7480111104, available=2118086656, percent=71.7, used=5362024448, free=2118086656)
2023-08-10 12:28:19,864:INFO:Physical Core: 4
2023-08-10 12:28:19,864:INFO:Logical Core: 4
2023-08-10 12:28:19,864:INFO:Checking libraries
2023-08-10 12:28:19,864:INFO:System:
2023-08-10 12:28:19,864:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:28:19,864:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:28:19,864:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:28:19,864:INFO:PyCaret required dependencies:
2023-08-10 12:28:19,864:INFO:                 pip: 23.1.2
2023-08-10 12:28:19,864:INFO:          setuptools: 58.1.0
2023-08-10 12:28:19,864:INFO:             pycaret: 3.0.4
2023-08-10 12:28:19,864:INFO:             IPython: 8.13.2
2023-08-10 12:28:19,864:INFO:          ipywidgets: 8.0.7
2023-08-10 12:28:19,864:INFO:                tqdm: 4.65.0
2023-08-10 12:28:19,864:INFO:               numpy: 1.23.5
2023-08-10 12:28:19,864:INFO:              pandas: 1.5.3
2023-08-10 12:28:19,864:INFO:              jinja2: 3.1.2
2023-08-10 12:28:19,864:INFO:               scipy: 1.10.1
2023-08-10 12:28:19,864:INFO:              joblib: 1.2.0
2023-08-10 12:28:19,864:INFO:             sklearn: 1.2.2
2023-08-10 12:28:19,864:INFO:                pyod: 1.1.0
2023-08-10 12:28:19,864:INFO:            imblearn: 0.11.0
2023-08-10 12:28:19,864:INFO:   category_encoders: 2.6.1
2023-08-10 12:28:19,864:INFO:            lightgbm: 4.0.0
2023-08-10 12:28:19,864:INFO:               numba: 0.57.1
2023-08-10 12:28:19,864:INFO:            requests: 2.31.0
2023-08-10 12:28:19,864:INFO:          matplotlib: 3.7.1
2023-08-10 12:28:19,864:INFO:          scikitplot: 0.3.7
2023-08-10 12:28:19,864:INFO:         yellowbrick: 1.5
2023-08-10 12:28:19,864:INFO:              plotly: 5.15.0
2023-08-10 12:28:19,864:INFO:    plotly-resampler: Not installed
2023-08-10 12:28:19,864:INFO:             kaleido: 0.2.1
2023-08-10 12:28:19,864:INFO:           schemdraw: 0.15
2023-08-10 12:28:19,864:INFO:         statsmodels: 0.14.0
2023-08-10 12:28:19,864:INFO:              sktime: 0.20.1
2023-08-10 12:28:19,864:INFO:               tbats: 1.1.3
2023-08-10 12:28:19,872:INFO:            pmdarima: 2.0.3
2023-08-10 12:28:19,872:INFO:              psutil: 5.9.5
2023-08-10 12:28:19,872:INFO:          markupsafe: 2.1.3
2023-08-10 12:28:19,872:INFO:             pickle5: Not installed
2023-08-10 12:28:19,872:INFO:         cloudpickle: 2.2.1
2023-08-10 12:28:19,872:INFO:         deprecation: 2.1.0
2023-08-10 12:28:19,872:INFO:              xxhash: 3.2.0
2023-08-10 12:28:19,872:INFO:           wurlitzer: Not installed
2023-08-10 12:28:19,872:INFO:PyCaret optional dependencies:
2023-08-10 12:28:19,872:INFO:                shap: Not installed
2023-08-10 12:28:19,872:INFO:           interpret: 0.4.2
2023-08-10 12:28:19,872:INFO:                umap: 0.5.3
2023-08-10 12:28:19,872:INFO:    pandas_profiling: Not installed
2023-08-10 12:28:19,872:INFO:  explainerdashboard: Not installed
2023-08-10 12:28:19,872:INFO:             autoviz: Not installed
2023-08-10 12:28:19,872:INFO:           fairlearn: Not installed
2023-08-10 12:28:19,872:INFO:          deepchecks: Not installed
2023-08-10 12:28:19,872:INFO:             xgboost: 1.7.6
2023-08-10 12:28:19,872:INFO:            catboost: Not installed
2023-08-10 12:28:19,872:INFO:              kmodes: Not installed
2023-08-10 12:28:19,872:INFO:             mlxtend: 0.22.0
2023-08-10 12:28:19,872:INFO:       statsforecast: Not installed
2023-08-10 12:28:19,872:INFO:        tune_sklearn: Not installed
2023-08-10 12:28:19,872:INFO:                 ray: Not installed
2023-08-10 12:28:19,872:INFO:            hyperopt: Not installed
2023-08-10 12:28:19,872:INFO:              optuna: Not installed
2023-08-10 12:28:19,872:INFO:               skopt: Not installed
2023-08-10 12:28:19,872:INFO:              mlflow: 2.4.2
2023-08-10 12:28:19,872:INFO:              gradio: Not installed
2023-08-10 12:28:19,872:INFO:             fastapi: Not installed
2023-08-10 12:28:19,872:INFO:             uvicorn: Not installed
2023-08-10 12:28:19,872:INFO:              m2cgen: Not installed
2023-08-10 12:28:19,872:INFO:           evidently: Not installed
2023-08-10 12:28:19,872:INFO:               fugue: Not installed
2023-08-10 12:28:19,872:INFO:           streamlit: 1.25.0
2023-08-10 12:28:19,872:INFO:             prophet: Not installed
2023-08-10 12:28:19,872:INFO:None
2023-08-10 12:28:19,872:INFO:Set up data.
2023-08-10 12:28:19,896:INFO:Set up index.
2023-08-10 12:28:19,896:INFO:Assigning column types.
2023-08-10 12:28:19,904:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 12:28:19,904:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 12:28:19,912:INFO:Preparing preprocessing pipeline...
2023-08-10 12:28:19,912:INFO:Set up simple imputation.
2023-08-10 12:28:19,912:INFO:Set up encoding of categorical features.
2023-08-10 12:28:20,080:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:28:20,096:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              f...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-10 12:28:20,096:INFO:Creating final display dataframe.
2023-08-10 12:28:20,160:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  8306
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  21cd
2023-08-10 12:28:20,160:INFO:setup() successfully completed in 2.39s...............
2023-08-10 12:28:21,272:INFO:Initializing create_model()
2023-08-10 12:28:21,281:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CDEC7580>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 12:28:21,281:INFO:Checking exceptions
2023-08-10 12:28:21,305:INFO:Importing untrained model
2023-08-10 12:28:21,305:INFO:Isolation Forest Imported successfully
2023-08-10 12:28:21,313:INFO:Fitting Model
2023-08-10 12:28:22,872:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8306, verbose=0)
2023-08-10 12:28:22,872:INFO:create_models() successfully completed......................................
2023-08-10 12:28:22,872:INFO:Uploading results into container
2023-08-10 12:28:22,872:INFO:Uploading model into container now
2023-08-10 12:28:22,872:INFO:_master_model_container: 1
2023-08-10 12:28:22,872:INFO:_display_container: 1
2023-08-10 12:28:22,872:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8306, verbose=0)
2023-08-10 12:28:22,872:INFO:create_model() successfully completed......................................
2023-08-10 12:28:24,352:INFO:Initializing plot_model()
2023-08-10 12:28:24,352:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8306, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CDEC7580>, system=True)
2023-08-10 12:28:24,352:INFO:Checking exceptions
2023-08-10 12:28:36,440:INFO:Preloading libraries
2023-08-10 12:28:36,464:INFO:Copying training dataset
2023-08-10 12:28:36,464:INFO:Plot type: umap
2023-08-10 12:28:36,464:INFO:SubProcess assign_model() called ==================================
2023-08-10 12:28:36,464:INFO:Initializing assign_model()
2023-08-10 12:28:36,464:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CDEC7580>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8306, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 12:28:36,464:INFO:Checking exceptions
2023-08-10 12:28:36,464:INFO:Determining Trained Model
2023-08-10 12:28:36,464:INFO:Trained Model : Isolation Forest
2023-08-10 12:28:36,464:INFO:Copying data
2023-08-10 12:28:36,496:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 12:28:36,496:INFO:(3941, 18)
2023-08-10 12:28:36,496:INFO:assign_model() successfully completed......................................
2023-08-10 12:28:36,496:INFO:SubProcess assign_model() end ==================================
2023-08-10 12:28:36,496:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 12:28:36,496:INFO:Fitting UMAP()
2023-08-10 12:29:09,953:INFO:Rendering Visual
2023-08-10 12:29:10,113:INFO:Visual Rendered Successfully
2023-08-10 12:29:10,617:INFO:plot_model() successfully completed......................................
2023-08-10 12:29:10,785:INFO:Initializing assign_model()
2023-08-10 12:29:10,785:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CDEC7580>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=8306, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 12:29:10,785:INFO:Checking exceptions
2023-08-10 12:29:10,785:INFO:Determining Trained Model
2023-08-10 12:29:10,785:INFO:Trained Model : Isolation Forest
2023-08-10 12:29:10,785:INFO:Copying data
2023-08-10 12:29:10,793:INFO:(3941, 13)
2023-08-10 12:29:10,793:INFO:assign_model() successfully completed......................................
2023-08-10 12:30:19,037:INFO:PyCaret AnomalyExperiment
2023-08-10 12:30:19,037:INFO:Logging name: anomaly-default-name
2023-08-10 12:30:19,037:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 12:30:19,037:INFO:version 3.0.4
2023-08-10 12:30:19,037:INFO:Initializing setup()
2023-08-10 12:30:19,037:INFO:self.USI: f6ee
2023-08-10 12:30:19,037:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'logging_param', 'exp_name_log', '_available_plots', 'n_jobs_param', 'X', 'USI', 'log_plots_param', 'data', 'seed', 'gpu_param', 'idx', 'pipeline', 'memory', 'gpu_n_jobs_param', 'exp_id'}
2023-08-10 12:30:19,037:INFO:Checking environment
2023-08-10 12:30:19,037:INFO:python_version: 3.9.13
2023-08-10 12:30:19,037:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:30:19,037:INFO:machine: AMD64
2023-08-10 12:30:19,037:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:30:19,045:INFO:Memory: svmem(total=7480111104, available=1633169408, percent=78.2, used=5846941696, free=1633169408)
2023-08-10 12:30:19,045:INFO:Physical Core: 4
2023-08-10 12:30:19,045:INFO:Logical Core: 4
2023-08-10 12:30:19,045:INFO:Checking libraries
2023-08-10 12:30:19,045:INFO:System:
2023-08-10 12:30:19,045:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:30:19,045:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:30:19,045:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:30:19,045:INFO:PyCaret required dependencies:
2023-08-10 12:30:19,045:INFO:                 pip: 23.1.2
2023-08-10 12:30:19,045:INFO:          setuptools: 58.1.0
2023-08-10 12:30:19,045:INFO:             pycaret: 3.0.4
2023-08-10 12:30:19,045:INFO:             IPython: 8.13.2
2023-08-10 12:30:19,045:INFO:          ipywidgets: 8.0.7
2023-08-10 12:30:19,045:INFO:                tqdm: 4.65.0
2023-08-10 12:30:19,045:INFO:               numpy: 1.23.5
2023-08-10 12:30:19,045:INFO:              pandas: 1.5.3
2023-08-10 12:30:19,045:INFO:              jinja2: 3.1.2
2023-08-10 12:30:19,045:INFO:               scipy: 1.10.1
2023-08-10 12:30:19,045:INFO:              joblib: 1.2.0
2023-08-10 12:30:19,045:INFO:             sklearn: 1.2.2
2023-08-10 12:30:19,045:INFO:                pyod: 1.1.0
2023-08-10 12:30:19,045:INFO:            imblearn: 0.11.0
2023-08-10 12:30:19,045:INFO:   category_encoders: 2.6.1
2023-08-10 12:30:19,045:INFO:            lightgbm: 4.0.0
2023-08-10 12:30:19,045:INFO:               numba: 0.57.1
2023-08-10 12:30:19,053:INFO:            requests: 2.31.0
2023-08-10 12:30:19,053:INFO:          matplotlib: 3.7.1
2023-08-10 12:30:19,053:INFO:          scikitplot: 0.3.7
2023-08-10 12:30:19,053:INFO:         yellowbrick: 1.5
2023-08-10 12:30:19,053:INFO:              plotly: 5.15.0
2023-08-10 12:30:19,053:INFO:    plotly-resampler: Not installed
2023-08-10 12:30:19,053:INFO:             kaleido: 0.2.1
2023-08-10 12:30:19,053:INFO:           schemdraw: 0.15
2023-08-10 12:30:19,053:INFO:         statsmodels: 0.14.0
2023-08-10 12:30:19,053:INFO:              sktime: 0.20.1
2023-08-10 12:30:19,053:INFO:               tbats: 1.1.3
2023-08-10 12:30:19,053:INFO:            pmdarima: 2.0.3
2023-08-10 12:30:19,053:INFO:              psutil: 5.9.5
2023-08-10 12:30:19,053:INFO:          markupsafe: 2.1.3
2023-08-10 12:30:19,053:INFO:             pickle5: Not installed
2023-08-10 12:30:19,053:INFO:         cloudpickle: 2.2.1
2023-08-10 12:30:19,053:INFO:         deprecation: 2.1.0
2023-08-10 12:30:19,053:INFO:              xxhash: 3.2.0
2023-08-10 12:30:19,053:INFO:           wurlitzer: Not installed
2023-08-10 12:30:19,053:INFO:PyCaret optional dependencies:
2023-08-10 12:30:19,053:INFO:                shap: Not installed
2023-08-10 12:30:19,053:INFO:           interpret: 0.4.2
2023-08-10 12:30:19,053:INFO:                umap: 0.5.3
2023-08-10 12:30:19,053:INFO:    pandas_profiling: Not installed
2023-08-10 12:30:19,053:INFO:  explainerdashboard: Not installed
2023-08-10 12:30:19,053:INFO:             autoviz: Not installed
2023-08-10 12:30:19,053:INFO:           fairlearn: Not installed
2023-08-10 12:30:19,053:INFO:          deepchecks: Not installed
2023-08-10 12:30:19,053:INFO:             xgboost: 1.7.6
2023-08-10 12:30:19,053:INFO:            catboost: Not installed
2023-08-10 12:30:19,053:INFO:              kmodes: Not installed
2023-08-10 12:30:19,053:INFO:             mlxtend: 0.22.0
2023-08-10 12:30:19,053:INFO:       statsforecast: Not installed
2023-08-10 12:30:19,053:INFO:        tune_sklearn: Not installed
2023-08-10 12:30:19,053:INFO:                 ray: Not installed
2023-08-10 12:30:19,053:INFO:            hyperopt: Not installed
2023-08-10 12:30:19,053:INFO:              optuna: Not installed
2023-08-10 12:30:19,053:INFO:               skopt: Not installed
2023-08-10 12:30:19,053:INFO:              mlflow: 2.4.2
2023-08-10 12:30:19,053:INFO:              gradio: Not installed
2023-08-10 12:30:19,053:INFO:             fastapi: Not installed
2023-08-10 12:30:19,053:INFO:             uvicorn: Not installed
2023-08-10 12:30:19,053:INFO:              m2cgen: Not installed
2023-08-10 12:30:19,053:INFO:           evidently: Not installed
2023-08-10 12:30:19,053:INFO:               fugue: Not installed
2023-08-10 12:30:19,053:INFO:           streamlit: 1.25.0
2023-08-10 12:30:19,053:INFO:             prophet: Not installed
2023-08-10 12:30:19,053:INFO:None
2023-08-10 12:30:19,053:INFO:Set up data.
2023-08-10 12:30:19,061:INFO:Set up index.
2023-08-10 12:30:19,061:INFO:Assigning column types.
2023-08-10 12:30:19,069:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 12:30:19,069:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 12:30:19,078:INFO:Preparing preprocessing pipeline...
2023-08-10 12:30:19,078:INFO:Set up simple imputation.
2023-08-10 12:30:19,078:INFO:Set up encoding of categorical features.
2023-08-10 12:30:19,166:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:30:19,173:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              f...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-10 12:30:19,173:INFO:Creating final display dataframe.
2023-08-10 12:30:19,205:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  4825
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  f6ee
2023-08-10 12:30:19,205:INFO:setup() successfully completed in 1.36s...............
2023-08-10 12:30:20,440:INFO:Initializing create_model()
2023-08-10 12:30:20,440:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFE696D0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 12:30:20,440:INFO:Checking exceptions
2023-08-10 12:30:20,472:INFO:Importing untrained model
2023-08-10 12:30:20,480:INFO:Isolation Forest Imported successfully
2023-08-10 12:30:20,480:INFO:Fitting Model
2023-08-10 12:30:22,160:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4825, verbose=0)
2023-08-10 12:30:22,160:INFO:create_models() successfully completed......................................
2023-08-10 12:30:22,160:INFO:Uploading results into container
2023-08-10 12:30:22,160:INFO:Uploading model into container now
2023-08-10 12:30:22,160:INFO:_master_model_container: 1
2023-08-10 12:30:22,160:INFO:_display_container: 1
2023-08-10 12:30:22,160:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4825, verbose=0)
2023-08-10 12:30:22,160:INFO:create_model() successfully completed......................................
2023-08-10 12:30:24,432:INFO:Initializing plot_model()
2023-08-10 12:30:24,432:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4825, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFE696D0>, system=True)
2023-08-10 12:30:24,432:INFO:Checking exceptions
2023-08-10 12:30:24,624:INFO:Preloading libraries
2023-08-10 12:30:24,656:INFO:Copying training dataset
2023-08-10 12:30:24,656:INFO:Plot type: umap
2023-08-10 12:30:24,656:INFO:SubProcess assign_model() called ==================================
2023-08-10 12:30:24,656:INFO:Initializing assign_model()
2023-08-10 12:30:24,656:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFE696D0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4825, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 12:30:24,656:INFO:Checking exceptions
2023-08-10 12:30:24,656:INFO:Determining Trained Model
2023-08-10 12:30:24,656:INFO:Trained Model : Isolation Forest
2023-08-10 12:30:24,656:INFO:Copying data
2023-08-10 12:30:24,712:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 12:30:24,712:INFO:(3941, 18)
2023-08-10 12:30:24,712:INFO:assign_model() successfully completed......................................
2023-08-10 12:30:24,720:INFO:SubProcess assign_model() end ==================================
2023-08-10 12:30:24,728:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 12:30:24,728:INFO:Fitting UMAP()
2023-08-10 12:31:03,356:INFO:Rendering Visual
2023-08-10 12:31:03,532:INFO:Visual Rendered Successfully
2023-08-10 12:31:04,084:INFO:plot_model() successfully completed......................................
2023-08-10 12:31:05,108:INFO:Initializing assign_model()
2023-08-10 12:31:05,108:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x00000273CFE696D0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4825, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 12:31:05,108:INFO:Checking exceptions
2023-08-10 12:31:05,108:INFO:Determining Trained Model
2023-08-10 12:31:05,108:INFO:Trained Model : Isolation Forest
2023-08-10 12:31:05,108:INFO:Copying data
2023-08-10 12:31:05,116:INFO:(3941, 13)
2023-08-10 12:31:05,116:INFO:assign_model() successfully completed......................................
2023-08-10 12:33:46,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:33:46,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:33:46,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:33:46,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:34:19,960:INFO:PyCaret AnomalyExperiment
2023-08-10 12:34:19,960:INFO:Logging name: anomaly-default-name
2023-08-10 12:34:19,960:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 12:34:19,968:INFO:version 3.0.4
2023-08-10 12:34:19,968:INFO:Initializing setup()
2023-08-10 12:34:19,968:INFO:self.USI: 3c1d
2023-08-10 12:34:19,968:INFO:self._variable_keys: {'idx', 'gpu_n_jobs_param', 'logging_param', 'exp_name_log', 'memory', 'seed', 'exp_id', 'data', 'gpu_param', 'USI', 'n_jobs_param', '_ml_usecase', 'pipeline', 'X', 'log_plots_param', '_available_plots', 'html_param'}
2023-08-10 12:34:19,968:INFO:Checking environment
2023-08-10 12:34:19,968:INFO:python_version: 3.9.13
2023-08-10 12:34:19,968:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:34:19,968:INFO:machine: AMD64
2023-08-10 12:34:19,968:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:34:19,976:INFO:Memory: svmem(total=7480111104, available=1354330112, percent=81.9, used=6125780992, free=1354330112)
2023-08-10 12:34:19,976:INFO:Physical Core: 4
2023-08-10 12:34:19,976:INFO:Logical Core: 4
2023-08-10 12:34:19,976:INFO:Checking libraries
2023-08-10 12:34:19,976:INFO:System:
2023-08-10 12:34:19,976:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:34:19,976:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:34:19,976:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:34:19,976:INFO:PyCaret required dependencies:
2023-08-10 12:34:20,344:INFO:                 pip: 23.1.2
2023-08-10 12:34:20,344:INFO:          setuptools: 58.1.0
2023-08-10 12:34:20,344:INFO:             pycaret: 3.0.4
2023-08-10 12:34:20,344:INFO:             IPython: 8.13.2
2023-08-10 12:34:20,344:INFO:          ipywidgets: 8.0.7
2023-08-10 12:34:20,344:INFO:                tqdm: 4.65.0
2023-08-10 12:34:20,344:INFO:               numpy: 1.23.5
2023-08-10 12:34:20,344:INFO:              pandas: 1.5.3
2023-08-10 12:34:20,344:INFO:              jinja2: 3.1.2
2023-08-10 12:34:20,344:INFO:               scipy: 1.10.1
2023-08-10 12:34:20,344:INFO:              joblib: 1.2.0
2023-08-10 12:34:20,344:INFO:             sklearn: 1.2.2
2023-08-10 12:34:20,344:INFO:                pyod: 1.1.0
2023-08-10 12:34:20,344:INFO:            imblearn: 0.11.0
2023-08-10 12:34:20,344:INFO:   category_encoders: 2.6.1
2023-08-10 12:34:20,344:INFO:            lightgbm: 4.0.0
2023-08-10 12:34:20,344:INFO:               numba: 0.57.1
2023-08-10 12:34:20,344:INFO:            requests: 2.31.0
2023-08-10 12:34:20,344:INFO:          matplotlib: 3.7.1
2023-08-10 12:34:20,344:INFO:          scikitplot: 0.3.7
2023-08-10 12:34:20,344:INFO:         yellowbrick: 1.5
2023-08-10 12:34:20,344:INFO:              plotly: 5.15.0
2023-08-10 12:34:20,344:INFO:    plotly-resampler: Not installed
2023-08-10 12:34:20,344:INFO:             kaleido: 0.2.1
2023-08-10 12:34:20,344:INFO:           schemdraw: 0.15
2023-08-10 12:34:20,344:INFO:         statsmodels: 0.14.0
2023-08-10 12:34:20,344:INFO:              sktime: 0.20.1
2023-08-10 12:34:20,344:INFO:               tbats: 1.1.3
2023-08-10 12:34:20,344:INFO:            pmdarima: 2.0.3
2023-08-10 12:34:20,344:INFO:              psutil: 5.9.5
2023-08-10 12:34:20,344:INFO:          markupsafe: 2.1.3
2023-08-10 12:34:20,344:INFO:             pickle5: Not installed
2023-08-10 12:34:20,344:INFO:         cloudpickle: 2.2.1
2023-08-10 12:34:20,344:INFO:         deprecation: 2.1.0
2023-08-10 12:34:20,344:INFO:              xxhash: 3.2.0
2023-08-10 12:34:20,344:INFO:           wurlitzer: Not installed
2023-08-10 12:34:20,344:INFO:PyCaret optional dependencies:
2023-08-10 12:34:20,392:INFO:                shap: Not installed
2023-08-10 12:34:20,392:INFO:           interpret: 0.4.2
2023-08-10 12:34:20,392:INFO:                umap: 0.5.3
2023-08-10 12:34:20,392:INFO:    pandas_profiling: Not installed
2023-08-10 12:34:20,392:INFO:  explainerdashboard: Not installed
2023-08-10 12:34:20,392:INFO:             autoviz: Not installed
2023-08-10 12:34:20,392:INFO:           fairlearn: Not installed
2023-08-10 12:34:20,392:INFO:          deepchecks: Not installed
2023-08-10 12:34:20,392:INFO:             xgboost: 1.7.6
2023-08-10 12:34:20,392:INFO:            catboost: Not installed
2023-08-10 12:34:20,392:INFO:              kmodes: Not installed
2023-08-10 12:34:20,392:INFO:             mlxtend: 0.22.0
2023-08-10 12:34:20,392:INFO:       statsforecast: Not installed
2023-08-10 12:34:20,392:INFO:        tune_sklearn: Not installed
2023-08-10 12:34:20,392:INFO:                 ray: Not installed
2023-08-10 12:34:20,392:INFO:            hyperopt: Not installed
2023-08-10 12:34:20,392:INFO:              optuna: Not installed
2023-08-10 12:34:20,392:INFO:               skopt: Not installed
2023-08-10 12:34:20,392:INFO:              mlflow: 2.4.2
2023-08-10 12:34:20,392:INFO:              gradio: Not installed
2023-08-10 12:34:20,392:INFO:             fastapi: Not installed
2023-08-10 12:34:20,392:INFO:             uvicorn: Not installed
2023-08-10 12:34:20,392:INFO:              m2cgen: Not installed
2023-08-10 12:34:20,392:INFO:           evidently: Not installed
2023-08-10 12:34:20,392:INFO:               fugue: Not installed
2023-08-10 12:34:20,392:INFO:           streamlit: 1.25.0
2023-08-10 12:34:20,392:INFO:             prophet: Not installed
2023-08-10 12:34:20,392:INFO:None
2023-08-10 12:34:20,392:INFO:Set up data.
2023-08-10 12:34:20,416:INFO:Set up index.
2023-08-10 12:34:20,416:INFO:Assigning column types.
2023-08-10 12:34:20,424:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 12:34:23,488:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 12:34:23,496:INFO:Preparing preprocessing pipeline...
2023-08-10 12:34:23,496:INFO:Set up simple imputation.
2023-08-10 12:34:23,504:INFO:Set up encoding of categorical features.
2023-08-10 12:34:23,624:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:34:23,648:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 12:34:23,648:INFO:Creating final display dataframe.
2023-08-10 12:34:23,696:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  7816
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  3c1d
2023-08-10 12:34:23,696:INFO:setup() successfully completed in 6.14s...............
2023-08-10 12:34:23,696:INFO:Initializing create_model()
2023-08-10 12:34:23,696:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562091D2E0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 12:34:23,696:INFO:Checking exceptions
2023-08-10 12:34:23,736:INFO:Importing untrained model
2023-08-10 12:34:23,736:INFO:Isolation Forest Imported successfully
2023-08-10 12:34:23,744:INFO:Fitting Model
2023-08-10 12:34:26,104:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7816, verbose=0)
2023-08-10 12:34:26,104:INFO:create_models() successfully completed......................................
2023-08-10 12:34:26,104:INFO:Uploading results into container
2023-08-10 12:34:26,104:INFO:Uploading model into container now
2023-08-10 12:34:26,104:INFO:_master_model_container: 1
2023-08-10 12:34:26,104:INFO:_display_container: 1
2023-08-10 12:34:26,104:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7816, verbose=0)
2023-08-10 12:34:26,104:INFO:create_model() successfully completed......................................
2023-08-10 12:34:27,960:INFO:Initializing plot_model()
2023-08-10 12:34:27,960:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7816, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562091D2E0>, system=True)
2023-08-10 12:34:27,960:INFO:Checking exceptions
2023-08-10 12:34:33,488:INFO:Preloading libraries
2023-08-10 12:34:33,528:INFO:Copying training dataset
2023-08-10 12:34:33,528:INFO:Plot type: umap
2023-08-10 12:34:33,528:INFO:SubProcess assign_model() called ==================================
2023-08-10 12:34:33,528:INFO:Initializing assign_model()
2023-08-10 12:34:33,528:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562091D2E0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7816, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 12:34:33,528:INFO:Checking exceptions
2023-08-10 12:34:33,528:INFO:Determining Trained Model
2023-08-10 12:34:33,528:INFO:Trained Model : Isolation Forest
2023-08-10 12:34:33,528:INFO:Copying data
2023-08-10 12:34:33,560:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 12:34:33,560:INFO:(3941, 18)
2023-08-10 12:34:33,560:INFO:assign_model() successfully completed......................................
2023-08-10 12:34:33,568:INFO:SubProcess assign_model() end ==================================
2023-08-10 12:34:33,568:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 12:34:49,555:INFO:Fitting UMAP()
2023-08-10 12:36:02,608:INFO:Rendering Visual
2023-08-10 12:36:06,840:INFO:Visual Rendered Successfully
2023-08-10 12:36:07,160:INFO:plot_model() successfully completed......................................
2023-08-10 12:36:07,216:INFO:Initializing assign_model()
2023-08-10 12:36:07,216:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562091D2E0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7816, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 12:36:07,216:INFO:Checking exceptions
2023-08-10 12:36:07,216:INFO:Determining Trained Model
2023-08-10 12:36:07,216:INFO:Trained Model : Isolation Forest
2023-08-10 12:36:07,216:INFO:Copying data
2023-08-10 12:36:07,224:INFO:(3941, 13)
2023-08-10 12:36:07,224:INFO:assign_model() successfully completed......................................
2023-08-10 12:40:07,731:INFO:PyCaret ClassificationExperiment
2023-08-10 12:40:07,731:INFO:Logging name: bank loan
2023-08-10 12:40:07,739:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 12:40:07,739:INFO:version 3.0.4
2023-08-10 12:40:07,739:INFO:Initializing setup()
2023-08-10 12:40:07,739:INFO:self.USI: 47c8
2023-08-10 12:40:07,739:INFO:self._variable_keys: {'X_test', 'y_test', 'idx', 'gpu_n_jobs_param', 'fix_imbalance', 'fold_generator', 'is_multiclass', 'logging_param', 'fold_groups_param', 'X_train', 'y_train', 'target_param', 'fold_shuffle_param', 'exp_name_log', 'memory', 'seed', 'y', 'exp_id', 'data', 'gpu_param', 'USI', 'n_jobs_param', '_ml_usecase', 'pipeline', 'X', 'log_plots_param', '_available_plots', 'html_param'}
2023-08-10 12:40:07,739:INFO:Checking environment
2023-08-10 12:40:07,739:INFO:python_version: 3.9.13
2023-08-10 12:40:07,739:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:40:07,739:INFO:machine: AMD64
2023-08-10 12:40:07,739:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:40:07,747:INFO:Memory: svmem(total=7480111104, available=826798080, percent=88.9, used=6653313024, free=826798080)
2023-08-10 12:40:07,747:INFO:Physical Core: 4
2023-08-10 12:40:07,747:INFO:Logical Core: 4
2023-08-10 12:40:07,747:INFO:Checking libraries
2023-08-10 12:40:07,747:INFO:System:
2023-08-10 12:40:07,755:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:40:07,755:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:40:07,755:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:40:07,755:INFO:PyCaret required dependencies:
2023-08-10 12:40:07,755:INFO:                 pip: 23.1.2
2023-08-10 12:40:07,755:INFO:          setuptools: 58.1.0
2023-08-10 12:40:07,755:INFO:             pycaret: 3.0.4
2023-08-10 12:40:07,755:INFO:             IPython: 8.13.2
2023-08-10 12:40:07,755:INFO:          ipywidgets: 8.0.7
2023-08-10 12:40:07,755:INFO:                tqdm: 4.65.0
2023-08-10 12:40:07,755:INFO:               numpy: 1.23.5
2023-08-10 12:40:07,755:INFO:              pandas: 1.5.3
2023-08-10 12:40:07,755:INFO:              jinja2: 3.1.2
2023-08-10 12:40:07,755:INFO:               scipy: 1.10.1
2023-08-10 12:40:07,755:INFO:              joblib: 1.2.0
2023-08-10 12:40:07,755:INFO:             sklearn: 1.2.2
2023-08-10 12:40:07,755:INFO:                pyod: 1.1.0
2023-08-10 12:40:07,755:INFO:            imblearn: 0.11.0
2023-08-10 12:40:07,755:INFO:   category_encoders: 2.6.1
2023-08-10 12:40:07,755:INFO:            lightgbm: 4.0.0
2023-08-10 12:40:07,755:INFO:               numba: 0.57.1
2023-08-10 12:40:07,763:INFO:            requests: 2.31.0
2023-08-10 12:40:07,763:INFO:          matplotlib: 3.7.1
2023-08-10 12:40:07,763:INFO:          scikitplot: 0.3.7
2023-08-10 12:40:07,763:INFO:         yellowbrick: 1.5
2023-08-10 12:40:07,763:INFO:              plotly: 5.15.0
2023-08-10 12:40:07,763:INFO:    plotly-resampler: Not installed
2023-08-10 12:40:07,763:INFO:             kaleido: 0.2.1
2023-08-10 12:40:07,763:INFO:           schemdraw: 0.15
2023-08-10 12:40:07,763:INFO:         statsmodels: 0.14.0
2023-08-10 12:40:07,763:INFO:              sktime: 0.20.1
2023-08-10 12:40:07,763:INFO:               tbats: 1.1.3
2023-08-10 12:40:07,763:INFO:            pmdarima: 2.0.3
2023-08-10 12:40:07,763:INFO:              psutil: 5.9.5
2023-08-10 12:40:07,763:INFO:          markupsafe: 2.1.3
2023-08-10 12:40:07,763:INFO:             pickle5: Not installed
2023-08-10 12:40:07,763:INFO:         cloudpickle: 2.2.1
2023-08-10 12:40:07,763:INFO:         deprecation: 2.1.0
2023-08-10 12:40:07,763:INFO:              xxhash: 3.2.0
2023-08-10 12:40:07,763:INFO:           wurlitzer: Not installed
2023-08-10 12:40:07,763:INFO:PyCaret optional dependencies:
2023-08-10 12:40:07,763:INFO:                shap: Not installed
2023-08-10 12:40:07,763:INFO:           interpret: 0.4.2
2023-08-10 12:40:07,763:INFO:                umap: 0.5.3
2023-08-10 12:40:07,763:INFO:    pandas_profiling: Not installed
2023-08-10 12:40:07,763:INFO:  explainerdashboard: Not installed
2023-08-10 12:40:07,763:INFO:             autoviz: Not installed
2023-08-10 12:40:07,763:INFO:           fairlearn: Not installed
2023-08-10 12:40:07,763:INFO:          deepchecks: Not installed
2023-08-10 12:40:07,763:INFO:             xgboost: 1.7.6
2023-08-10 12:40:07,763:INFO:            catboost: Not installed
2023-08-10 12:40:07,763:INFO:              kmodes: Not installed
2023-08-10 12:40:07,763:INFO:             mlxtend: 0.22.0
2023-08-10 12:40:07,763:INFO:       statsforecast: Not installed
2023-08-10 12:40:07,763:INFO:        tune_sklearn: Not installed
2023-08-10 12:40:07,763:INFO:                 ray: Not installed
2023-08-10 12:40:07,763:INFO:            hyperopt: Not installed
2023-08-10 12:40:07,763:INFO:              optuna: Not installed
2023-08-10 12:40:07,763:INFO:               skopt: Not installed
2023-08-10 12:40:07,763:INFO:              mlflow: 2.4.2
2023-08-10 12:40:07,763:INFO:              gradio: Not installed
2023-08-10 12:40:07,763:INFO:             fastapi: Not installed
2023-08-10 12:40:07,763:INFO:             uvicorn: Not installed
2023-08-10 12:40:07,763:INFO:              m2cgen: Not installed
2023-08-10 12:40:07,771:INFO:           evidently: Not installed
2023-08-10 12:40:07,771:INFO:               fugue: Not installed
2023-08-10 12:40:07,771:INFO:           streamlit: 1.25.0
2023-08-10 12:40:07,771:INFO:             prophet: Not installed
2023-08-10 12:40:07,771:INFO:None
2023-08-10 12:40:07,771:INFO:Set up data.
2023-08-10 12:40:07,827:INFO:Set up train/test split.
2023-08-10 12:40:07,859:INFO:Set up index.
2023-08-10 12:40:07,867:INFO:Set up folding strategy.
2023-08-10 12:40:07,867:INFO:Assigning column types.
2023-08-10 12:40:07,883:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 12:40:08,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:40:08,091:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:08,275:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:08,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:08,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:40:08,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:08,627:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:08,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:08,635:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 12:40:08,795:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:08,891:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:08,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:09,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:09,155:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:09,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:09,171:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 12:40:09,419:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:09,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:09,683:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:09,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:09,699:INFO:Preparing preprocessing pipeline...
2023-08-10 12:40:09,699:INFO:Set up simple imputation.
2023-08-10 12:40:09,707:INFO:Set up encoding of categorical features.
2023-08-10 12:40:09,707:INFO:Set up removing outliers.
2023-08-10 12:40:10,027:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:40:10,043:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=3040,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:40:10,043:INFO:Creating final display dataframe.
2023-08-10 12:40:14,915:INFO:Setup _display_container:                     Description            Value
0                    Session id             3040
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2523, 17)
5   Transformed train set shape       (1738, 17)
6    Transformed test set shape        (785, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15              Remove outliers          iforest
16           Outliers threshold             0.05
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment    DagshubLogger
22              Experiment Name        bank loan
23                          USI             47c8
2023-08-10 12:40:15,267:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:15,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:15,539:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:15,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:15,555:INFO:Logging experiment in loggers
2023-08-10 12:40:57,081:INFO:PyCaret ClassificationExperiment
2023-08-10 12:40:57,081:INFO:Logging name: Customer Churn
2023-08-10 12:40:57,081:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 12:40:57,081:INFO:version 3.0.4
2023-08-10 12:40:57,081:INFO:Initializing setup()
2023-08-10 12:40:57,081:INFO:self.USI: c54f
2023-08-10 12:40:57,081:INFO:self._variable_keys: {'X_test', 'y_test', 'idx', 'gpu_n_jobs_param', 'fix_imbalance', 'fold_generator', 'is_multiclass', 'logging_param', 'fold_groups_param', 'X_train', 'y_train', 'target_param', 'fold_shuffle_param', 'exp_name_log', 'memory', 'seed', 'y', 'exp_id', 'data', 'gpu_param', 'USI', 'n_jobs_param', '_ml_usecase', 'pipeline', 'X', 'log_plots_param', '_available_plots', 'html_param'}
2023-08-10 12:40:57,081:INFO:Checking environment
2023-08-10 12:40:57,081:INFO:python_version: 3.9.13
2023-08-10 12:40:57,081:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:40:57,089:INFO:machine: AMD64
2023-08-10 12:40:57,089:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:40:57,105:INFO:Memory: svmem(total=7480111104, available=830320640, percent=88.9, used=6649790464, free=830320640)
2023-08-10 12:40:57,105:INFO:Physical Core: 4
2023-08-10 12:40:57,105:INFO:Logical Core: 4
2023-08-10 12:40:57,105:INFO:Checking libraries
2023-08-10 12:40:57,105:INFO:System:
2023-08-10 12:40:57,105:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:40:57,105:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:40:57,105:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:40:57,105:INFO:PyCaret required dependencies:
2023-08-10 12:40:57,105:INFO:                 pip: 23.1.2
2023-08-10 12:40:57,105:INFO:          setuptools: 58.1.0
2023-08-10 12:40:57,105:INFO:             pycaret: 3.0.4
2023-08-10 12:40:57,105:INFO:             IPython: 8.13.2
2023-08-10 12:40:57,105:INFO:          ipywidgets: 8.0.7
2023-08-10 12:40:57,105:INFO:                tqdm: 4.65.0
2023-08-10 12:40:57,105:INFO:               numpy: 1.23.5
2023-08-10 12:40:57,105:INFO:              pandas: 1.5.3
2023-08-10 12:40:57,105:INFO:              jinja2: 3.1.2
2023-08-10 12:40:57,105:INFO:               scipy: 1.10.1
2023-08-10 12:40:57,105:INFO:              joblib: 1.2.0
2023-08-10 12:40:57,105:INFO:             sklearn: 1.2.2
2023-08-10 12:40:57,105:INFO:                pyod: 1.1.0
2023-08-10 12:40:57,105:INFO:            imblearn: 0.11.0
2023-08-10 12:40:57,105:INFO:   category_encoders: 2.6.1
2023-08-10 12:40:57,105:INFO:            lightgbm: 4.0.0
2023-08-10 12:40:57,105:INFO:               numba: 0.57.1
2023-08-10 12:40:57,105:INFO:            requests: 2.31.0
2023-08-10 12:40:57,105:INFO:          matplotlib: 3.7.1
2023-08-10 12:40:57,105:INFO:          scikitplot: 0.3.7
2023-08-10 12:40:57,105:INFO:         yellowbrick: 1.5
2023-08-10 12:40:57,105:INFO:              plotly: 5.15.0
2023-08-10 12:40:57,105:INFO:    plotly-resampler: Not installed
2023-08-10 12:40:57,105:INFO:             kaleido: 0.2.1
2023-08-10 12:40:57,105:INFO:           schemdraw: 0.15
2023-08-10 12:40:57,105:INFO:         statsmodels: 0.14.0
2023-08-10 12:40:57,105:INFO:              sktime: 0.20.1
2023-08-10 12:40:57,105:INFO:               tbats: 1.1.3
2023-08-10 12:40:57,105:INFO:            pmdarima: 2.0.3
2023-08-10 12:40:57,113:INFO:              psutil: 5.9.5
2023-08-10 12:40:57,113:INFO:          markupsafe: 2.1.3
2023-08-10 12:40:57,113:INFO:             pickle5: Not installed
2023-08-10 12:40:57,113:INFO:         cloudpickle: 2.2.1
2023-08-10 12:40:57,113:INFO:         deprecation: 2.1.0
2023-08-10 12:40:57,113:INFO:              xxhash: 3.2.0
2023-08-10 12:40:57,113:INFO:           wurlitzer: Not installed
2023-08-10 12:40:57,113:INFO:PyCaret optional dependencies:
2023-08-10 12:40:57,113:INFO:                shap: Not installed
2023-08-10 12:40:57,113:INFO:           interpret: 0.4.2
2023-08-10 12:40:57,113:INFO:                umap: 0.5.3
2023-08-10 12:40:57,113:INFO:    pandas_profiling: Not installed
2023-08-10 12:40:57,113:INFO:  explainerdashboard: Not installed
2023-08-10 12:40:57,113:INFO:             autoviz: Not installed
2023-08-10 12:40:57,113:INFO:           fairlearn: Not installed
2023-08-10 12:40:57,113:INFO:          deepchecks: Not installed
2023-08-10 12:40:57,113:INFO:             xgboost: 1.7.6
2023-08-10 12:40:57,113:INFO:            catboost: Not installed
2023-08-10 12:40:57,113:INFO:              kmodes: Not installed
2023-08-10 12:40:57,113:INFO:             mlxtend: 0.22.0
2023-08-10 12:40:57,121:INFO:       statsforecast: Not installed
2023-08-10 12:40:57,121:INFO:        tune_sklearn: Not installed
2023-08-10 12:40:57,121:INFO:                 ray: Not installed
2023-08-10 12:40:57,121:INFO:            hyperopt: Not installed
2023-08-10 12:40:57,121:INFO:              optuna: Not installed
2023-08-10 12:40:57,121:INFO:               skopt: Not installed
2023-08-10 12:40:57,121:INFO:              mlflow: 2.4.2
2023-08-10 12:40:57,121:INFO:              gradio: Not installed
2023-08-10 12:40:57,121:INFO:             fastapi: Not installed
2023-08-10 12:40:57,121:INFO:             uvicorn: Not installed
2023-08-10 12:40:57,121:INFO:              m2cgen: Not installed
2023-08-10 12:40:57,121:INFO:           evidently: Not installed
2023-08-10 12:40:57,121:INFO:               fugue: Not installed
2023-08-10 12:40:57,121:INFO:           streamlit: 1.25.0
2023-08-10 12:40:57,121:INFO:             prophet: Not installed
2023-08-10 12:40:57,121:INFO:None
2023-08-10 12:40:57,121:INFO:Set up data.
2023-08-10 12:40:57,161:INFO:Set up train/test split.
2023-08-10 12:40:57,201:INFO:Set up index.
2023-08-10 12:40:57,201:INFO:Set up folding strategy.
2023-08-10 12:40:57,201:INFO:Assigning column types.
2023-08-10 12:40:57,225:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 12:40:57,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:40:57,449:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:57,593:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:57,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:57,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:40:57,865:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:58,001:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:58,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:58,017:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 12:40:58,241:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:58,345:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:58,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:58,665:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:40:58,889:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:58,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:58,905:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 12:40:59,185:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:59,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:59,473:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:40:59,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:40:59,489:INFO:Preparing preprocessing pipeline...
2023-08-10 12:40:59,489:INFO:Set up simple imputation.
2023-08-10 12:40:59,505:INFO:Set up encoding of categorical features.
2023-08-10 12:40:59,505:INFO:Set up removing outliers.
2023-08-10 12:40:59,826:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:40:59,865:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=5584,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:40:59,865:INFO:Creating final display dataframe.
2023-08-10 12:41:07,975:INFO:Setup _display_container:                     Description            Value
0                    Session id             5584
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2523, 17)
5   Transformed train set shape       (1738, 17)
6    Transformed test set shape        (785, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15              Remove outliers          iforest
16           Outliers threshold             0.05
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment    DagshubLogger
22              Experiment Name   Customer Churn
23                          USI             c54f
2023-08-10 12:41:08,479:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:41:08,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:41:09,239:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:41:09,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:41:09,255:INFO:Logging experiment in loggers
2023-08-10 12:41:31,843:INFO:SubProcess save_model() called ==================================
2023-08-10 12:41:31,907:INFO:Initializing save_model()
2023-08-10 12:41:31,907:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=5584,
                                                               threshold=0.05)))],
         verbose=False), model_name=C:\Users\HP\AppData\Local\Temp\tmpgiezkfr1\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=5584,
                                                               threshold=0.05)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-10 12:41:31,907:INFO:Adding model into prep_pipe
2023-08-10 12:41:31,907:WARNING:Only Model saved as it was a pipeline.
2023-08-10 12:41:32,163:INFO:C:\Users\HP\AppData\Local\Temp\tmpgiezkfr1\Transformation Pipeline.pkl saved in current working directory
2023-08-10 12:41:32,195:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=5584,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:41:32,195:INFO:save_model() successfully completed......................................
2023-08-10 12:41:32,811:INFO:SubProcess save_model() end ==================================
2023-08-10 12:41:44,093:INFO:setup() successfully completed in 18.29s...............
2023-08-10 12:42:12,680:INFO:Initializing get_config()
2023-08-10 12:42:12,680:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000256232BB130>, variable=pipeline)
2023-08-10 12:42:12,704:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=5584,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:42:12,704:INFO:get_config() successfully completed......................................
2023-08-10 12:44:56,589:INFO:PyCaret AnomalyExperiment
2023-08-10 12:44:56,589:INFO:Logging name: anomaly-default-name
2023-08-10 12:44:56,589:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 12:44:56,589:INFO:version 3.0.4
2023-08-10 12:44:56,589:INFO:Initializing setup()
2023-08-10 12:44:56,589:INFO:self.USI: ab82
2023-08-10 12:44:56,589:INFO:self._variable_keys: {'idx', 'gpu_n_jobs_param', 'logging_param', 'exp_name_log', 'memory', 'seed', 'exp_id', 'data', 'gpu_param', 'USI', 'n_jobs_param', '_ml_usecase', 'pipeline', 'X', 'log_plots_param', '_available_plots', 'html_param'}
2023-08-10 12:44:56,589:INFO:Checking environment
2023-08-10 12:44:56,589:INFO:python_version: 3.9.13
2023-08-10 12:44:56,589:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:44:56,589:INFO:machine: AMD64
2023-08-10 12:44:56,589:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:44:56,597:INFO:Memory: svmem(total=7480111104, available=888864768, percent=88.1, used=6591246336, free=888864768)
2023-08-10 12:44:56,605:INFO:Physical Core: 4
2023-08-10 12:44:56,605:INFO:Logical Core: 4
2023-08-10 12:44:56,605:INFO:Checking libraries
2023-08-10 12:44:56,605:INFO:System:
2023-08-10 12:44:56,605:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:44:56,605:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:44:56,605:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:44:56,605:INFO:PyCaret required dependencies:
2023-08-10 12:44:56,605:INFO:                 pip: 23.1.2
2023-08-10 12:44:56,605:INFO:          setuptools: 58.1.0
2023-08-10 12:44:56,605:INFO:             pycaret: 3.0.4
2023-08-10 12:44:56,605:INFO:             IPython: 8.13.2
2023-08-10 12:44:56,605:INFO:          ipywidgets: 8.0.7
2023-08-10 12:44:56,605:INFO:                tqdm: 4.65.0
2023-08-10 12:44:56,605:INFO:               numpy: 1.23.5
2023-08-10 12:44:56,605:INFO:              pandas: 1.5.3
2023-08-10 12:44:56,605:INFO:              jinja2: 3.1.2
2023-08-10 12:44:56,605:INFO:               scipy: 1.10.1
2023-08-10 12:44:56,605:INFO:              joblib: 1.2.0
2023-08-10 12:44:56,605:INFO:             sklearn: 1.2.2
2023-08-10 12:44:56,605:INFO:                pyod: 1.1.0
2023-08-10 12:44:56,605:INFO:            imblearn: 0.11.0
2023-08-10 12:44:56,605:INFO:   category_encoders: 2.6.1
2023-08-10 12:44:56,605:INFO:            lightgbm: 4.0.0
2023-08-10 12:44:56,605:INFO:               numba: 0.57.1
2023-08-10 12:44:56,605:INFO:            requests: 2.31.0
2023-08-10 12:44:56,605:INFO:          matplotlib: 3.7.1
2023-08-10 12:44:56,605:INFO:          scikitplot: 0.3.7
2023-08-10 12:44:56,605:INFO:         yellowbrick: 1.5
2023-08-10 12:44:56,605:INFO:              plotly: 5.15.0
2023-08-10 12:44:56,605:INFO:    plotly-resampler: Not installed
2023-08-10 12:44:56,605:INFO:             kaleido: 0.2.1
2023-08-10 12:44:56,605:INFO:           schemdraw: 0.15
2023-08-10 12:44:56,605:INFO:         statsmodels: 0.14.0
2023-08-10 12:44:56,605:INFO:              sktime: 0.20.1
2023-08-10 12:44:56,605:INFO:               tbats: 1.1.3
2023-08-10 12:44:56,605:INFO:            pmdarima: 2.0.3
2023-08-10 12:44:56,605:INFO:              psutil: 5.9.5
2023-08-10 12:44:56,605:INFO:          markupsafe: 2.1.3
2023-08-10 12:44:56,605:INFO:             pickle5: Not installed
2023-08-10 12:44:56,605:INFO:         cloudpickle: 2.2.1
2023-08-10 12:44:56,605:INFO:         deprecation: 2.1.0
2023-08-10 12:44:56,605:INFO:              xxhash: 3.2.0
2023-08-10 12:44:56,605:INFO:           wurlitzer: Not installed
2023-08-10 12:44:56,605:INFO:PyCaret optional dependencies:
2023-08-10 12:44:56,605:INFO:                shap: Not installed
2023-08-10 12:44:56,605:INFO:           interpret: 0.4.2
2023-08-10 12:44:56,605:INFO:                umap: 0.5.3
2023-08-10 12:44:56,605:INFO:    pandas_profiling: Not installed
2023-08-10 12:44:56,605:INFO:  explainerdashboard: Not installed
2023-08-10 12:44:56,605:INFO:             autoviz: Not installed
2023-08-10 12:44:56,605:INFO:           fairlearn: Not installed
2023-08-10 12:44:56,605:INFO:          deepchecks: Not installed
2023-08-10 12:44:56,613:INFO:             xgboost: 1.7.6
2023-08-10 12:44:56,613:INFO:            catboost: Not installed
2023-08-10 12:44:56,613:INFO:              kmodes: Not installed
2023-08-10 12:44:56,613:INFO:             mlxtend: 0.22.0
2023-08-10 12:44:56,613:INFO:       statsforecast: Not installed
2023-08-10 12:44:56,613:INFO:        tune_sklearn: Not installed
2023-08-10 12:44:56,613:INFO:                 ray: Not installed
2023-08-10 12:44:56,613:INFO:            hyperopt: Not installed
2023-08-10 12:44:56,613:INFO:              optuna: Not installed
2023-08-10 12:44:56,613:INFO:               skopt: Not installed
2023-08-10 12:44:56,613:INFO:              mlflow: 2.4.2
2023-08-10 12:44:56,613:INFO:              gradio: Not installed
2023-08-10 12:44:56,613:INFO:             fastapi: Not installed
2023-08-10 12:44:56,613:INFO:             uvicorn: Not installed
2023-08-10 12:44:56,613:INFO:              m2cgen: Not installed
2023-08-10 12:44:56,613:INFO:           evidently: Not installed
2023-08-10 12:44:56,613:INFO:               fugue: Not installed
2023-08-10 12:44:56,613:INFO:           streamlit: 1.25.0
2023-08-10 12:44:56,613:INFO:             prophet: Not installed
2023-08-10 12:44:56,613:INFO:None
2023-08-10 12:44:56,613:INFO:Set up data.
2023-08-10 12:44:56,629:INFO:Set up index.
2023-08-10 12:44:56,629:INFO:Assigning column types.
2023-08-10 12:44:56,637:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 12:44:56,637:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 12:44:56,645:INFO:Preparing preprocessing pipeline...
2023-08-10 12:44:56,645:INFO:Set up simple imputation.
2023-08-10 12:44:56,645:INFO:Set up encoding of categorical features.
2023-08-10 12:44:56,765:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:44:56,781:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              f...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-08-10 12:44:56,781:INFO:Creating final display dataframe.
2023-08-10 12:44:56,829:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  7828
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  ab82
2023-08-10 12:44:56,829:INFO:setup() successfully completed in 2.57s...............
2023-08-10 12:44:58,269:INFO:Initializing create_model()
2023-08-10 12:44:58,269:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562AD3A7F0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 12:44:58,269:INFO:Checking exceptions
2023-08-10 12:44:58,309:INFO:Importing untrained model
2023-08-10 12:44:58,309:INFO:Isolation Forest Imported successfully
2023-08-10 12:44:58,309:INFO:Fitting Model
2023-08-10 12:45:00,189:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7828, verbose=0)
2023-08-10 12:45:00,189:INFO:create_models() successfully completed......................................
2023-08-10 12:45:00,189:INFO:Uploading results into container
2023-08-10 12:45:00,189:INFO:Uploading model into container now
2023-08-10 12:45:00,189:INFO:_master_model_container: 1
2023-08-10 12:45:00,189:INFO:_display_container: 1
2023-08-10 12:45:00,189:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7828, verbose=0)
2023-08-10 12:45:00,189:INFO:create_model() successfully completed......................................
2023-08-10 12:45:03,693:INFO:Initializing plot_model()
2023-08-10 12:45:03,693:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7828, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562AD3A7F0>, system=True)
2023-08-10 12:45:03,693:INFO:Checking exceptions
2023-08-10 12:45:09,037:INFO:Preloading libraries
2023-08-10 12:45:09,069:INFO:Copying training dataset
2023-08-10 12:45:09,069:INFO:Plot type: umap
2023-08-10 12:45:09,069:INFO:SubProcess assign_model() called ==================================
2023-08-10 12:45:09,077:INFO:Initializing assign_model()
2023-08-10 12:45:09,077:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562AD3A7F0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7828, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 12:45:09,077:INFO:Checking exceptions
2023-08-10 12:45:09,077:INFO:Determining Trained Model
2023-08-10 12:45:09,077:INFO:Trained Model : Isolation Forest
2023-08-10 12:45:09,077:INFO:Copying data
2023-08-10 12:45:09,109:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 12:45:09,109:INFO:(3941, 18)
2023-08-10 12:45:09,109:INFO:assign_model() successfully completed......................................
2023-08-10 12:45:09,109:INFO:SubProcess assign_model() end ==================================
2023-08-10 12:45:09,117:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 12:45:09,117:INFO:Fitting UMAP()
2023-08-10 12:45:49,331:INFO:Rendering Visual
2023-08-10 12:45:49,507:INFO:Visual Rendered Successfully
2023-08-10 12:45:50,043:INFO:plot_model() successfully completed......................................
2023-08-10 12:45:50,091:INFO:Initializing assign_model()
2023-08-10 12:45:50,091:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002562AD3A7F0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=7828, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 12:45:50,091:INFO:Checking exceptions
2023-08-10 12:45:50,091:INFO:Determining Trained Model
2023-08-10 12:45:50,091:INFO:Trained Model : Isolation Forest
2023-08-10 12:45:50,091:INFO:Copying data
2023-08-10 12:45:50,099:INFO:(3941, 13)
2023-08-10 12:45:50,099:INFO:assign_model() successfully completed......................................
2023-08-10 12:48:11,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:48:11,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:48:11,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:48:11,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 12:48:58,950:INFO:PyCaret AnomalyExperiment
2023-08-10 12:48:58,950:INFO:Logging name: anomaly-default-name
2023-08-10 12:48:58,950:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 12:48:58,950:INFO:version 3.0.4
2023-08-10 12:48:58,950:INFO:Initializing setup()
2023-08-10 12:48:58,950:INFO:self.USI: c0b3
2023-08-10 12:48:58,950:INFO:self._variable_keys: {'_available_plots', 'pipeline', 'idx', 'logging_param', 'html_param', 'exp_name_log', 'memory', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'seed', 'USI', 'exp_id', 'gpu_param', '_ml_usecase', 'X', 'n_jobs_param'}
2023-08-10 12:48:58,950:INFO:Checking environment
2023-08-10 12:48:58,950:INFO:python_version: 3.9.13
2023-08-10 12:48:58,950:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:48:58,950:INFO:machine: AMD64
2023-08-10 12:48:58,950:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:48:58,958:INFO:Memory: svmem(total=7480111104, available=1283575808, percent=82.8, used=6196535296, free=1283575808)
2023-08-10 12:48:58,958:INFO:Physical Core: 4
2023-08-10 12:48:58,958:INFO:Logical Core: 4
2023-08-10 12:48:58,958:INFO:Checking libraries
2023-08-10 12:48:58,958:INFO:System:
2023-08-10 12:48:58,958:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:48:58,958:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:48:58,958:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:48:58,958:INFO:PyCaret required dependencies:
2023-08-10 12:48:59,142:INFO:                 pip: 23.1.2
2023-08-10 12:48:59,142:INFO:          setuptools: 58.1.0
2023-08-10 12:48:59,142:INFO:             pycaret: 3.0.4
2023-08-10 12:48:59,142:INFO:             IPython: 8.13.2
2023-08-10 12:48:59,142:INFO:          ipywidgets: 8.0.7
2023-08-10 12:48:59,142:INFO:                tqdm: 4.65.0
2023-08-10 12:48:59,142:INFO:               numpy: 1.23.5
2023-08-10 12:48:59,142:INFO:              pandas: 1.5.3
2023-08-10 12:48:59,142:INFO:              jinja2: 3.1.2
2023-08-10 12:48:59,142:INFO:               scipy: 1.10.1
2023-08-10 12:48:59,142:INFO:              joblib: 1.2.0
2023-08-10 12:48:59,142:INFO:             sklearn: 1.2.2
2023-08-10 12:48:59,142:INFO:                pyod: 1.1.0
2023-08-10 12:48:59,142:INFO:            imblearn: 0.11.0
2023-08-10 12:48:59,142:INFO:   category_encoders: 2.6.1
2023-08-10 12:48:59,142:INFO:            lightgbm: 4.0.0
2023-08-10 12:48:59,142:INFO:               numba: 0.57.1
2023-08-10 12:48:59,142:INFO:            requests: 2.31.0
2023-08-10 12:48:59,142:INFO:          matplotlib: 3.7.1
2023-08-10 12:48:59,142:INFO:          scikitplot: 0.3.7
2023-08-10 12:48:59,142:INFO:         yellowbrick: 1.5
2023-08-10 12:48:59,142:INFO:              plotly: 5.15.0
2023-08-10 12:48:59,142:INFO:    plotly-resampler: Not installed
2023-08-10 12:48:59,142:INFO:             kaleido: 0.2.1
2023-08-10 12:48:59,142:INFO:           schemdraw: 0.15
2023-08-10 12:48:59,142:INFO:         statsmodels: 0.14.0
2023-08-10 12:48:59,142:INFO:              sktime: 0.20.1
2023-08-10 12:48:59,142:INFO:               tbats: 1.1.3
2023-08-10 12:48:59,142:INFO:            pmdarima: 2.0.3
2023-08-10 12:48:59,142:INFO:              psutil: 5.9.5
2023-08-10 12:48:59,142:INFO:          markupsafe: 2.1.3
2023-08-10 12:48:59,142:INFO:             pickle5: Not installed
2023-08-10 12:48:59,142:INFO:         cloudpickle: 2.2.1
2023-08-10 12:48:59,142:INFO:         deprecation: 2.1.0
2023-08-10 12:48:59,142:INFO:              xxhash: 3.2.0
2023-08-10 12:48:59,142:INFO:           wurlitzer: Not installed
2023-08-10 12:48:59,142:INFO:PyCaret optional dependencies:
2023-08-10 12:48:59,182:INFO:                shap: Not installed
2023-08-10 12:48:59,182:INFO:           interpret: 0.4.2
2023-08-10 12:48:59,182:INFO:                umap: 0.5.3
2023-08-10 12:48:59,182:INFO:    pandas_profiling: Not installed
2023-08-10 12:48:59,182:INFO:  explainerdashboard: Not installed
2023-08-10 12:48:59,182:INFO:             autoviz: Not installed
2023-08-10 12:48:59,182:INFO:           fairlearn: Not installed
2023-08-10 12:48:59,182:INFO:          deepchecks: Not installed
2023-08-10 12:48:59,182:INFO:             xgboost: 1.7.6
2023-08-10 12:48:59,182:INFO:            catboost: Not installed
2023-08-10 12:48:59,182:INFO:              kmodes: Not installed
2023-08-10 12:48:59,182:INFO:             mlxtend: 0.22.0
2023-08-10 12:48:59,182:INFO:       statsforecast: Not installed
2023-08-10 12:48:59,182:INFO:        tune_sklearn: Not installed
2023-08-10 12:48:59,182:INFO:                 ray: Not installed
2023-08-10 12:48:59,182:INFO:            hyperopt: Not installed
2023-08-10 12:48:59,190:INFO:              optuna: Not installed
2023-08-10 12:48:59,190:INFO:               skopt: Not installed
2023-08-10 12:48:59,190:INFO:              mlflow: 2.4.2
2023-08-10 12:48:59,190:INFO:              gradio: Not installed
2023-08-10 12:48:59,190:INFO:             fastapi: Not installed
2023-08-10 12:48:59,190:INFO:             uvicorn: Not installed
2023-08-10 12:48:59,190:INFO:              m2cgen: Not installed
2023-08-10 12:48:59,190:INFO:           evidently: Not installed
2023-08-10 12:48:59,190:INFO:               fugue: Not installed
2023-08-10 12:48:59,190:INFO:           streamlit: 1.25.0
2023-08-10 12:48:59,190:INFO:             prophet: Not installed
2023-08-10 12:48:59,190:INFO:None
2023-08-10 12:48:59,190:INFO:Set up data.
2023-08-10 12:48:59,206:INFO:Set up index.
2023-08-10 12:48:59,206:INFO:Assigning column types.
2023-08-10 12:48:59,214:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 12:49:01,078:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 12:49:01,086:INFO:Preparing preprocessing pipeline...
2023-08-10 12:49:01,086:INFO:Set up simple imputation.
2023-08-10 12:49:01,094:INFO:Set up encoding of categorical features.
2023-08-10 12:49:01,206:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:49:01,230:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 12:49:01,230:INFO:Creating final display dataframe.
2023-08-10 12:49:01,278:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  4382
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  c0b3
2023-08-10 12:49:01,278:INFO:setup() successfully completed in 4.2s...............
2023-08-10 12:49:01,278:INFO:Initializing create_model()
2023-08-10 12:49:01,278:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002C3EB561FA0>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 12:49:01,278:INFO:Checking exceptions
2023-08-10 12:49:01,318:INFO:Importing untrained model
2023-08-10 12:49:01,318:INFO:Isolation Forest Imported successfully
2023-08-10 12:49:01,318:INFO:Fitting Model
2023-08-10 12:49:03,230:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4382, verbose=0)
2023-08-10 12:49:03,230:INFO:create_models() successfully completed......................................
2023-08-10 12:49:03,230:INFO:Uploading results into container
2023-08-10 12:49:03,230:INFO:Uploading model into container now
2023-08-10 12:49:03,230:INFO:_master_model_container: 1
2023-08-10 12:49:03,230:INFO:_display_container: 1
2023-08-10 12:49:03,230:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4382, verbose=0)
2023-08-10 12:49:03,230:INFO:create_model() successfully completed......................................
2023-08-10 12:49:04,902:INFO:Initializing plot_model()
2023-08-10 12:49:04,902:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4382, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002C3EB561FA0>, system=True)
2023-08-10 12:49:04,902:INFO:Checking exceptions
2023-08-10 12:49:10,256:INFO:Preloading libraries
2023-08-10 12:49:10,296:INFO:Copying training dataset
2023-08-10 12:49:10,296:INFO:Plot type: umap
2023-08-10 12:49:10,296:INFO:SubProcess assign_model() called ==================================
2023-08-10 12:49:10,296:INFO:Initializing assign_model()
2023-08-10 12:49:10,296:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002C3EB561FA0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4382, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 12:49:10,296:INFO:Checking exceptions
2023-08-10 12:49:10,296:INFO:Determining Trained Model
2023-08-10 12:49:10,296:INFO:Trained Model : Isolation Forest
2023-08-10 12:49:10,296:INFO:Copying data
2023-08-10 12:49:10,336:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 12:49:10,336:INFO:(3941, 18)
2023-08-10 12:49:10,336:INFO:assign_model() successfully completed......................................
2023-08-10 12:49:10,336:INFO:SubProcess assign_model() end ==================================
2023-08-10 12:49:10,344:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 12:49:24,417:INFO:Fitting UMAP()
2023-08-10 12:50:18,436:INFO:Rendering Visual
2023-08-10 12:50:21,902:INFO:Visual Rendered Successfully
2023-08-10 12:50:22,246:INFO:plot_model() successfully completed......................................
2023-08-10 12:50:22,294:INFO:Initializing assign_model()
2023-08-10 12:50:22,294:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x000002C3EB561FA0>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=4382, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 12:50:22,294:INFO:Checking exceptions
2023-08-10 12:50:22,302:INFO:Determining Trained Model
2023-08-10 12:50:22,302:INFO:Trained Model : Isolation Forest
2023-08-10 12:50:22,302:INFO:Copying data
2023-08-10 12:50:22,302:INFO:(3941, 13)
2023-08-10 12:50:22,302:INFO:assign_model() successfully completed......................................
2023-08-10 12:50:24,958:INFO:PyCaret ClassificationExperiment
2023-08-10 12:50:24,958:INFO:Logging name: Customer Churn
2023-08-10 12:50:24,958:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 12:50:24,958:INFO:version 3.0.4
2023-08-10 12:50:24,958:INFO:Initializing setup()
2023-08-10 12:50:24,958:INFO:self.USI: ec0f
2023-08-10 12:50:24,958:INFO:self._variable_keys: {'X_train', 'target_param', 'y_train', '_available_plots', 'X_test', 'is_multiclass', 'y', 'pipeline', 'idx', 'logging_param', 'html_param', 'exp_name_log', 'memory', 'fix_imbalance', 'log_plots_param', 'fold_generator', 'X', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'seed', 'USI', 'exp_id', 'fold_shuffle_param', 'gpu_param', '_ml_usecase', 'y_test', 'n_jobs_param'}
2023-08-10 12:50:24,958:INFO:Checking environment
2023-08-10 12:50:24,958:INFO:python_version: 3.9.13
2023-08-10 12:50:24,958:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:50:24,958:INFO:machine: AMD64
2023-08-10 12:50:24,958:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:50:24,966:INFO:Memory: svmem(total=7480111104, available=1063124992, percent=85.8, used=6416986112, free=1063124992)
2023-08-10 12:50:24,966:INFO:Physical Core: 4
2023-08-10 12:50:24,966:INFO:Logical Core: 4
2023-08-10 12:50:24,966:INFO:Checking libraries
2023-08-10 12:50:24,966:INFO:System:
2023-08-10 12:50:24,966:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:50:24,966:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:50:24,966:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:50:24,974:INFO:PyCaret required dependencies:
2023-08-10 12:50:24,974:INFO:                 pip: 23.1.2
2023-08-10 12:50:24,974:INFO:          setuptools: 58.1.0
2023-08-10 12:50:24,974:INFO:             pycaret: 3.0.4
2023-08-10 12:50:24,974:INFO:             IPython: 8.13.2
2023-08-10 12:50:24,974:INFO:          ipywidgets: 8.0.7
2023-08-10 12:50:24,974:INFO:                tqdm: 4.65.0
2023-08-10 12:50:24,974:INFO:               numpy: 1.23.5
2023-08-10 12:50:24,974:INFO:              pandas: 1.5.3
2023-08-10 12:50:24,974:INFO:              jinja2: 3.1.2
2023-08-10 12:50:24,974:INFO:               scipy: 1.10.1
2023-08-10 12:50:24,974:INFO:              joblib: 1.2.0
2023-08-10 12:50:24,974:INFO:             sklearn: 1.2.2
2023-08-10 12:50:24,974:INFO:                pyod: 1.1.0
2023-08-10 12:50:24,974:INFO:            imblearn: 0.11.0
2023-08-10 12:50:24,974:INFO:   category_encoders: 2.6.1
2023-08-10 12:50:24,974:INFO:            lightgbm: 4.0.0
2023-08-10 12:50:24,974:INFO:               numba: 0.57.1
2023-08-10 12:50:24,974:INFO:            requests: 2.31.0
2023-08-10 12:50:24,974:INFO:          matplotlib: 3.7.1
2023-08-10 12:50:24,974:INFO:          scikitplot: 0.3.7
2023-08-10 12:50:24,974:INFO:         yellowbrick: 1.5
2023-08-10 12:50:24,974:INFO:              plotly: 5.15.0
2023-08-10 12:50:24,974:INFO:    plotly-resampler: Not installed
2023-08-10 12:50:24,974:INFO:             kaleido: 0.2.1
2023-08-10 12:50:24,974:INFO:           schemdraw: 0.15
2023-08-10 12:50:24,974:INFO:         statsmodels: 0.14.0
2023-08-10 12:50:24,974:INFO:              sktime: 0.20.1
2023-08-10 12:50:24,974:INFO:               tbats: 1.1.3
2023-08-10 12:50:24,974:INFO:            pmdarima: 2.0.3
2023-08-10 12:50:24,974:INFO:              psutil: 5.9.5
2023-08-10 12:50:24,974:INFO:          markupsafe: 2.1.3
2023-08-10 12:50:24,974:INFO:             pickle5: Not installed
2023-08-10 12:50:24,974:INFO:         cloudpickle: 2.2.1
2023-08-10 12:50:24,974:INFO:         deprecation: 2.1.0
2023-08-10 12:50:24,974:INFO:              xxhash: 3.2.0
2023-08-10 12:50:24,974:INFO:           wurlitzer: Not installed
2023-08-10 12:50:24,974:INFO:PyCaret optional dependencies:
2023-08-10 12:50:24,974:INFO:                shap: Not installed
2023-08-10 12:50:24,974:INFO:           interpret: 0.4.2
2023-08-10 12:50:24,974:INFO:                umap: 0.5.3
2023-08-10 12:50:24,974:INFO:    pandas_profiling: Not installed
2023-08-10 12:50:24,974:INFO:  explainerdashboard: Not installed
2023-08-10 12:50:24,974:INFO:             autoviz: Not installed
2023-08-10 12:50:24,974:INFO:           fairlearn: Not installed
2023-08-10 12:50:24,974:INFO:          deepchecks: Not installed
2023-08-10 12:50:24,974:INFO:             xgboost: 1.7.6
2023-08-10 12:50:24,974:INFO:            catboost: Not installed
2023-08-10 12:50:24,974:INFO:              kmodes: Not installed
2023-08-10 12:50:24,974:INFO:             mlxtend: 0.22.0
2023-08-10 12:50:24,974:INFO:       statsforecast: Not installed
2023-08-10 12:50:24,974:INFO:        tune_sklearn: Not installed
2023-08-10 12:50:24,974:INFO:                 ray: Not installed
2023-08-10 12:50:24,974:INFO:            hyperopt: Not installed
2023-08-10 12:50:24,974:INFO:              optuna: Not installed
2023-08-10 12:50:24,974:INFO:               skopt: Not installed
2023-08-10 12:50:24,974:INFO:              mlflow: 2.4.2
2023-08-10 12:50:24,974:INFO:              gradio: Not installed
2023-08-10 12:50:24,974:INFO:             fastapi: Not installed
2023-08-10 12:50:24,974:INFO:             uvicorn: Not installed
2023-08-10 12:50:24,974:INFO:              m2cgen: Not installed
2023-08-10 12:50:24,974:INFO:           evidently: Not installed
2023-08-10 12:50:24,974:INFO:               fugue: Not installed
2023-08-10 12:50:24,974:INFO:           streamlit: 1.25.0
2023-08-10 12:50:24,974:INFO:             prophet: Not installed
2023-08-10 12:50:24,974:INFO:None
2023-08-10 12:50:24,974:INFO:Set up data.
2023-08-10 12:50:24,998:INFO:Set up train/test split.
2023-08-10 12:50:25,014:INFO:Set up index.
2023-08-10 12:50:25,014:INFO:Set up folding strategy.
2023-08-10 12:50:25,014:INFO:Assigning column types.
2023-08-10 12:50:25,030:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 12:50:25,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:50:25,182:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:50:25,342:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:25,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:25,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:50:25,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:50:25,678:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:25,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:25,686:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 12:50:25,838:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:50:25,926:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:25,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:26,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:50:26,191:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:26,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:26,199:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 12:50:26,447:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:26,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:26,703:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:26,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:26,711:INFO:Preparing preprocessing pipeline...
2023-08-10 12:50:26,711:INFO:Set up simple imputation.
2023-08-10 12:50:26,727:INFO:Set up encoding of categorical features.
2023-08-10 12:50:26,727:INFO:Set up removing outliers.
2023-08-10 12:50:26,991:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:50:27,015:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=5971,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:50:27,015:INFO:Creating final display dataframe.
2023-08-10 12:50:31,288:INFO:Setup _display_container:                     Description            Value
0                    Session id             5971
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2523, 17)
5   Transformed train set shape       (1738, 17)
6    Transformed test set shape        (785, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15              Remove outliers          iforest
16           Outliers threshold             0.05
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment    DagshubLogger
22              Experiment Name   Customer Churn
23                          USI             ec0f
2023-08-10 12:50:31,592:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:31,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:31,848:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:50:31,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:50:31,864:INFO:Logging experiment in loggers
2023-08-10 12:51:49,314:INFO:PyCaret ClassificationExperiment
2023-08-10 12:51:49,314:INFO:Logging name: Customer Churn
2023-08-10 12:51:49,314:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 12:51:49,314:INFO:version 3.0.4
2023-08-10 12:51:49,314:INFO:Initializing setup()
2023-08-10 12:51:49,314:INFO:self.USI: a7a6
2023-08-10 12:51:49,314:INFO:self._variable_keys: {'X_train', 'target_param', 'y_train', '_available_plots', 'X_test', 'is_multiclass', 'y', 'pipeline', 'idx', 'logging_param', 'html_param', 'exp_name_log', 'memory', 'fix_imbalance', 'log_plots_param', 'fold_generator', 'X', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'seed', 'USI', 'exp_id', 'fold_shuffle_param', 'gpu_param', '_ml_usecase', 'y_test', 'n_jobs_param'}
2023-08-10 12:51:49,314:INFO:Checking environment
2023-08-10 12:51:49,314:INFO:python_version: 3.9.13
2023-08-10 12:51:49,314:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 12:51:49,314:INFO:machine: AMD64
2023-08-10 12:51:49,314:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 12:51:49,329:INFO:Memory: svmem(total=7480111104, available=927539200, percent=87.6, used=6552571904, free=927539200)
2023-08-10 12:51:49,329:INFO:Physical Core: 4
2023-08-10 12:51:49,329:INFO:Logical Core: 4
2023-08-10 12:51:49,329:INFO:Checking libraries
2023-08-10 12:51:49,329:INFO:System:
2023-08-10 12:51:49,329:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 12:51:49,329:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 12:51:49,329:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 12:51:49,329:INFO:PyCaret required dependencies:
2023-08-10 12:51:49,329:INFO:                 pip: 23.1.2
2023-08-10 12:51:49,329:INFO:          setuptools: 58.1.0
2023-08-10 12:51:49,329:INFO:             pycaret: 3.0.4
2023-08-10 12:51:49,329:INFO:             IPython: 8.13.2
2023-08-10 12:51:49,337:INFO:          ipywidgets: 8.0.7
2023-08-10 12:51:49,337:INFO:                tqdm: 4.65.0
2023-08-10 12:51:49,337:INFO:               numpy: 1.23.5
2023-08-10 12:51:49,337:INFO:              pandas: 1.5.3
2023-08-10 12:51:49,337:INFO:              jinja2: 3.1.2
2023-08-10 12:51:49,337:INFO:               scipy: 1.10.1
2023-08-10 12:51:49,337:INFO:              joblib: 1.2.0
2023-08-10 12:51:49,337:INFO:             sklearn: 1.2.2
2023-08-10 12:51:49,337:INFO:                pyod: 1.1.0
2023-08-10 12:51:49,337:INFO:            imblearn: 0.11.0
2023-08-10 12:51:49,337:INFO:   category_encoders: 2.6.1
2023-08-10 12:51:49,337:INFO:            lightgbm: 4.0.0
2023-08-10 12:51:49,337:INFO:               numba: 0.57.1
2023-08-10 12:51:49,337:INFO:            requests: 2.31.0
2023-08-10 12:51:49,337:INFO:          matplotlib: 3.7.1
2023-08-10 12:51:49,337:INFO:          scikitplot: 0.3.7
2023-08-10 12:51:49,337:INFO:         yellowbrick: 1.5
2023-08-10 12:51:49,337:INFO:              plotly: 5.15.0
2023-08-10 12:51:49,337:INFO:    plotly-resampler: Not installed
2023-08-10 12:51:49,337:INFO:             kaleido: 0.2.1
2023-08-10 12:51:49,337:INFO:           schemdraw: 0.15
2023-08-10 12:51:49,337:INFO:         statsmodels: 0.14.0
2023-08-10 12:51:49,337:INFO:              sktime: 0.20.1
2023-08-10 12:51:49,337:INFO:               tbats: 1.1.3
2023-08-10 12:51:49,337:INFO:            pmdarima: 2.0.3
2023-08-10 12:51:49,337:INFO:              psutil: 5.9.5
2023-08-10 12:51:49,337:INFO:          markupsafe: 2.1.3
2023-08-10 12:51:49,337:INFO:             pickle5: Not installed
2023-08-10 12:51:49,337:INFO:         cloudpickle: 2.2.1
2023-08-10 12:51:49,337:INFO:         deprecation: 2.1.0
2023-08-10 12:51:49,337:INFO:              xxhash: 3.2.0
2023-08-10 12:51:49,337:INFO:           wurlitzer: Not installed
2023-08-10 12:51:49,337:INFO:PyCaret optional dependencies:
2023-08-10 12:51:49,337:INFO:                shap: Not installed
2023-08-10 12:51:49,337:INFO:           interpret: 0.4.2
2023-08-10 12:51:49,337:INFO:                umap: 0.5.3
2023-08-10 12:51:49,337:INFO:    pandas_profiling: Not installed
2023-08-10 12:51:49,337:INFO:  explainerdashboard: Not installed
2023-08-10 12:51:49,337:INFO:             autoviz: Not installed
2023-08-10 12:51:49,337:INFO:           fairlearn: Not installed
2023-08-10 12:51:49,337:INFO:          deepchecks: Not installed
2023-08-10 12:51:49,337:INFO:             xgboost: 1.7.6
2023-08-10 12:51:49,337:INFO:            catboost: Not installed
2023-08-10 12:51:49,337:INFO:              kmodes: Not installed
2023-08-10 12:51:49,337:INFO:             mlxtend: 0.22.0
2023-08-10 12:51:49,337:INFO:       statsforecast: Not installed
2023-08-10 12:51:49,337:INFO:        tune_sklearn: Not installed
2023-08-10 12:51:49,337:INFO:                 ray: Not installed
2023-08-10 12:51:49,337:INFO:            hyperopt: Not installed
2023-08-10 12:51:49,337:INFO:              optuna: Not installed
2023-08-10 12:51:49,337:INFO:               skopt: Not installed
2023-08-10 12:51:49,337:INFO:              mlflow: 2.4.2
2023-08-10 12:51:49,337:INFO:              gradio: Not installed
2023-08-10 12:51:49,337:INFO:             fastapi: Not installed
2023-08-10 12:51:49,337:INFO:             uvicorn: Not installed
2023-08-10 12:51:49,337:INFO:              m2cgen: Not installed
2023-08-10 12:51:49,337:INFO:           evidently: Not installed
2023-08-10 12:51:49,337:INFO:               fugue: Not installed
2023-08-10 12:51:49,337:INFO:           streamlit: 1.25.0
2023-08-10 12:51:49,337:INFO:             prophet: Not installed
2023-08-10 12:51:49,337:INFO:None
2023-08-10 12:51:49,337:INFO:Set up data.
2023-08-10 12:51:49,369:INFO:Set up train/test split.
2023-08-10 12:51:49,385:INFO:Set up index.
2023-08-10 12:51:49,385:INFO:Set up folding strategy.
2023-08-10 12:51:49,385:INFO:Assigning column types.
2023-08-10 12:51:49,401:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 12:51:49,569:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:51:49,577:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:51:49,689:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:49,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:49,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 12:51:49,889:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:51:50,001:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:50,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:50,017:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 12:51:50,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:51:50,298:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:50,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:50,465:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 12:51:50,569:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:50,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:50,577:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 12:51:50,873:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:50,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:51,281:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:51,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:51,305:INFO:Preparing preprocessing pipeline...
2023-08-10 12:51:51,313:INFO:Set up simple imputation.
2023-08-10 12:51:51,329:INFO:Set up encoding of categorical features.
2023-08-10 12:51:51,329:INFO:Set up removing outliers.
2023-08-10 12:51:51,705:INFO:Finished creating preprocessing pipeline.
2023-08-10 12:51:51,722:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:51:51,730:INFO:Creating final display dataframe.
2023-08-10 12:51:56,417:INFO:Setup _display_container:                     Description            Value
0                    Session id             6661
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2523, 17)
5   Transformed train set shape       (1738, 17)
6    Transformed test set shape        (785, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15              Remove outliers          iforest
16           Outliers threshold             0.05
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment    DagshubLogger
22              Experiment Name   Customer Churn
23                          USI             a7a6
2023-08-10 12:51:56,785:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:56,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:57,049:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 12:51:57,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 12:51:57,065:INFO:Logging experiment in loggers
2023-08-10 12:52:13,668:INFO:SubProcess save_model() called ==================================
2023-08-10 12:52:13,724:INFO:Initializing save_model()
2023-08-10 12:52:13,732:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05)))],
         verbose=False), model_name=C:\Users\HP\AppData\Local\Temp\tmpnh35vuad\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-10 12:52:13,732:INFO:Adding model into prep_pipe
2023-08-10 12:52:13,732:WARNING:Only Model saved as it was a pipeline.
2023-08-10 12:52:13,972:INFO:C:\Users\HP\AppData\Local\Temp\tmpnh35vuad\Transformation Pipeline.pkl saved in current working directory
2023-08-10 12:52:13,988:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:52:13,988:INFO:save_model() successfully completed......................................
2023-08-10 12:52:14,588:INFO:SubProcess save_model() end ==================================
2023-08-10 12:52:27,132:INFO:setup() successfully completed in 10.08s...............
2023-08-10 12:52:47,096:INFO:Initializing get_config()
2023-08-10 12:52:47,096:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, variable=pipeline)
2023-08-10 12:52:47,120:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 12:52:47,120:INFO:get_config() successfully completed......................................
2023-08-10 13:21:42,285:INFO:gpu_param set to False
2023-08-10 13:21:42,747:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 13:21:42,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 13:21:43,327:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 13:21:43,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 13:24:28,799:INFO:Initializing compare_models()
2023-08-10 13:24:28,800:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, include=['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt', 'nb'], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, 'include': ['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt', 'nb'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 13:24:28,800:INFO:Checking exceptions
2023-08-10 13:24:28,833:INFO:Preparing display monitor
2023-08-10 13:24:29,205:INFO:Initializing Ada Boost Classifier
2023-08-10 13:24:29,206:INFO:Total runtime is 1.6697247823079427e-05 minutes
2023-08-10 13:24:29,229:INFO:SubProcess create_model() called ==================================
2023-08-10 13:24:29,232:INFO:Initializing create_model()
2023-08-10 13:24:29,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:24:29,233:INFO:Checking exceptions
2023-08-10 13:24:29,234:INFO:Importing libraries
2023-08-10 13:24:29,234:INFO:Copying training dataset
2023-08-10 13:24:29,257:INFO:Defining folds
2023-08-10 13:24:29,257:INFO:Declaring metric variables
2023-08-10 13:24:29,277:INFO:Importing untrained model
2023-08-10 13:24:29,292:INFO:Ada Boost Classifier Imported successfully
2023-08-10 13:24:29,323:INFO:Starting cross validation
2023-08-10 13:24:29,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:24:56,398:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:24:58,721:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:24:58,825:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:24:59,059:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:24:59,654:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:25:00,539:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:25:00,792:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:01,140:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:01,795:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:02,267:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:04,267:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:04,502:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:05,589:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:12,753:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:25:14,768:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:25:15,299:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:15,384:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:25:16,670:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:25:17,407:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:25:17,420:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:18,024:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:19,287:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:19,618:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:25:19,933:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:25:19,991:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:21,386:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:25:22,748:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:23,123:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:24,947:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:31,336:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:25:32,655:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 13:25:34,629:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:36,479:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:25:36,829:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:25:38,159:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:25:38,857:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:40,165:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:25:55,804:INFO:Calculating mean and std
2023-08-10 13:25:55,814:INFO:Creating metrics dataframe
2023-08-10 13:25:58,986:INFO:Uploading results into container
2023-08-10 13:25:58,988:INFO:Uploading model into container now
2023-08-10 13:25:58,995:INFO:_master_model_container: 1
2023-08-10 13:25:58,995:INFO:_display_container: 2
2023-08-10 13:25:59,003:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6661)
2023-08-10 13:25:59,004:INFO:create_model() successfully completed......................................
2023-08-10 13:26:00,533:INFO:SubProcess create_model() end ==================================
2023-08-10 13:26:00,534:INFO:Creating metrics dataframe
2023-08-10 13:26:00,578:INFO:Initializing Gradient Boosting Classifier
2023-08-10 13:26:00,579:INFO:Total runtime is 1.5228993852933248 minutes
2023-08-10 13:26:00,593:INFO:SubProcess create_model() called ==================================
2023-08-10 13:26:00,595:INFO:Initializing create_model()
2023-08-10 13:26:00,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:26:00,596:INFO:Checking exceptions
2023-08-10 13:26:00,596:INFO:Importing libraries
2023-08-10 13:26:00,597:INFO:Copying training dataset
2023-08-10 13:26:00,621:INFO:Defining folds
2023-08-10 13:26:00,621:INFO:Declaring metric variables
2023-08-10 13:26:00,639:INFO:Importing untrained model
2023-08-10 13:26:00,654:INFO:Gradient Boosting Classifier Imported successfully
2023-08-10 13:26:00,703:INFO:Starting cross validation
2023-08-10 13:26:00,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:26:04,900:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:26:05,249:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:26:05,272:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:26:06,036:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:26:06,050:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:26:23,309:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:26:23,622:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:26:48,811:INFO:Calculating mean and std
2023-08-10 13:26:48,816:INFO:Creating metrics dataframe
2023-08-10 13:26:52,415:INFO:Uploading results into container
2023-08-10 13:26:52,417:INFO:Uploading model into container now
2023-08-10 13:26:52,418:INFO:_master_model_container: 2
2023-08-10 13:26:52,418:INFO:_display_container: 2
2023-08-10 13:26:52,420:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6661, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-10 13:26:52,422:INFO:create_model() successfully completed......................................
2023-08-10 13:26:53,000:INFO:SubProcess create_model() end ==================================
2023-08-10 13:26:53,000:INFO:Creating metrics dataframe
2023-08-10 13:26:53,052:INFO:Initializing Extreme Gradient Boosting
2023-08-10 13:26:53,052:INFO:Total runtime is 2.3974465092023216 minutes
2023-08-10 13:26:53,076:INFO:SubProcess create_model() called ==================================
2023-08-10 13:26:53,077:INFO:Initializing create_model()
2023-08-10 13:26:53,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:26:53,078:INFO:Checking exceptions
2023-08-10 13:26:53,078:INFO:Importing libraries
2023-08-10 13:26:53,079:INFO:Copying training dataset
2023-08-10 13:26:53,117:INFO:Defining folds
2023-08-10 13:26:53,119:INFO:Declaring metric variables
2023-08-10 13:26:53,160:INFO:Importing untrained model
2023-08-10 13:26:53,200:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 13:26:53,269:INFO:Starting cross validation
2023-08-10 13:26:53,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:27:33,810:INFO:Calculating mean and std
2023-08-10 13:27:33,815:INFO:Creating metrics dataframe
2023-08-10 13:27:38,379:INFO:Uploading results into container
2023-08-10 13:27:38,382:INFO:Uploading model into container now
2023-08-10 13:27:38,385:INFO:_master_model_container: 3
2023-08-10 13:27:38,389:INFO:_display_container: 2
2023-08-10 13:27:38,400:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 13:27:38,403:INFO:create_model() successfully completed......................................
2023-08-10 13:27:39,026:INFO:SubProcess create_model() end ==================================
2023-08-10 13:27:39,026:INFO:Creating metrics dataframe
2023-08-10 13:27:39,085:INFO:Initializing Random Forest Classifier
2023-08-10 13:27:39,086:INFO:Total runtime is 3.164672927061717 minutes
2023-08-10 13:27:39,111:INFO:SubProcess create_model() called ==================================
2023-08-10 13:27:39,112:INFO:Initializing create_model()
2023-08-10 13:27:39,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:27:39,113:INFO:Checking exceptions
2023-08-10 13:27:39,114:INFO:Importing libraries
2023-08-10 13:27:39,114:INFO:Copying training dataset
2023-08-10 13:27:39,151:INFO:Defining folds
2023-08-10 13:27:39,151:INFO:Declaring metric variables
2023-08-10 13:27:39,187:INFO:Importing untrained model
2023-08-10 13:27:39,211:INFO:Random Forest Classifier Imported successfully
2023-08-10 13:27:39,273:INFO:Starting cross validation
2023-08-10 13:27:39,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:27:43,289:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:27:43,407:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:27:43,462:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:27:43,976:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:27:44,912:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:27:44,930:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:27:44,981:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:27:45,696:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:27:55,313:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 13:27:57,476:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:27:57,627:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:27:57,844:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:28:00,288:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:28:00,313:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:28:00,380:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:28:00,442:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:28:03,247:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:28:12,609:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:28:12,829:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 13:28:14,210:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:28:14,426:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:28:30,129:INFO:Calculating mean and std
2023-08-10 13:28:30,132:INFO:Creating metrics dataframe
2023-08-10 13:28:33,872:INFO:Uploading results into container
2023-08-10 13:28:33,874:INFO:Uploading model into container now
2023-08-10 13:28:33,875:INFO:_master_model_container: 4
2023-08-10 13:28:33,876:INFO:_display_container: 2
2023-08-10 13:28:33,878:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6661, verbose=0, warm_start=False)
2023-08-10 13:28:33,878:INFO:create_model() successfully completed......................................
2023-08-10 13:28:34,443:INFO:SubProcess create_model() end ==================================
2023-08-10 13:28:34,443:INFO:Creating metrics dataframe
2023-08-10 13:28:34,496:INFO:Initializing Logistic Regression
2023-08-10 13:28:34,496:INFO:Total runtime is 4.088169737656911 minutes
2023-08-10 13:28:34,521:INFO:SubProcess create_model() called ==================================
2023-08-10 13:28:34,523:INFO:Initializing create_model()
2023-08-10 13:28:34,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:28:34,523:INFO:Checking exceptions
2023-08-10 13:28:34,524:INFO:Importing libraries
2023-08-10 13:28:34,524:INFO:Copying training dataset
2023-08-10 13:28:34,559:INFO:Defining folds
2023-08-10 13:28:34,559:INFO:Declaring metric variables
2023-08-10 13:28:34,579:INFO:Importing untrained model
2023-08-10 13:28:34,647:INFO:Logistic Regression Imported successfully
2023-08-10 13:28:34,727:INFO:Starting cross validation
2023-08-10 13:28:34,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:28:48,573:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 13:29:18,145:INFO:Calculating mean and std
2023-08-10 13:29:18,152:INFO:Creating metrics dataframe
2023-08-10 13:29:21,122:INFO:Uploading results into container
2023-08-10 13:29:21,125:INFO:Uploading model into container now
2023-08-10 13:29:21,126:INFO:_master_model_container: 5
2023-08-10 13:29:21,126:INFO:_display_container: 2
2023-08-10 13:29:21,128:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6661, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 13:29:21,128:INFO:create_model() successfully completed......................................
2023-08-10 13:29:21,572:INFO:SubProcess create_model() end ==================================
2023-08-10 13:29:21,574:INFO:Creating metrics dataframe
2023-08-10 13:29:21,623:INFO:Initializing K Neighbors Classifier
2023-08-10 13:29:21,624:INFO:Total runtime is 4.8736468354860945 minutes
2023-08-10 13:29:21,642:INFO:SubProcess create_model() called ==================================
2023-08-10 13:29:21,643:INFO:Initializing create_model()
2023-08-10 13:29:21,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:29:21,643:INFO:Checking exceptions
2023-08-10 13:29:21,644:INFO:Importing libraries
2023-08-10 13:29:21,644:INFO:Copying training dataset
2023-08-10 13:29:21,669:INFO:Defining folds
2023-08-10 13:29:21,669:INFO:Declaring metric variables
2023-08-10 13:29:21,700:INFO:Importing untrained model
2023-08-10 13:29:21,720:INFO:K Neighbors Classifier Imported successfully
2023-08-10 13:29:21,755:INFO:Starting cross validation
2023-08-10 13:29:21,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:29:50,011:INFO:Calculating mean and std
2023-08-10 13:29:50,017:INFO:Creating metrics dataframe
2023-08-10 13:29:52,814:INFO:Uploading results into container
2023-08-10 13:29:52,816:INFO:Uploading model into container now
2023-08-10 13:29:52,818:INFO:_master_model_container: 6
2023-08-10 13:29:52,818:INFO:_display_container: 2
2023-08-10 13:29:52,821:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-10 13:29:52,822:INFO:create_model() successfully completed......................................
2023-08-10 13:29:53,343:INFO:SubProcess create_model() end ==================================
2023-08-10 13:29:53,343:INFO:Creating metrics dataframe
2023-08-10 13:29:53,385:INFO:Initializing Decision Tree Classifier
2023-08-10 13:29:53,386:INFO:Total runtime is 5.403015104929606 minutes
2023-08-10 13:29:53,401:INFO:SubProcess create_model() called ==================================
2023-08-10 13:29:53,402:INFO:Initializing create_model()
2023-08-10 13:29:53,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:29:53,404:INFO:Checking exceptions
2023-08-10 13:29:53,404:INFO:Importing libraries
2023-08-10 13:29:53,405:INFO:Copying training dataset
2023-08-10 13:29:53,431:INFO:Defining folds
2023-08-10 13:29:53,432:INFO:Declaring metric variables
2023-08-10 13:29:53,452:INFO:Importing untrained model
2023-08-10 13:29:53,483:INFO:Decision Tree Classifier Imported successfully
2023-08-10 13:29:53,515:INFO:Starting cross validation
2023-08-10 13:29:53,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:30:18,405:INFO:Calculating mean and std
2023-08-10 13:30:18,408:INFO:Creating metrics dataframe
2023-08-10 13:30:23,731:INFO:Uploading results into container
2023-08-10 13:30:23,734:INFO:Uploading model into container now
2023-08-10 13:30:23,737:INFO:_master_model_container: 7
2023-08-10 13:30:23,737:INFO:_display_container: 2
2023-08-10 13:30:23,740:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6661, splitter='best')
2023-08-10 13:30:23,741:INFO:create_model() successfully completed......................................
2023-08-10 13:30:25,004:INFO:SubProcess create_model() end ==================================
2023-08-10 13:30:25,005:INFO:Creating metrics dataframe
2023-08-10 13:30:25,066:INFO:Initializing Naive Bayes
2023-08-10 13:30:25,067:INFO:Total runtime is 5.931035721302033 minutes
2023-08-10 13:30:25,083:INFO:SubProcess create_model() called ==================================
2023-08-10 13:30:25,086:INFO:Initializing create_model()
2023-08-10 13:30:25,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDFFEB50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:30:25,087:INFO:Checking exceptions
2023-08-10 13:30:25,087:INFO:Importing libraries
2023-08-10 13:30:25,087:INFO:Copying training dataset
2023-08-10 13:30:25,120:INFO:Defining folds
2023-08-10 13:30:25,121:INFO:Declaring metric variables
2023-08-10 13:30:25,141:INFO:Importing untrained model
2023-08-10 13:30:25,168:INFO:Naive Bayes Imported successfully
2023-08-10 13:30:25,234:INFO:Starting cross validation
2023-08-10 13:30:25,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 13:30:27,075:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 13:30:54,951:INFO:Calculating mean and std
2023-08-10 13:30:54,954:INFO:Creating metrics dataframe
2023-08-10 13:30:57,566:INFO:Uploading results into container
2023-08-10 13:30:57,568:INFO:Uploading model into container now
2023-08-10 13:30:57,570:INFO:_master_model_container: 8
2023-08-10 13:30:57,570:INFO:_display_container: 2
2023-08-10 13:30:57,573:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 13:30:57,573:INFO:create_model() successfully completed......................................
2023-08-10 13:30:57,989:INFO:SubProcess create_model() end ==================================
2023-08-10 13:30:57,989:INFO:Creating metrics dataframe
2023-08-10 13:30:58,087:INFO:Initializing create_model()
2023-08-10 13:30:58,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 13:30:58,088:INFO:Checking exceptions
2023-08-10 13:30:58,094:INFO:Importing libraries
2023-08-10 13:30:58,094:INFO:Copying training dataset
2023-08-10 13:30:58,111:INFO:Defining folds
2023-08-10 13:30:58,111:INFO:Declaring metric variables
2023-08-10 13:30:58,112:INFO:Importing untrained model
2023-08-10 13:30:58,113:INFO:Declaring custom model
2023-08-10 13:30:58,118:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 13:30:58,185:INFO:Cross validation set to False
2023-08-10 13:30:58,185:INFO:Fitting Model
2023-08-10 13:31:01,183:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 13:31:01,183:INFO:create_model() successfully completed......................................
2023-08-10 13:31:01,663:INFO:Creating Dashboard logs
2023-08-10 13:31:01,683:INFO:Model: Extreme Gradient Boosting
2023-08-10 13:31:02,772:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 6661, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-08-10 13:31:08,348:INFO:Initializing predict_model()
2023-08-10 13:31:08,348:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F3F51280>)
2023-08-10 13:31:08,349:INFO:Checking exceptions
2023-08-10 13:31:08,349:INFO:Preloading libraries
2023-08-10 13:31:09,802:INFO:SubProcess plot_model() called ==================================
2023-08-10 13:31:09,805:INFO:Initializing plot_model()
2023-08-10 13:31:09,805:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpi7s1ue6z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 13:31:09,805:INFO:Checking exceptions
2023-08-10 13:31:09,814:INFO:Preloading libraries
2023-08-10 13:31:09,831:INFO:Copying training dataset
2023-08-10 13:31:09,832:INFO:Plot type: auc
2023-08-10 13:31:10,661:INFO:Fitting Model
2023-08-10 13:31:10,664:INFO:Scoring test/hold-out set
2023-08-10 13:31:10,762:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpi7s1ue6z\AUC.png'
2023-08-10 13:31:11,683:INFO:Visual Rendered Successfully
2023-08-10 13:31:12,098:INFO:plot_model() successfully completed......................................
2023-08-10 13:31:12,684:INFO:Initializing plot_model()
2023-08-10 13:31:12,684:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpi7s1ue6z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 13:31:12,685:INFO:Checking exceptions
2023-08-10 13:31:12,692:INFO:Preloading libraries
2023-08-10 13:31:12,712:INFO:Copying training dataset
2023-08-10 13:31:12,712:INFO:Plot type: confusion_matrix
2023-08-10 13:31:13,534:INFO:Fitting Model
2023-08-10 13:31:13,537:INFO:Scoring test/hold-out set
2023-08-10 13:31:13,625:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpi7s1ue6z\Confusion Matrix.png'
2023-08-10 13:31:14,085:INFO:Visual Rendered Successfully
2023-08-10 13:31:14,504:INFO:plot_model() successfully completed......................................
2023-08-10 13:31:15,804:INFO:Initializing plot_model()
2023-08-10 13:31:15,804:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpi7s1ue6z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 13:31:15,804:INFO:Checking exceptions
2023-08-10 13:31:15,814:INFO:Preloading libraries
2023-08-10 13:31:15,829:INFO:Copying training dataset
2023-08-10 13:31:15,829:INFO:Plot type: feature
2023-08-10 13:31:15,831:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 13:31:16,143:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpi7s1ue6z\Feature Importance.png'
2023-08-10 13:31:16,889:INFO:Visual Rendered Successfully
2023-08-10 13:31:17,305:INFO:plot_model() successfully completed......................................
2023-08-10 13:31:17,956:INFO:SubProcess plot_model() end ==================================
2023-08-10 13:31:25,981:INFO:Creating Dashboard logs
2023-08-10 13:31:25,993:INFO:Model: Naive Bayes
2023-08-10 13:31:26,828:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-08-10 13:31:44,837:INFO:Creating Dashboard logs
2023-08-10 13:31:44,849:INFO:Model: Decision Tree Classifier
2023-08-10 13:31:45,725:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 6661, 'splitter': 'best'}
2023-08-10 13:32:00,196:INFO:Creating Dashboard logs
2023-08-10 13:32:00,208:INFO:Model: Ada Boost Classifier
2023-08-10 13:32:01,040:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 6661}
2023-08-10 13:32:19,445:INFO:Creating Dashboard logs
2023-08-10 13:32:19,457:INFO:Model: Gradient Boosting Classifier
2023-08-10 13:32:20,343:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6661, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-08-10 13:32:33,608:INFO:Creating Dashboard logs
2023-08-10 13:32:33,617:INFO:Model: Random Forest Classifier
2023-08-10 13:32:34,435:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 13:32:50,041:INFO:Creating Dashboard logs
2023-08-10 13:32:50,051:INFO:Model: Logistic Regression
2023-08-10 13:32:50,876:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6661, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 13:33:04,167:INFO:Creating Dashboard logs
2023-08-10 13:33:04,182:INFO:Model: K Neighbors Classifier
2023-08-10 13:33:05,021:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-08-10 13:33:18,438:INFO:_master_model_container: 8
2023-08-10 13:33:18,439:INFO:_display_container: 2
2023-08-10 13:33:18,441:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 13:33:18,442:INFO:compare_models() successfully completed......................................
2023-08-10 15:20:14,763:INFO:Initializing create_model()
2023-08-10 15:20:14,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=xgboost, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 15:20:14,763:INFO:Checking exceptions
2023-08-10 15:20:14,891:INFO:Importing libraries
2023-08-10 15:20:14,891:INFO:Copying training dataset
2023-08-10 15:20:14,915:INFO:Defining folds
2023-08-10 15:20:14,915:INFO:Declaring metric variables
2023-08-10 15:20:14,947:INFO:Importing untrained model
2023-08-10 15:20:14,987:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 15:20:15,067:INFO:Cross validation set to False
2023-08-10 15:20:15,067:INFO:Fitting Model
2023-08-10 15:20:16,123:INFO:Initializing predict_model()
2023-08-10 15:20:16,123:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2AAB670>)
2023-08-10 15:20:16,123:INFO:Checking exceptions
2023-08-10 15:20:16,123:INFO:Preloading libraries
2023-08-10 15:20:16,123:INFO:Set up data.
2023-08-10 15:20:16,147:INFO:Set up index.
2023-08-10 15:20:17,483:INFO:Initializing predict_model()
2023-08-10 15:20:17,483:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2AAB670>)
2023-08-10 15:20:17,483:INFO:Checking exceptions
2023-08-10 15:20:17,483:INFO:Preloading libraries
2023-08-10 15:20:18,787:INFO:_display_container: 3
2023-08-10 15:20:23,908:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 15:20:23,909:INFO:create_model() successfully completed......................................
2023-08-10 15:21:34,198:INFO:Initializing create_model()
2023-08-10 15:21:34,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=nb, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 15:21:34,198:INFO:Checking exceptions
2023-08-10 15:21:34,278:INFO:Importing libraries
2023-08-10 15:21:34,278:INFO:Copying training dataset
2023-08-10 15:21:34,342:INFO:Defining folds
2023-08-10 15:21:34,342:INFO:Declaring metric variables
2023-08-10 15:21:34,486:INFO:Importing untrained model
2023-08-10 15:21:34,502:INFO:Naive Bayes Imported successfully
2023-08-10 15:21:34,654:INFO:Cross validation set to False
2023-08-10 15:21:34,654:INFO:Fitting Model
2023-08-10 15:21:36,333:INFO:Initializing predict_model()
2023-08-10 15:21:36,341:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F4315790>)
2023-08-10 15:21:36,341:INFO:Checking exceptions
2023-08-10 15:21:36,341:INFO:Preloading libraries
2023-08-10 15:21:36,341:INFO:Set up data.
2023-08-10 15:21:36,453:INFO:Set up index.
2023-08-10 15:21:38,745:INFO:Initializing predict_model()
2023-08-10 15:21:38,745:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3ED414AF0>)
2023-08-10 15:21:38,745:INFO:Checking exceptions
2023-08-10 15:21:38,745:INFO:Preloading libraries
2023-08-10 15:21:42,970:INFO:_display_container: 4
2023-08-10 15:21:51,372:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 15:21:51,372:INFO:create_model() successfully completed......................................
2023-08-10 15:23:12,620:INFO:Initializing create_model()
2023-08-10 15:23:12,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=dt, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 15:23:12,620:INFO:Checking exceptions
2023-08-10 15:23:12,684:INFO:Importing libraries
2023-08-10 15:23:12,692:INFO:Copying training dataset
2023-08-10 15:23:12,716:INFO:Defining folds
2023-08-10 15:23:12,716:INFO:Declaring metric variables
2023-08-10 15:23:12,732:INFO:Importing untrained model
2023-08-10 15:23:12,748:INFO:Decision Tree Classifier Imported successfully
2023-08-10 15:23:12,796:INFO:Cross validation set to False
2023-08-10 15:23:12,796:INFO:Fitting Model
2023-08-10 15:23:13,252:INFO:Initializing predict_model()
2023-08-10 15:23:13,252:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=6661, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2AAB5E0>)
2023-08-10 15:23:13,252:INFO:Checking exceptions
2023-08-10 15:23:13,252:INFO:Preloading libraries
2023-08-10 15:23:13,252:INFO:Set up data.
2023-08-10 15:23:13,324:INFO:Set up index.
2023-08-10 15:23:14,194:INFO:Initializing predict_model()
2023-08-10 15:23:14,194:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=6661, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2AAB5E0>)
2023-08-10 15:23:14,202:INFO:Checking exceptions
2023-08-10 15:23:14,202:INFO:Preloading libraries
2023-08-10 15:23:15,410:INFO:_display_container: 5
2023-08-10 15:23:17,818:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6661, splitter='best')
2023-08-10 15:23:17,818:INFO:create_model() successfully completed......................................
2023-08-10 15:31:02,280:INFO:Initializing ensemble_model()
2023-08-10 15:31:02,280:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6661, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.35, verbose=False, return_train_score=False)
2023-08-10 15:31:02,280:INFO:Checking exceptions
2023-08-10 15:31:02,304:INFO:Importing libraries
2023-08-10 15:31:02,304:INFO:Copying training dataset
2023-08-10 15:31:02,304:INFO:Checking base model
2023-08-10 15:31:02,304:INFO:Base model : Decision Tree Classifier
2023-08-10 15:31:02,304:INFO:Importing untrained ensembler
2023-08-10 15:31:02,304:INFO:Ensemble method set to Bagging
2023-08-10 15:31:02,304:INFO:SubProcess create_model() called ==================================
2023-08-10 15:31:02,312:INFO:Initializing create_model()
2023-08-10 15:31:02,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   random_state=6661,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.35, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3ED1C6550>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 15:31:02,312:INFO:Checking exceptions
2023-08-10 15:31:02,312:INFO:Importing libraries
2023-08-10 15:31:02,312:INFO:Copying training dataset
2023-08-10 15:31:02,336:INFO:Defining folds
2023-08-10 15:31:02,336:INFO:Declaring metric variables
2023-08-10 15:31:02,336:INFO:Importing untrained model
2023-08-10 15:31:02,336:INFO:Declaring custom model
2023-08-10 15:31:02,344:INFO:Bagging Classifier Imported successfully
2023-08-10 15:31:02,344:INFO:Starting cross validation
2023-08-10 15:31:02,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 15:31:35,598:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:31:56,736:INFO:Calculating mean and std
2023-08-10 15:31:56,744:INFO:Creating metrics dataframe
2023-08-10 15:31:56,744:INFO:Finalizing model
2023-08-10 15:31:59,984:INFO:Uploading results into container
2023-08-10 15:31:59,984:INFO:Uploading model into container now
2023-08-10 15:31:59,984:INFO:_master_model_container: 9
2023-08-10 15:31:59,984:INFO:_display_container: 6
2023-08-10 15:31:59,992:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 15:31:59,992:INFO:create_model() successfully completed......................................
2023-08-10 15:32:00,416:INFO:SubProcess create_model() end ==================================
2023-08-10 15:32:00,416:INFO:Creating Dashboard logs
2023-08-10 15:32:00,416:INFO:Model: Bagging Classifier
2023-08-10 15:32:01,440:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 15:32:16,042:INFO:Initializing predict_model()
2023-08-10 15:32:16,042:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2C3B4C0>)
2023-08-10 15:32:16,050:INFO:Checking exceptions
2023-08-10 15:32:16,050:INFO:Preloading libraries
2023-08-10 15:32:17,674:INFO:SubProcess plot_model() called ==================================
2023-08-10 15:32:17,690:INFO:Initializing plot_model()
2023-08-10 15:32:17,690:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp2iv_ph1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 15:32:17,690:INFO:Checking exceptions
2023-08-10 15:32:17,698:INFO:Preloading libraries
2023-08-10 15:32:17,706:INFO:Copying training dataset
2023-08-10 15:32:17,706:INFO:Plot type: auc
2023-08-10 15:32:18,546:INFO:Fitting Model
2023-08-10 15:32:18,554:INFO:Scoring test/hold-out set
2023-08-10 15:32:18,666:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp2iv_ph1a\AUC.png'
2023-08-10 15:32:19,586:INFO:Visual Rendered Successfully
2023-08-10 15:32:20,266:INFO:plot_model() successfully completed......................................
2023-08-10 15:32:21,322:INFO:Initializing plot_model()
2023-08-10 15:32:21,330:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp2iv_ph1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 15:32:21,330:INFO:Checking exceptions
2023-08-10 15:32:21,338:INFO:Preloading libraries
2023-08-10 15:32:21,354:INFO:Copying training dataset
2023-08-10 15:32:21,354:INFO:Plot type: confusion_matrix
2023-08-10 15:32:22,242:INFO:Fitting Model
2023-08-10 15:32:22,242:INFO:Scoring test/hold-out set
2023-08-10 15:32:22,410:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp2iv_ph1a\Confusion Matrix.png'
2023-08-10 15:32:23,402:INFO:Visual Rendered Successfully
2023-08-10 15:32:24,307:INFO:plot_model() successfully completed......................................
2023-08-10 15:32:26,282:INFO:Initializing plot_model()
2023-08-10 15:32:26,282:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp2iv_ph1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 15:32:26,282:INFO:Checking exceptions
2023-08-10 15:32:26,290:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 15:32:26,290:INFO:SubProcess plot_model() end ==================================
2023-08-10 15:32:34,500:INFO:_master_model_container: 9
2023-08-10 15:32:34,500:INFO:_display_container: 6
2023-08-10 15:32:34,508:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 15:32:34,508:INFO:ensemble_model() successfully completed......................................
2023-08-10 15:32:35,052:INFO:Initializing tune_model()
2023-08-10 15:32:35,052:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 15:32:35,052:INFO:Checking exceptions
2023-08-10 15:32:35,132:INFO:Copying training dataset
2023-08-10 15:32:35,156:INFO:Checking base model
2023-08-10 15:32:35,156:INFO:Base model : Bagging Classifier
2023-08-10 15:32:35,172:INFO:Declaring metric variables
2023-08-10 15:32:35,196:INFO:Defining Hyperparameters
2023-08-10 15:32:35,941:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 15:32:35,941:INFO:Tuning with n_jobs=-1
2023-08-10 15:32:35,941:INFO:Initializing RandomizedSearchCV
2023-08-10 15:33:10,571:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:33:15,155:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:33:20,803:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:33:25,357:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:33:36,759:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:33:44,031:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:33:47,183:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:33:51,199:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:06,386:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:11,755:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:14,315:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:15,364:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:17,044:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:18,188:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:20,005:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:22,036:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:25,058:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:28,019:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:31,308:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:33,969:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:38,271:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:40,619:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:45,249:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:47,056:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:50,572:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:52,624:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:34:55,673:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 15:34:57,150:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:19,818:INFO:best_params: {'actual_estimator__n_estimators': 150}
2023-08-10 15:35:19,821:INFO:Hyperparameter search completed
2023-08-10 15:35:19,822:INFO:SubProcess create_model() called ==================================
2023-08-10 15:35:19,835:INFO:Initializing create_model()
2023-08-10 15:35:19,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F2EA1100>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150})
2023-08-10 15:35:19,837:INFO:Checking exceptions
2023-08-10 15:35:19,838:INFO:Importing libraries
2023-08-10 15:35:19,839:INFO:Copying training dataset
2023-08-10 15:35:19,866:INFO:Defining folds
2023-08-10 15:35:19,866:INFO:Declaring metric variables
2023-08-10 15:35:19,882:INFO:Importing untrained model
2023-08-10 15:35:19,883:INFO:Declaring custom model
2023-08-10 15:35:19,902:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 15:35:19,932:INFO:Starting cross validation
2023-08-10 15:35:20,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 15:35:22,552:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:22,578:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:22,647:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:22,680:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:25,118:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:25,205:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:25,298:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:25,318:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:34,876:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:35,339:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:35,843:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:36,792:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:37,584:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:37,709:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:38,099:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:44,918:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:46,583:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:46,659:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 15:35:59,364:INFO:Calculating mean and std
2023-08-10 15:35:59,369:INFO:Creating metrics dataframe
2023-08-10 15:35:59,399:INFO:Finalizing model
2023-08-10 15:36:03,612:INFO:Initializing predict_model()
2023-08-10 15:36:03,612:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=6661,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=150,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.35,
                                                      random_state=6661,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F44218B0>)
2023-08-10 15:36:03,613:INFO:Checking exceptions
2023-08-10 15:36:03,613:INFO:Preloading libraries
2023-08-10 15:36:03,614:INFO:Set up data.
2023-08-10 15:36:03,634:INFO:Set up index.
2023-08-10 15:36:06,795:INFO:Uploading results into container
2023-08-10 15:36:06,797:INFO:Uploading model into container now
2023-08-10 15:36:06,802:INFO:_master_model_container: 10
2023-08-10 15:36:06,802:INFO:_display_container: 7
2023-08-10 15:36:06,813:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 15:36:06,814:INFO:create_model() successfully completed......................................
2023-08-10 15:36:07,249:INFO:SubProcess create_model() end ==================================
2023-08-10 15:36:07,249:INFO:choose_better activated
2023-08-10 15:36:07,261:INFO:SubProcess create_model() called ==================================
2023-08-10 15:36:07,269:INFO:Initializing create_model()
2023-08-10 15:36:07,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 15:36:07,270:INFO:Checking exceptions
2023-08-10 15:36:07,275:INFO:Importing libraries
2023-08-10 15:36:07,276:INFO:Copying training dataset
2023-08-10 15:36:07,295:INFO:Defining folds
2023-08-10 15:36:07,296:INFO:Declaring metric variables
2023-08-10 15:36:07,298:INFO:Importing untrained model
2023-08-10 15:36:07,298:INFO:Declaring custom model
2023-08-10 15:36:07,303:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 15:36:07,304:INFO:Starting cross validation
2023-08-10 15:36:07,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 15:36:36,227:INFO:Calculating mean and std
2023-08-10 15:36:36,228:INFO:Creating metrics dataframe
2023-08-10 15:36:36,235:INFO:Finalizing model
2023-08-10 15:36:39,374:INFO:Uploading results into container
2023-08-10 15:36:39,376:INFO:Uploading model into container now
2023-08-10 15:36:39,377:INFO:_master_model_container: 11
2023-08-10 15:36:39,378:INFO:_display_container: 8
2023-08-10 15:36:39,386:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 15:36:39,388:INFO:create_model() successfully completed......................................
2023-08-10 15:36:39,802:INFO:SubProcess create_model() end ==================================
2023-08-10 15:36:39,812:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.6366
2023-08-10 15:36:39,825:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.6718
2023-08-10 15:36:39,834:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) is best model
2023-08-10 15:36:39,835:INFO:choose_better completed
2023-08-10 15:36:39,836:INFO:Creating Dashboard logs
2023-08-10 15:36:39,848:INFO:Model: Bagging Classifier
2023-08-10 15:38:46,325:ERROR:_log_model() for CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) raised an exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\socket.py", line 954, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connectionpool.py", line 714, in urlopen
    httplib_response = self._make_request(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connectionpool.py", line 403, in _make_request
    self._validate_conn(conn)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connectionpool.py", line 1053, in _validate_conn
    conn.connect()
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000002C3F444A3A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connectionpool.py", line 826, in urlopen
    return self.urlopen(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connectionpool.py", line 826, in urlopen
    return self.urlopen(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connectionpool.py", line 826, in urlopen
    return self.urlopen(
  [Previous line repeated 2 more times]
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\connectionpool.py", line 798, in urlopen
    retries = retries.increment(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='dagshub.com', port=443): Max retries exceeded with url: /abrahamtarra/Customer_Churn.mlflow/api/2.0/mlflow/experiments/get-by-name?experiment_name=Customer+Churn (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002C3F444A3A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\utils\rest_utils.py", line 93, in http_request
    return _get_http_response_with_retries(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\utils\request_utils.py", line 131, in _get_http_response_with_retries
    return session.request(method, url, **kwargs)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='dagshub.com', port=443): Max retries exceeded with url: /abrahamtarra/Customer_Churn.mlflow/api/2.0/mlflow/experiments/get-by-name?experiment_name=Customer+Churn (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002C3F444A3A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 186, in _log_model
    self.logging_param.log_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 64, in log_model
    self.init_loggers(experiment.exp_name_log, full_name, setup=False)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 31, in init_loggers
    logger.init_experiment(exp_name_log, full_name, setup=setup)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dagshub_logger.py", line 75, in init_experiment
    super().init_experiment(*args, **kwargs)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\mlflow_logger.py", line 53, in init_experiment
    mlflow.set_experiment(exp_name_log)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\tracking\fluent.py", line 126, in set_experiment
    experiment = client.get_experiment_by_name(experiment_name)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\tracking\client.py", line 507, in get_experiment_by_name
    return self._tracking_client.get_experiment_by_name(name)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\tracking\_tracking_service\client.py", line 222, in get_experiment_by_name
    return self.store.get_experiment_by_name(name)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\store\tracking\rest_store.py", line 307, in get_experiment_by_name
    response_proto = self._call_endpoint(GetExperimentByName, req_body)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\store\tracking\rest_store.py", line 59, in _call_endpoint
    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\utils\rest_utils.py", line 197, in call_endpoint
    response = http_request(**call_kwargs)
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\mlflow\utils\rest_utils.py", line 111, in http_request
    raise MlflowException(f"API request to {url} failed with exception {e}")
mlflow.exceptions.MlflowException: API request to https://dagshub.com/abrahamtarra/Customer_Churn.mlflow/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPSConnectionPool(host='dagshub.com', port=443): Max retries exceeded with url: /abrahamtarra/Customer_Churn.mlflow/api/2.0/mlflow/experiments/get-by-name?experiment_name=Customer+Churn (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002C3F444A3A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

2023-08-10 15:38:46,389:INFO:_master_model_container: 11
2023-08-10 15:38:46,390:INFO:_display_container: 7
2023-08-10 15:38:46,401:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 15:38:46,402:INFO:tune_model() successfully completed......................................
2023-08-10 16:02:40,214:INFO:Initializing tune_model()
2023-08-10 16:02:40,214:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=100, custom_grid=None, optimize=Bal. Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 16:02:40,215:INFO:Checking exceptions
2023-08-10 16:02:40,285:INFO:Copying training dataset
2023-08-10 16:02:40,298:INFO:Checking base model
2023-08-10 16:02:40,298:INFO:Base model : Naive Bayes
2023-08-10 16:02:40,314:INFO:Declaring metric variables
2023-08-10 16:02:40,332:INFO:Defining Hyperparameters
2023-08-10 16:02:40,333:INFO:100 is bigger than total combinations 28, setting search algorithm to grid
2023-08-10 16:02:41,102:INFO:Tuning with n_jobs=-1
2023-08-10 16:02:41,103:INFO:Initializing GridSearchCV
2023-08-10 16:15:46,710:INFO:best_params: {'actual_estimator__var_smoothing': 1e-05}
2023-08-10 16:15:46,714:INFO:Hyperparameter search completed
2023-08-10 16:15:46,715:INFO:SubProcess create_model() called ==================================
2023-08-10 16:15:46,716:INFO:Initializing create_model()
2023-08-10 16:15:46,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDB14AC0>, model_only=True, return_train_score=True, kwargs={'var_smoothing': 1e-05})
2023-08-10 16:15:46,717:INFO:Checking exceptions
2023-08-10 16:15:46,718:INFO:Importing libraries
2023-08-10 16:15:46,719:INFO:Copying training dataset
2023-08-10 16:15:46,746:INFO:Defining folds
2023-08-10 16:15:46,747:INFO:Declaring metric variables
2023-08-10 16:15:46,764:INFO:Importing untrained model
2023-08-10 16:15:46,764:INFO:Declaring custom model
2023-08-10 16:15:46,778:INFO:Naive Bayes Imported successfully
2023-08-10 16:15:46,809:INFO:Starting cross validation
2023-08-10 16:15:46,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:16:19,256:INFO:Calculating mean and std
2023-08-10 16:16:19,262:INFO:Creating metrics dataframe
2023-08-10 16:16:19,301:INFO:Finalizing model
2023-08-10 16:16:19,547:INFO:Initializing predict_model()
2023-08-10 16:16:19,548:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-05))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F3F51550>)
2023-08-10 16:16:19,548:INFO:Checking exceptions
2023-08-10 16:16:19,548:INFO:Preloading libraries
2023-08-10 16:16:19,549:INFO:Set up data.
2023-08-10 16:16:19,573:INFO:Set up index.
2023-08-10 16:16:23,591:INFO:Uploading results into container
2023-08-10 16:16:23,600:INFO:Uploading model into container now
2023-08-10 16:16:23,607:INFO:_master_model_container: 12
2023-08-10 16:16:23,607:INFO:_display_container: 8
2023-08-10 16:16:23,608:INFO:GaussianNB(priors=None, var_smoothing=1e-05)
2023-08-10 16:16:23,608:INFO:create_model() successfully completed......................................
2023-08-10 16:16:24,045:INFO:SubProcess create_model() end ==================================
2023-08-10 16:16:24,045:INFO:choose_better activated
2023-08-10 16:16:24,055:INFO:SubProcess create_model() called ==================================
2023-08-10 16:16:24,056:INFO:Initializing create_model()
2023-08-10 16:16:24,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 16:16:24,057:INFO:Checking exceptions
2023-08-10 16:16:24,064:INFO:Importing libraries
2023-08-10 16:16:24,064:INFO:Copying training dataset
2023-08-10 16:16:24,087:INFO:Defining folds
2023-08-10 16:16:24,087:INFO:Declaring metric variables
2023-08-10 16:16:24,088:INFO:Importing untrained model
2023-08-10 16:16:24,088:INFO:Declaring custom model
2023-08-10 16:16:24,089:INFO:Naive Bayes Imported successfully
2023-08-10 16:16:24,090:INFO:Starting cross validation
2023-08-10 16:16:24,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:16:51,184:INFO:Calculating mean and std
2023-08-10 16:16:51,186:INFO:Creating metrics dataframe
2023-08-10 16:16:51,193:INFO:Finalizing model
2023-08-10 16:16:54,278:INFO:Uploading results into container
2023-08-10 16:16:54,280:INFO:Uploading model into container now
2023-08-10 16:16:54,281:INFO:_master_model_container: 13
2023-08-10 16:16:54,282:INFO:_display_container: 9
2023-08-10 16:16:54,282:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 16:16:54,283:INFO:create_model() successfully completed......................................
2023-08-10 16:16:54,686:INFO:SubProcess create_model() end ==================================
2023-08-10 16:16:54,687:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Bal. Accuracy is 0.7475
2023-08-10 16:16:54,688:INFO:GaussianNB(priors=None, var_smoothing=1e-05) result for Bal. Accuracy is 0.7525
2023-08-10 16:16:54,689:INFO:GaussianNB(priors=None, var_smoothing=1e-05) is best model
2023-08-10 16:16:54,689:INFO:choose_better completed
2023-08-10 16:16:54,690:INFO:Creating Dashboard logs
2023-08-10 16:16:54,702:INFO:Model: Naive Bayes
2023-08-10 16:16:55,756:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-05}
2023-08-10 16:17:01,193:INFO:Initializing predict_model()
2023-08-10 16:17:01,193:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F3FCE160>)
2023-08-10 16:17:01,193:INFO:Checking exceptions
2023-08-10 16:17:01,193:INFO:Preloading libraries
2023-08-10 16:17:02,621:INFO:SubProcess plot_model() called ==================================
2023-08-10 16:17:02,622:INFO:Initializing plot_model()
2023-08-10 16:17:02,622:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmptn4b70ba, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:17:02,623:INFO:Checking exceptions
2023-08-10 16:17:02,631:INFO:Preloading libraries
2023-08-10 16:17:02,631:INFO:Copying training dataset
2023-08-10 16:17:02,632:INFO:Plot type: auc
2023-08-10 16:17:03,371:INFO:Fitting Model
2023-08-10 16:17:03,372:INFO:Scoring test/hold-out set
2023-08-10 16:17:03,453:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmptn4b70ba\AUC.png'
2023-08-10 16:17:04,283:INFO:Visual Rendered Successfully
2023-08-10 16:17:04,687:INFO:plot_model() successfully completed......................................
2023-08-10 16:17:07,061:INFO:Initializing plot_model()
2023-08-10 16:17:07,062:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmptn4b70ba, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:17:07,062:INFO:Checking exceptions
2023-08-10 16:17:07,068:INFO:Preloading libraries
2023-08-10 16:17:07,070:INFO:Copying training dataset
2023-08-10 16:17:07,070:INFO:Plot type: confusion_matrix
2023-08-10 16:17:07,792:INFO:Fitting Model
2023-08-10 16:17:07,793:INFO:Scoring test/hold-out set
2023-08-10 16:17:07,857:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmptn4b70ba\Confusion Matrix.png'
2023-08-10 16:17:08,252:INFO:Visual Rendered Successfully
2023-08-10 16:17:08,654:INFO:plot_model() successfully completed......................................
2023-08-10 16:17:09,195:INFO:Initializing plot_model()
2023-08-10 16:17:09,195:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmptn4b70ba, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:17:09,196:INFO:Checking exceptions
2023-08-10 16:17:09,197:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 16:17:09,197:INFO:SubProcess plot_model() end ==================================
2023-08-10 16:17:18,487:INFO:_master_model_container: 13
2023-08-10 16:17:18,488:INFO:_display_container: 8
2023-08-10 16:17:18,489:INFO:GaussianNB(priors=None, var_smoothing=1e-05)
2023-08-10 16:17:18,489:INFO:tune_model() successfully completed......................................
2023-08-10 16:20:10,235:INFO:Initializing tune_model()
2023-08-10 16:20:10,236:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F2, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 16:20:10,236:INFO:Checking exceptions
2023-08-10 16:20:10,293:INFO:Copying training dataset
2023-08-10 16:20:10,310:INFO:Checking base model
2023-08-10 16:20:10,311:INFO:Base model : Naive Bayes
2023-08-10 16:20:10,324:INFO:Declaring metric variables
2023-08-10 16:20:10,337:INFO:Defining Hyperparameters
2023-08-10 16:20:11,055:INFO:Tuning with n_jobs=-1
2023-08-10 16:20:11,055:INFO:Initializing RandomizedSearchCV
2023-08-10 16:25:03,048:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2023-08-10 16:25:03,051:INFO:Hyperparameter search completed
2023-08-10 16:25:03,052:INFO:SubProcess create_model() called ==================================
2023-08-10 16:25:03,053:INFO:Initializing create_model()
2023-08-10 16:25:03,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F444AE80>, model_only=True, return_train_score=True, kwargs={'var_smoothing': 1e-09})
2023-08-10 16:25:03,054:INFO:Checking exceptions
2023-08-10 16:25:03,055:INFO:Importing libraries
2023-08-10 16:25:03,055:INFO:Copying training dataset
2023-08-10 16:25:03,074:INFO:Defining folds
2023-08-10 16:25:03,075:INFO:Declaring metric variables
2023-08-10 16:25:03,087:INFO:Importing untrained model
2023-08-10 16:25:03,087:INFO:Declaring custom model
2023-08-10 16:25:03,101:INFO:Naive Bayes Imported successfully
2023-08-10 16:25:03,143:INFO:Starting cross validation
2023-08-10 16:25:03,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:25:27,800:INFO:Calculating mean and std
2023-08-10 16:25:27,806:INFO:Creating metrics dataframe
2023-08-10 16:25:27,865:INFO:Finalizing model
2023-08-10 16:25:28,082:INFO:Initializing predict_model()
2023-08-10 16:25:28,083:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F1810C10>)
2023-08-10 16:25:28,083:INFO:Checking exceptions
2023-08-10 16:25:28,083:INFO:Preloading libraries
2023-08-10 16:25:28,084:INFO:Set up data.
2023-08-10 16:25:28,105:INFO:Set up index.
2023-08-10 16:25:31,328:INFO:Uploading results into container
2023-08-10 16:25:31,331:INFO:Uploading model into container now
2023-08-10 16:25:31,333:INFO:_master_model_container: 14
2023-08-10 16:25:31,334:INFO:_display_container: 9
2023-08-10 16:25:31,334:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 16:25:31,335:INFO:create_model() successfully completed......................................
2023-08-10 16:25:31,704:INFO:SubProcess create_model() end ==================================
2023-08-10 16:25:31,704:INFO:choose_better activated
2023-08-10 16:25:31,713:INFO:SubProcess create_model() called ==================================
2023-08-10 16:25:31,714:INFO:Initializing create_model()
2023-08-10 16:25:31,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 16:25:31,716:INFO:Checking exceptions
2023-08-10 16:25:31,721:INFO:Importing libraries
2023-08-10 16:25:31,721:INFO:Copying training dataset
2023-08-10 16:25:31,733:INFO:Defining folds
2023-08-10 16:25:31,733:INFO:Declaring metric variables
2023-08-10 16:25:31,734:INFO:Importing untrained model
2023-08-10 16:25:31,734:INFO:Declaring custom model
2023-08-10 16:25:31,735:INFO:Naive Bayes Imported successfully
2023-08-10 16:25:31,735:INFO:Starting cross validation
2023-08-10 16:25:31,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:25:54,589:INFO:Calculating mean and std
2023-08-10 16:25:54,590:INFO:Creating metrics dataframe
2023-08-10 16:25:54,599:INFO:Finalizing model
2023-08-10 16:25:57,305:INFO:Uploading results into container
2023-08-10 16:25:57,307:INFO:Uploading model into container now
2023-08-10 16:25:57,308:INFO:_master_model_container: 15
2023-08-10 16:25:57,308:INFO:_display_container: 10
2023-08-10 16:25:57,309:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 16:25:57,309:INFO:create_model() successfully completed......................................
2023-08-10 16:25:57,681:INFO:SubProcess create_model() end ==================================
2023-08-10 16:25:57,682:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F2 is 0.6289
2023-08-10 16:25:57,683:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F2 is 0.6289
2023-08-10 16:25:57,683:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2023-08-10 16:25:57,683:INFO:choose_better completed
2023-08-10 16:25:57,685:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-10 16:25:57,686:INFO:Creating Dashboard logs
2023-08-10 16:25:57,700:INFO:Model: Naive Bayes
2023-08-10 16:25:58,638:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-08-10 16:26:04,041:INFO:Initializing predict_model()
2023-08-10 16:26:04,041:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2BC8B80>)
2023-08-10 16:26:04,041:INFO:Checking exceptions
2023-08-10 16:26:04,041:INFO:Preloading libraries
2023-08-10 16:26:05,447:INFO:SubProcess plot_model() called ==================================
2023-08-10 16:26:05,448:INFO:Initializing plot_model()
2023-08-10 16:26:05,448:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp55qd73ph, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:26:05,448:INFO:Checking exceptions
2023-08-10 16:26:05,453:INFO:Preloading libraries
2023-08-10 16:26:05,454:INFO:Copying training dataset
2023-08-10 16:26:05,454:INFO:Plot type: auc
2023-08-10 16:26:06,249:INFO:Fitting Model
2023-08-10 16:26:06,250:INFO:Scoring test/hold-out set
2023-08-10 16:26:06,336:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp55qd73ph\AUC.png'
2023-08-10 16:26:07,240:INFO:Visual Rendered Successfully
2023-08-10 16:26:07,669:INFO:plot_model() successfully completed......................................
2023-08-10 16:26:08,618:INFO:Initializing plot_model()
2023-08-10 16:26:08,619:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp55qd73ph, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:26:08,619:INFO:Checking exceptions
2023-08-10 16:26:08,623:INFO:Preloading libraries
2023-08-10 16:26:08,624:INFO:Copying training dataset
2023-08-10 16:26:08,624:INFO:Plot type: confusion_matrix
2023-08-10 16:26:09,385:INFO:Fitting Model
2023-08-10 16:26:09,386:INFO:Scoring test/hold-out set
2023-08-10 16:26:09,454:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp55qd73ph\Confusion Matrix.png'
2023-08-10 16:26:09,870:INFO:Visual Rendered Successfully
2023-08-10 16:26:10,278:INFO:plot_model() successfully completed......................................
2023-08-10 16:26:10,837:INFO:Initializing plot_model()
2023-08-10 16:26:10,838:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp55qd73ph, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:26:10,838:INFO:Checking exceptions
2023-08-10 16:26:10,838:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 16:26:10,839:INFO:SubProcess plot_model() end ==================================
2023-08-10 16:26:23,011:INFO:_master_model_container: 15
2023-08-10 16:26:23,012:INFO:_display_container: 9
2023-08-10 16:26:23,013:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 16:26:23,013:INFO:tune_model() successfully completed......................................
2023-08-10 16:30:30,840:INFO:Initializing tune_model()
2023-08-10 16:30:30,840:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [5, 50, 250, 500], 'max_depth': [1, 3, 5, 7], 'learning_rate': [0.01, 0.1, 1, 10], 'max_iter': [10]}, optimize=F2, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 16:30:30,841:INFO:Checking exceptions
2023-08-10 16:30:30,906:INFO:Copying training dataset
2023-08-10 16:30:30,921:INFO:Checking base model
2023-08-10 16:30:30,923:INFO:Base model : Naive Bayes
2023-08-10 16:30:30,936:INFO:Declaring metric variables
2023-08-10 16:30:30,951:INFO:Defining Hyperparameters
2023-08-10 16:30:31,534:INFO:custom_grid: {'actual_estimator__n_estimators': [5, 50, 250, 500], 'actual_estimator__max_depth': [1, 3, 5, 7], 'actual_estimator__learning_rate': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [10]}
2023-08-10 16:30:31,534:INFO:Tuning with n_jobs=-1
2023-08-10 16:30:31,535:INFO:Initializing RandomizedSearchCV
2023-08-10 16:31:44,780:INFO:Initializing tune_model()
2023-08-10 16:31:44,781:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [5, 50, 250, 500], 'max_depth': [1, 3, 5, 7], 'learning_rate': [0.01, 0.1, 1, 10], 'max_iter': [10]}, optimize=F2, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 16:31:44,781:INFO:Checking exceptions
2023-08-10 16:31:44,863:INFO:Copying training dataset
2023-08-10 16:31:44,876:INFO:Checking base model
2023-08-10 16:31:44,877:INFO:Base model : Naive Bayes
2023-08-10 16:31:44,892:INFO:Declaring metric variables
2023-08-10 16:31:44,911:INFO:Defining Hyperparameters
2023-08-10 16:31:49,130:INFO:custom_grid: {'actual_estimator__n_estimators': [5, 50, 250, 500], 'actual_estimator__max_depth': [1, 3, 5, 7], 'actual_estimator__learning_rate': [0.01, 0.1, 1, 10], 'actual_estimator__max_iter': [10]}
2023-08-10 16:31:49,130:INFO:Tuning with n_jobs=-1
2023-08-10 16:31:49,130:INFO:Initializing RandomizedSearchCV
2023-08-10 16:33:17,297:INFO:Initializing tune_model()
2023-08-10 16:33:17,298:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F2, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 16:33:17,298:INFO:Checking exceptions
2023-08-10 16:33:17,365:INFO:Copying training dataset
2023-08-10 16:33:17,381:INFO:Checking base model
2023-08-10 16:33:17,382:INFO:Base model : Naive Bayes
2023-08-10 16:33:17,397:INFO:Declaring metric variables
2023-08-10 16:33:17,414:INFO:Defining Hyperparameters
2023-08-10 16:33:20,945:INFO:Tuning with n_jobs=-1
2023-08-10 16:33:20,945:INFO:Initializing RandomizedSearchCV
2023-08-10 16:34:06,047:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:34:32,476:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 16:39:53,724:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2023-08-10 16:39:53,726:INFO:Hyperparameter search completed
2023-08-10 16:39:53,727:INFO:SubProcess create_model() called ==================================
2023-08-10 16:39:53,729:INFO:Initializing create_model()
2023-08-10 16:39:53,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3ED835EB0>, model_only=True, return_train_score=True, kwargs={'var_smoothing': 1e-09})
2023-08-10 16:39:53,730:INFO:Checking exceptions
2023-08-10 16:39:53,730:INFO:Importing libraries
2023-08-10 16:39:53,732:INFO:Copying training dataset
2023-08-10 16:39:53,764:INFO:Defining folds
2023-08-10 16:39:53,765:INFO:Declaring metric variables
2023-08-10 16:39:53,782:INFO:Importing untrained model
2023-08-10 16:39:53,783:INFO:Declaring custom model
2023-08-10 16:39:53,808:INFO:Naive Bayes Imported successfully
2023-08-10 16:39:53,838:INFO:Starting cross validation
2023-08-10 16:39:53,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:40:22,785:INFO:Calculating mean and std
2023-08-10 16:40:22,791:INFO:Creating metrics dataframe
2023-08-10 16:40:22,831:INFO:Finalizing model
2023-08-10 16:40:23,061:INFO:Initializing predict_model()
2023-08-10 16:40:23,062:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6661,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C97700>)
2023-08-10 16:40:23,062:INFO:Checking exceptions
2023-08-10 16:40:23,062:INFO:Preloading libraries
2023-08-10 16:40:23,063:INFO:Set up data.
2023-08-10 16:40:23,086:INFO:Set up index.
2023-08-10 16:40:27,111:INFO:Uploading results into container
2023-08-10 16:40:27,114:INFO:Uploading model into container now
2023-08-10 16:40:27,117:INFO:_master_model_container: 16
2023-08-10 16:40:27,118:INFO:_display_container: 10
2023-08-10 16:40:27,119:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 16:40:27,120:INFO:create_model() successfully completed......................................
2023-08-10 16:40:27,665:INFO:SubProcess create_model() end ==================================
2023-08-10 16:40:27,668:INFO:choose_better activated
2023-08-10 16:40:27,681:INFO:SubProcess create_model() called ==================================
2023-08-10 16:40:27,682:INFO:Initializing create_model()
2023-08-10 16:40:27,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 16:40:27,685:INFO:Checking exceptions
2023-08-10 16:40:27,691:INFO:Importing libraries
2023-08-10 16:40:27,691:INFO:Copying training dataset
2023-08-10 16:40:27,705:INFO:Defining folds
2023-08-10 16:40:27,706:INFO:Declaring metric variables
2023-08-10 16:40:27,706:INFO:Importing untrained model
2023-08-10 16:40:27,706:INFO:Declaring custom model
2023-08-10 16:40:27,707:INFO:Naive Bayes Imported successfully
2023-08-10 16:40:27,708:INFO:Starting cross validation
2023-08-10 16:40:27,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:40:55,547:INFO:Calculating mean and std
2023-08-10 16:40:55,551:INFO:Creating metrics dataframe
2023-08-10 16:40:55,557:INFO:Finalizing model
2023-08-10 16:40:58,836:INFO:Uploading results into container
2023-08-10 16:40:58,838:INFO:Uploading model into container now
2023-08-10 16:40:58,839:INFO:_master_model_container: 17
2023-08-10 16:40:58,839:INFO:_display_container: 11
2023-08-10 16:40:58,840:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 16:40:58,840:INFO:create_model() successfully completed......................................
2023-08-10 16:40:59,286:INFO:SubProcess create_model() end ==================================
2023-08-10 16:40:59,287:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F2 is 0.6289
2023-08-10 16:40:59,289:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for F2 is 0.6289
2023-08-10 16:40:59,289:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2023-08-10 16:40:59,290:INFO:choose_better completed
2023-08-10 16:40:59,291:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-10 16:40:59,293:INFO:Creating Dashboard logs
2023-08-10 16:40:59,308:INFO:Model: Naive Bayes
2023-08-10 16:41:00,419:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-08-10 16:41:08,769:INFO:Initializing predict_model()
2023-08-10 16:41:08,769:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F28E45E0>)
2023-08-10 16:41:08,770:INFO:Checking exceptions
2023-08-10 16:41:08,770:INFO:Preloading libraries
2023-08-10 16:41:10,227:INFO:SubProcess plot_model() called ==================================
2023-08-10 16:41:10,228:INFO:Initializing plot_model()
2023-08-10 16:41:10,228:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpy2ztsvys, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:41:10,229:INFO:Checking exceptions
2023-08-10 16:41:10,237:INFO:Preloading libraries
2023-08-10 16:41:10,237:INFO:Copying training dataset
2023-08-10 16:41:10,237:INFO:Plot type: auc
2023-08-10 16:41:11,073:INFO:Fitting Model
2023-08-10 16:41:11,075:INFO:Scoring test/hold-out set
2023-08-10 16:41:11,172:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpy2ztsvys\AUC.png'
2023-08-10 16:41:12,129:INFO:Visual Rendered Successfully
2023-08-10 16:41:12,589:INFO:plot_model() successfully completed......................................
2023-08-10 16:41:13,423:INFO:Initializing plot_model()
2023-08-10 16:41:13,423:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpy2ztsvys, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:41:13,424:INFO:Checking exceptions
2023-08-10 16:41:13,430:INFO:Preloading libraries
2023-08-10 16:41:13,432:INFO:Copying training dataset
2023-08-10 16:41:13,433:INFO:Plot type: confusion_matrix
2023-08-10 16:41:14,299:INFO:Fitting Model
2023-08-10 16:41:14,301:INFO:Scoring test/hold-out set
2023-08-10 16:41:14,374:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpy2ztsvys\Confusion Matrix.png'
2023-08-10 16:41:14,922:INFO:Visual Rendered Successfully
2023-08-10 16:41:15,375:INFO:plot_model() successfully completed......................................
2023-08-10 16:41:15,936:INFO:Initializing plot_model()
2023-08-10 16:41:15,936:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpy2ztsvys, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:41:15,936:INFO:Checking exceptions
2023-08-10 16:41:15,937:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 16:41:15,937:INFO:SubProcess plot_model() end ==================================
2023-08-10 16:41:26,493:INFO:_master_model_container: 17
2023-08-10 16:41:26,494:INFO:_display_container: 10
2023-08-10 16:41:26,495:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 16:41:26,495:INFO:tune_model() successfully completed......................................
2023-08-10 16:42:05,037:INFO:Initializing ensemble_model()
2023-08-10 16:42:05,038:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6661, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.35, verbose=False, return_train_score=False)
2023-08-10 16:42:05,038:INFO:Checking exceptions
2023-08-10 16:42:05,052:INFO:Importing libraries
2023-08-10 16:42:05,053:INFO:Copying training dataset
2023-08-10 16:42:05,054:INFO:Checking base model
2023-08-10 16:42:05,054:INFO:Base model : Decision Tree Classifier
2023-08-10 16:42:05,055:INFO:Importing untrained ensembler
2023-08-10 16:42:05,055:INFO:Ensemble method set to Bagging
2023-08-10 16:42:05,055:INFO:SubProcess create_model() called ==================================
2023-08-10 16:42:05,059:INFO:Initializing create_model()
2023-08-10 16:42:05,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   random_state=6661,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.35, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F48F9DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 16:42:05,060:INFO:Checking exceptions
2023-08-10 16:42:05,060:INFO:Importing libraries
2023-08-10 16:42:05,060:INFO:Copying training dataset
2023-08-10 16:42:05,084:INFO:Defining folds
2023-08-10 16:42:05,084:INFO:Declaring metric variables
2023-08-10 16:42:05,085:INFO:Importing untrained model
2023-08-10 16:42:05,085:INFO:Declaring custom model
2023-08-10 16:42:05,088:INFO:Bagging Classifier Imported successfully
2023-08-10 16:42:05,088:INFO:Starting cross validation
2023-08-10 16:42:05,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:42:36,457:INFO:Calculating mean and std
2023-08-10 16:42:36,461:INFO:Creating metrics dataframe
2023-08-10 16:42:36,467:INFO:Finalizing model
2023-08-10 16:42:39,883:INFO:Uploading results into container
2023-08-10 16:42:39,884:INFO:Uploading model into container now
2023-08-10 16:42:39,886:INFO:_master_model_container: 18
2023-08-10 16:42:39,886:INFO:_display_container: 11
2023-08-10 16:42:39,897:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:42:39,897:INFO:create_model() successfully completed......................................
2023-08-10 16:42:40,349:INFO:SubProcess create_model() end ==================================
2023-08-10 16:42:40,350:INFO:Creating Dashboard logs
2023-08-10 16:42:40,351:INFO:Model: Bagging Classifier
2023-08-10 16:42:41,263:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 16:42:46,640:INFO:Initializing predict_model()
2023-08-10 16:42:46,640:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C69700>)
2023-08-10 16:42:46,640:INFO:Checking exceptions
2023-08-10 16:42:46,640:INFO:Preloading libraries
2023-08-10 16:42:48,075:INFO:SubProcess plot_model() called ==================================
2023-08-10 16:42:48,084:INFO:Initializing plot_model()
2023-08-10 16:42:48,085:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpud1mz_qp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:42:48,085:INFO:Checking exceptions
2023-08-10 16:42:48,090:INFO:Preloading libraries
2023-08-10 16:42:48,095:INFO:Copying training dataset
2023-08-10 16:42:48,096:INFO:Plot type: auc
2023-08-10 16:42:48,905:INFO:Fitting Model
2023-08-10 16:42:48,907:INFO:Scoring test/hold-out set
2023-08-10 16:42:48,997:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpud1mz_qp\AUC.png'
2023-08-10 16:42:49,879:INFO:Visual Rendered Successfully
2023-08-10 16:42:50,334:INFO:plot_model() successfully completed......................................
2023-08-10 16:42:51,258:INFO:Initializing plot_model()
2023-08-10 16:42:51,259:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpud1mz_qp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:42:51,260:INFO:Checking exceptions
2023-08-10 16:42:51,265:INFO:Preloading libraries
2023-08-10 16:42:51,269:INFO:Copying training dataset
2023-08-10 16:42:51,269:INFO:Plot type: confusion_matrix
2023-08-10 16:42:52,035:INFO:Fitting Model
2023-08-10 16:42:52,036:INFO:Scoring test/hold-out set
2023-08-10 16:42:52,119:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpud1mz_qp\Confusion Matrix.png'
2023-08-10 16:42:52,538:INFO:Visual Rendered Successfully
2023-08-10 16:42:52,982:INFO:plot_model() successfully completed......................................
2023-08-10 16:42:53,617:INFO:Initializing plot_model()
2023-08-10 16:42:53,618:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpud1mz_qp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:42:53,618:INFO:Checking exceptions
2023-08-10 16:42:53,619:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 16:42:53,619:INFO:SubProcess plot_model() end ==================================
2023-08-10 16:43:02,468:INFO:_master_model_container: 18
2023-08-10 16:43:02,469:INFO:_display_container: 11
2023-08-10 16:43:02,480:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:43:02,480:INFO:ensemble_model() successfully completed......................................
2023-08-10 16:43:02,946:INFO:Initializing tune_model()
2023-08-10 16:43:02,946:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=F2, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 16:43:02,947:INFO:Checking exceptions
2023-08-10 16:43:03,004:INFO:Copying training dataset
2023-08-10 16:43:03,020:INFO:Checking base model
2023-08-10 16:43:03,021:INFO:Base model : Bagging Classifier
2023-08-10 16:43:03,038:INFO:Declaring metric variables
2023-08-10 16:43:03,052:INFO:Defining Hyperparameters
2023-08-10 16:43:03,715:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 16:43:03,716:INFO:Tuning with n_jobs=-1
2023-08-10 16:43:03,716:INFO:Initializing RandomizedSearchCV
2023-08-10 16:45:02,570:INFO:best_params: {'actual_estimator__n_estimators': 100}
2023-08-10 16:45:02,574:INFO:Hyperparameter search completed
2023-08-10 16:45:02,574:INFO:SubProcess create_model() called ==================================
2023-08-10 16:45:02,588:INFO:Initializing create_model()
2023-08-10 16:45:02,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F4420D90>, model_only=True, return_train_score=True, kwargs={'n_estimators': 100})
2023-08-10 16:45:02,592:INFO:Checking exceptions
2023-08-10 16:45:02,593:INFO:Importing libraries
2023-08-10 16:45:02,594:INFO:Copying training dataset
2023-08-10 16:45:02,622:INFO:Defining folds
2023-08-10 16:45:02,623:INFO:Declaring metric variables
2023-08-10 16:45:02,636:INFO:Importing untrained model
2023-08-10 16:45:02,638:INFO:Declaring custom model
2023-08-10 16:45:02,655:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 16:45:02,691:INFO:Starting cross validation
2023-08-10 16:45:02,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:45:04,840:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:06,654:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:13,127:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:13,592:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:13,632:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:15,274:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:15,315:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:15,687:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:15,809:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:45:37,504:INFO:Calculating mean and std
2023-08-10 16:45:37,508:INFO:Creating metrics dataframe
2023-08-10 16:45:37,540:INFO:Finalizing model
2023-08-10 16:45:40,465:INFO:Initializing predict_model()
2023-08-10 16:45:40,466:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=6661,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.35,
                                                      random_state=6661,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F44E65E0>)
2023-08-10 16:45:40,466:INFO:Checking exceptions
2023-08-10 16:45:40,466:INFO:Preloading libraries
2023-08-10 16:45:40,469:INFO:Set up data.
2023-08-10 16:45:40,490:INFO:Set up index.
2023-08-10 16:45:43,939:INFO:Uploading results into container
2023-08-10 16:45:43,942:INFO:Uploading model into container now
2023-08-10 16:45:43,945:INFO:_master_model_container: 19
2023-08-10 16:45:43,946:INFO:_display_container: 12
2023-08-10 16:45:43,966:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:45:43,967:INFO:create_model() successfully completed......................................
2023-08-10 16:45:44,440:INFO:SubProcess create_model() end ==================================
2023-08-10 16:45:44,440:INFO:choose_better activated
2023-08-10 16:45:44,450:INFO:SubProcess create_model() called ==================================
2023-08-10 16:45:44,462:INFO:Initializing create_model()
2023-08-10 16:45:44,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 16:45:44,463:INFO:Checking exceptions
2023-08-10 16:45:44,470:INFO:Importing libraries
2023-08-10 16:45:44,470:INFO:Copying training dataset
2023-08-10 16:45:44,485:INFO:Defining folds
2023-08-10 16:45:44,485:INFO:Declaring metric variables
2023-08-10 16:45:44,486:INFO:Importing untrained model
2023-08-10 16:45:44,486:INFO:Declaring custom model
2023-08-10 16:45:44,491:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 16:45:44,491:INFO:Starting cross validation
2023-08-10 16:45:44,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:46:14,414:INFO:Calculating mean and std
2023-08-10 16:46:14,418:INFO:Creating metrics dataframe
2023-08-10 16:46:14,425:INFO:Finalizing model
2023-08-10 16:46:17,921:INFO:Uploading results into container
2023-08-10 16:46:17,923:INFO:Uploading model into container now
2023-08-10 16:46:17,924:INFO:_master_model_container: 20
2023-08-10 16:46:17,924:INFO:_display_container: 13
2023-08-10 16:46:17,936:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:46:17,937:INFO:create_model() successfully completed......................................
2023-08-10 16:46:18,394:INFO:SubProcess create_model() end ==================================
2023-08-10 16:46:18,405:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for F2 is 0.6924
2023-08-10 16:46:18,418:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for F2 is 0.7181
2023-08-10 16:46:18,426:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) is best model
2023-08-10 16:46:18,427:INFO:choose_better completed
2023-08-10 16:46:18,428:INFO:Creating Dashboard logs
2023-08-10 16:46:18,442:INFO:Model: Bagging Classifier
2023-08-10 16:46:19,320:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 16:46:24,609:INFO:Initializing predict_model()
2023-08-10 16:46:24,609:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2B66550>)
2023-08-10 16:46:24,609:INFO:Checking exceptions
2023-08-10 16:46:24,610:INFO:Preloading libraries
2023-08-10 16:46:27,313:INFO:SubProcess plot_model() called ==================================
2023-08-10 16:46:27,323:INFO:Initializing plot_model()
2023-08-10 16:46:27,323:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpf4agjnc4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:46:27,324:INFO:Checking exceptions
2023-08-10 16:46:27,328:INFO:Preloading libraries
2023-08-10 16:46:27,367:INFO:Copying training dataset
2023-08-10 16:46:27,367:INFO:Plot type: auc
2023-08-10 16:46:28,118:INFO:Fitting Model
2023-08-10 16:46:28,120:INFO:Scoring test/hold-out set
2023-08-10 16:46:28,341:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpf4agjnc4\AUC.png'
2023-08-10 16:46:29,200:INFO:Visual Rendered Successfully
2023-08-10 16:46:29,645:INFO:plot_model() successfully completed......................................
2023-08-10 16:46:31,393:INFO:Initializing plot_model()
2023-08-10 16:46:31,393:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpf4agjnc4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:46:31,393:INFO:Checking exceptions
2023-08-10 16:46:31,401:INFO:Preloading libraries
2023-08-10 16:46:31,430:INFO:Copying training dataset
2023-08-10 16:46:31,432:INFO:Plot type: confusion_matrix
2023-08-10 16:46:32,183:INFO:Fitting Model
2023-08-10 16:46:32,184:INFO:Scoring test/hold-out set
2023-08-10 16:46:32,394:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpf4agjnc4\Confusion Matrix.png'
2023-08-10 16:46:32,815:INFO:Visual Rendered Successfully
2023-08-10 16:46:33,257:INFO:plot_model() successfully completed......................................
2023-08-10 16:46:33,860:INFO:Initializing plot_model()
2023-08-10 16:46:33,860:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpf4agjnc4, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:46:33,860:INFO:Checking exceptions
2023-08-10 16:46:33,861:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 16:46:33,861:INFO:SubProcess plot_model() end ==================================
2023-08-10 16:46:48,334:INFO:_master_model_container: 20
2023-08-10 16:46:48,335:INFO:_display_container: 12
2023-08-10 16:46:48,347:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:46:48,348:INFO:tune_model() successfully completed......................................
2023-08-10 16:50:43,879:INFO:Initializing ensemble_model()
2023-08-10 16:50:43,880:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6661, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.35, verbose=False, return_train_score=False)
2023-08-10 16:50:43,881:INFO:Checking exceptions
2023-08-10 16:50:43,896:INFO:Importing libraries
2023-08-10 16:50:43,896:INFO:Copying training dataset
2023-08-10 16:50:43,897:INFO:Checking base model
2023-08-10 16:50:43,897:INFO:Base model : Decision Tree Classifier
2023-08-10 16:50:43,898:INFO:Importing untrained ensembler
2023-08-10 16:50:43,898:INFO:Ensemble method set to Bagging
2023-08-10 16:50:43,899:INFO:SubProcess create_model() called ==================================
2023-08-10 16:50:43,905:INFO:Initializing create_model()
2023-08-10 16:50:43,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   random_state=6661,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.35, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EB5C6340>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 16:50:43,907:INFO:Checking exceptions
2023-08-10 16:50:43,908:INFO:Importing libraries
2023-08-10 16:50:43,908:INFO:Copying training dataset
2023-08-10 16:50:43,925:INFO:Defining folds
2023-08-10 16:50:43,925:INFO:Declaring metric variables
2023-08-10 16:50:43,926:INFO:Importing untrained model
2023-08-10 16:50:43,926:INFO:Declaring custom model
2023-08-10 16:50:43,929:INFO:Bagging Classifier Imported successfully
2023-08-10 16:50:43,930:INFO:Starting cross validation
2023-08-10 16:50:43,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:51:15,590:INFO:Calculating mean and std
2023-08-10 16:51:15,591:INFO:Creating metrics dataframe
2023-08-10 16:51:15,597:INFO:Finalizing model
2023-08-10 16:51:18,996:INFO:Uploading results into container
2023-08-10 16:51:18,999:INFO:Uploading model into container now
2023-08-10 16:51:19,000:INFO:_master_model_container: 21
2023-08-10 16:51:19,000:INFO:_display_container: 13
2023-08-10 16:51:19,009:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:51:19,009:INFO:create_model() successfully completed......................................
2023-08-10 16:51:19,461:INFO:SubProcess create_model() end ==================================
2023-08-10 16:51:19,462:INFO:Creating Dashboard logs
2023-08-10 16:51:19,463:INFO:Model: Bagging Classifier
2023-08-10 16:51:20,310:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 16:51:25,551:INFO:Initializing predict_model()
2023-08-10 16:51:25,551:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C69700>)
2023-08-10 16:51:25,552:INFO:Checking exceptions
2023-08-10 16:51:25,552:INFO:Preloading libraries
2023-08-10 16:51:27,006:INFO:SubProcess plot_model() called ==================================
2023-08-10 16:51:27,019:INFO:Initializing plot_model()
2023-08-10 16:51:27,020:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp88c5rgv5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:51:27,020:INFO:Checking exceptions
2023-08-10 16:51:27,025:INFO:Preloading libraries
2023-08-10 16:51:27,031:INFO:Copying training dataset
2023-08-10 16:51:27,031:INFO:Plot type: auc
2023-08-10 16:51:27,757:INFO:Fitting Model
2023-08-10 16:51:27,759:INFO:Scoring test/hold-out set
2023-08-10 16:51:27,845:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp88c5rgv5\AUC.png'
2023-08-10 16:51:28,667:INFO:Visual Rendered Successfully
2023-08-10 16:51:29,087:INFO:plot_model() successfully completed......................................
2023-08-10 16:51:29,840:INFO:Initializing plot_model()
2023-08-10 16:51:29,840:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp88c5rgv5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:51:29,840:INFO:Checking exceptions
2023-08-10 16:51:29,846:INFO:Preloading libraries
2023-08-10 16:51:29,851:INFO:Copying training dataset
2023-08-10 16:51:29,852:INFO:Plot type: confusion_matrix
2023-08-10 16:51:30,585:INFO:Fitting Model
2023-08-10 16:51:30,586:INFO:Scoring test/hold-out set
2023-08-10 16:51:30,663:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp88c5rgv5\Confusion Matrix.png'
2023-08-10 16:51:31,074:INFO:Visual Rendered Successfully
2023-08-10 16:51:31,500:INFO:plot_model() successfully completed......................................
2023-08-10 16:51:32,016:INFO:Initializing plot_model()
2023-08-10 16:51:32,017:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp88c5rgv5, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:51:32,017:INFO:Checking exceptions
2023-08-10 16:51:32,019:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 16:51:32,019:INFO:SubProcess plot_model() end ==================================
2023-08-10 16:51:40,946:INFO:_master_model_container: 21
2023-08-10 16:51:40,946:INFO:_display_container: 13
2023-08-10 16:51:40,956:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:51:40,957:INFO:ensemble_model() successfully completed......................................
2023-08-10 16:51:41,389:INFO:Initializing tune_model()
2023-08-10 16:51:41,389:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 16:51:41,389:INFO:Checking exceptions
2023-08-10 16:51:41,460:INFO:Copying training dataset
2023-08-10 16:51:41,474:INFO:Checking base model
2023-08-10 16:51:41,475:INFO:Base model : Bagging Classifier
2023-08-10 16:51:41,490:INFO:Declaring metric variables
2023-08-10 16:51:41,502:INFO:Defining Hyperparameters
2023-08-10 16:51:42,133:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 16:51:42,134:INFO:Tuning with n_jobs=-1
2023-08-10 16:51:42,134:INFO:Initializing RandomizedSearchCV
2023-08-10 16:52:45,865:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:53:38,732:INFO:best_params: {'actual_estimator__n_estimators': 100}
2023-08-10 16:53:38,734:INFO:Hyperparameter search completed
2023-08-10 16:53:38,735:INFO:SubProcess create_model() called ==================================
2023-08-10 16:53:38,747:INFO:Initializing create_model()
2023-08-10 16:53:38,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F439D4F0>, model_only=True, return_train_score=True, kwargs={'n_estimators': 100})
2023-08-10 16:53:38,750:INFO:Checking exceptions
2023-08-10 16:53:38,751:INFO:Importing libraries
2023-08-10 16:53:38,752:INFO:Copying training dataset
2023-08-10 16:53:38,772:INFO:Defining folds
2023-08-10 16:53:38,773:INFO:Declaring metric variables
2023-08-10 16:53:38,788:INFO:Importing untrained model
2023-08-10 16:53:38,789:INFO:Declaring custom model
2023-08-10 16:53:38,818:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 16:53:38,853:INFO:Starting cross validation
2023-08-10 16:53:38,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:53:48,837:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 16:54:12,909:INFO:Calculating mean and std
2023-08-10 16:54:12,914:INFO:Creating metrics dataframe
2023-08-10 16:54:12,942:INFO:Finalizing model
2023-08-10 16:54:13,376:INFO:Initializing predict_model()
2023-08-10 16:54:13,376:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=6661,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.35,
                                                      random_state=6661,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C97430>)
2023-08-10 16:54:13,377:INFO:Checking exceptions
2023-08-10 16:54:13,377:INFO:Preloading libraries
2023-08-10 16:54:13,378:INFO:Set up data.
2023-08-10 16:54:13,399:INFO:Set up index.
2023-08-10 16:54:17,855:INFO:Uploading results into container
2023-08-10 16:54:17,859:INFO:Uploading model into container now
2023-08-10 16:54:17,860:INFO:_master_model_container: 22
2023-08-10 16:54:17,861:INFO:_display_container: 14
2023-08-10 16:54:17,887:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:54:17,887:INFO:create_model() successfully completed......................................
2023-08-10 16:54:18,364:INFO:SubProcess create_model() end ==================================
2023-08-10 16:54:18,364:INFO:choose_better activated
2023-08-10 16:54:18,377:INFO:SubProcess create_model() called ==================================
2023-08-10 16:54:18,390:INFO:Initializing create_model()
2023-08-10 16:54:18,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 16:54:18,391:INFO:Checking exceptions
2023-08-10 16:54:18,396:INFO:Importing libraries
2023-08-10 16:54:18,396:INFO:Copying training dataset
2023-08-10 16:54:18,414:INFO:Defining folds
2023-08-10 16:54:18,414:INFO:Declaring metric variables
2023-08-10 16:54:18,415:INFO:Importing untrained model
2023-08-10 16:54:18,415:INFO:Declaring custom model
2023-08-10 16:54:18,423:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 16:54:18,425:INFO:Starting cross validation
2023-08-10 16:54:18,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 16:54:48,623:INFO:Calculating mean and std
2023-08-10 16:54:48,625:INFO:Creating metrics dataframe
2023-08-10 16:54:48,632:INFO:Finalizing model
2023-08-10 16:54:51,883:INFO:Uploading results into container
2023-08-10 16:54:51,885:INFO:Uploading model into container now
2023-08-10 16:54:51,886:INFO:_master_model_container: 23
2023-08-10 16:54:51,887:INFO:_display_container: 15
2023-08-10 16:54:51,896:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:54:51,897:INFO:create_model() successfully completed......................................
2023-08-10 16:54:52,324:INFO:SubProcess create_model() end ==================================
2023-08-10 16:54:52,333:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Recall is 0.7105
2023-08-10 16:54:52,343:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Recall is 0.736
2023-08-10 16:54:52,351:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False) is best model
2023-08-10 16:54:52,352:INFO:choose_better completed
2023-08-10 16:54:52,353:INFO:Creating Dashboard logs
2023-08-10 16:54:52,367:INFO:Model: Bagging Classifier
2023-08-10 16:54:53,177:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 16:54:59,628:INFO:Initializing predict_model()
2023-08-10 16:54:59,628:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3ED4143A0>)
2023-08-10 16:54:59,629:INFO:Checking exceptions
2023-08-10 16:54:59,629:INFO:Preloading libraries
2023-08-10 16:55:01,208:INFO:SubProcess plot_model() called ==================================
2023-08-10 16:55:01,217:INFO:Initializing plot_model()
2023-08-10 16:55:01,218:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp15chwhlb, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:55:01,218:INFO:Checking exceptions
2023-08-10 16:55:01,224:INFO:Preloading libraries
2023-08-10 16:55:01,261:INFO:Copying training dataset
2023-08-10 16:55:01,261:INFO:Plot type: auc
2023-08-10 16:55:02,024:INFO:Fitting Model
2023-08-10 16:55:02,025:INFO:Scoring test/hold-out set
2023-08-10 16:55:02,239:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp15chwhlb\AUC.png'
2023-08-10 16:55:03,073:INFO:Visual Rendered Successfully
2023-08-10 16:55:03,510:INFO:plot_model() successfully completed......................................
2023-08-10 16:55:04,274:INFO:Initializing plot_model()
2023-08-10 16:55:04,275:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp15chwhlb, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:55:04,275:INFO:Checking exceptions
2023-08-10 16:55:04,279:INFO:Preloading libraries
2023-08-10 16:55:04,309:INFO:Copying training dataset
2023-08-10 16:55:04,310:INFO:Plot type: confusion_matrix
2023-08-10 16:55:05,067:INFO:Fitting Model
2023-08-10 16:55:05,068:INFO:Scoring test/hold-out set
2023-08-10 16:55:05,281:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp15chwhlb\Confusion Matrix.png'
2023-08-10 16:55:05,693:INFO:Visual Rendered Successfully
2023-08-10 16:55:06,122:INFO:plot_model() successfully completed......................................
2023-08-10 16:55:06,992:INFO:Initializing plot_model()
2023-08-10 16:55:06,993:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp15chwhlb, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 16:55:06,993:INFO:Checking exceptions
2023-08-10 16:55:06,993:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 16:55:06,994:INFO:SubProcess plot_model() end ==================================
2023-08-10 16:55:19,915:INFO:_master_model_container: 23
2023-08-10 16:55:19,915:INFO:_display_container: 14
2023-08-10 16:55:19,928:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False,
                                     probability_threshold=0.35,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 16:55:19,929:INFO:tune_model() successfully completed......................................
2023-08-10 17:02:59,755:INFO:Initializing ensemble_model()
2023-08-10 17:02:59,755:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6661, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 17:02:59,756:INFO:Checking exceptions
2023-08-10 17:02:59,770:INFO:Importing libraries
2023-08-10 17:02:59,771:INFO:Copying training dataset
2023-08-10 17:02:59,771:INFO:Checking base model
2023-08-10 17:02:59,772:INFO:Base model : Decision Tree Classifier
2023-08-10 17:02:59,773:INFO:Importing untrained ensembler
2023-08-10 17:02:59,774:INFO:Ensemble method set to Bagging
2023-08-10 17:02:59,774:INFO:SubProcess create_model() called ==================================
2023-08-10 17:02:59,779:INFO:Initializing create_model()
2023-08-10 17:02:59,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   random_state=6661,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3ED993460>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:02:59,780:INFO:Checking exceptions
2023-08-10 17:02:59,781:INFO:Importing libraries
2023-08-10 17:02:59,781:INFO:Copying training dataset
2023-08-10 17:02:59,797:INFO:Defining folds
2023-08-10 17:02:59,797:INFO:Declaring metric variables
2023-08-10 17:02:59,798:INFO:Importing untrained model
2023-08-10 17:02:59,798:INFO:Declaring custom model
2023-08-10 17:02:59,801:INFO:Bagging Classifier Imported successfully
2023-08-10 17:02:59,802:INFO:Starting cross validation
2023-08-10 17:02:59,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:03:44,333:INFO:Calculating mean and std
2023-08-10 17:03:44,334:INFO:Creating metrics dataframe
2023-08-10 17:03:44,340:INFO:Finalizing model
2023-08-10 17:03:48,104:INFO:Uploading results into container
2023-08-10 17:03:48,106:INFO:Uploading model into container now
2023-08-10 17:03:48,107:INFO:_master_model_container: 24
2023-08-10 17:03:48,107:INFO:_display_container: 15
2023-08-10 17:03:48,118:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:03:48,119:INFO:create_model() successfully completed......................................
2023-08-10 17:03:48,671:INFO:SubProcess create_model() end ==================================
2023-08-10 17:03:48,672:INFO:Creating Dashboard logs
2023-08-10 17:03:48,674:INFO:Model: Bagging Classifier
2023-08-10 17:03:49,515:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:03:54,831:INFO:Initializing predict_model()
2023-08-10 17:03:54,831:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2B66820>)
2023-08-10 17:03:54,834:INFO:Checking exceptions
2023-08-10 17:03:54,834:INFO:Preloading libraries
2023-08-10 17:03:58,128:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:03:58,138:INFO:Initializing plot_model()
2023-08-10 17:03:58,139:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpgpu7iv6u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:03:58,139:INFO:Checking exceptions
2023-08-10 17:03:58,146:INFO:Preloading libraries
2023-08-10 17:03:58,150:INFO:Copying training dataset
2023-08-10 17:03:58,150:INFO:Plot type: auc
2023-08-10 17:03:58,904:INFO:Fitting Model
2023-08-10 17:03:58,905:INFO:Scoring test/hold-out set
2023-08-10 17:03:58,991:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpgpu7iv6u\AUC.png'
2023-08-10 17:03:59,847:INFO:Visual Rendered Successfully
2023-08-10 17:04:00,304:INFO:plot_model() successfully completed......................................
2023-08-10 17:04:01,075:INFO:Initializing plot_model()
2023-08-10 17:04:01,076:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpgpu7iv6u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:04:01,076:INFO:Checking exceptions
2023-08-10 17:04:01,082:INFO:Preloading libraries
2023-08-10 17:04:01,086:INFO:Copying training dataset
2023-08-10 17:04:01,087:INFO:Plot type: confusion_matrix
2023-08-10 17:04:01,888:INFO:Fitting Model
2023-08-10 17:04:01,889:INFO:Scoring test/hold-out set
2023-08-10 17:04:01,972:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpgpu7iv6u\Confusion Matrix.png'
2023-08-10 17:04:02,409:INFO:Visual Rendered Successfully
2023-08-10 17:04:02,854:INFO:plot_model() successfully completed......................................
2023-08-10 17:04:09,360:INFO:Initializing plot_model()
2023-08-10 17:04:09,360:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpgpu7iv6u, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:04:09,361:INFO:Checking exceptions
2023-08-10 17:04:09,362:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:04:09,362:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:04:18,233:INFO:_master_model_container: 24
2023-08-10 17:04:18,234:INFO:_display_container: 15
2023-08-10 17:04:18,243:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:04:18,243:INFO:ensemble_model() successfully completed......................................
2023-08-10 17:04:18,684:INFO:Initializing tune_model()
2023-08-10 17:04:18,685:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec.	, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 17:04:18,685:INFO:Checking exceptions
2023-08-10 17:04:33,873:INFO:Initializing ensemble_model()
2023-08-10 17:04:33,873:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6661, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 17:04:33,873:INFO:Checking exceptions
2023-08-10 17:04:33,889:INFO:Importing libraries
2023-08-10 17:04:33,889:INFO:Copying training dataset
2023-08-10 17:04:33,890:INFO:Checking base model
2023-08-10 17:04:33,890:INFO:Base model : Decision Tree Classifier
2023-08-10 17:04:33,891:INFO:Importing untrained ensembler
2023-08-10 17:04:33,892:INFO:Ensemble method set to Bagging
2023-08-10 17:04:33,892:INFO:SubProcess create_model() called ==================================
2023-08-10 17:04:33,895:INFO:Initializing create_model()
2023-08-10 17:04:33,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   random_state=6661,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F151ED30>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:04:33,896:INFO:Checking exceptions
2023-08-10 17:04:33,896:INFO:Importing libraries
2023-08-10 17:04:33,896:INFO:Copying training dataset
2023-08-10 17:04:33,914:INFO:Defining folds
2023-08-10 17:04:33,914:INFO:Declaring metric variables
2023-08-10 17:04:33,915:INFO:Importing untrained model
2023-08-10 17:04:33,916:INFO:Declaring custom model
2023-08-10 17:04:33,919:INFO:Bagging Classifier Imported successfully
2023-08-10 17:04:33,920:INFO:Starting cross validation
2023-08-10 17:04:33,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:04:35,517:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:05:04,879:INFO:Calculating mean and std
2023-08-10 17:05:04,881:INFO:Creating metrics dataframe
2023-08-10 17:05:04,890:INFO:Finalizing model
2023-08-10 17:05:08,548:INFO:Uploading results into container
2023-08-10 17:05:08,550:INFO:Uploading model into container now
2023-08-10 17:05:08,552:INFO:_master_model_container: 25
2023-08-10 17:05:08,552:INFO:_display_container: 16
2023-08-10 17:05:08,563:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:05:08,564:INFO:create_model() successfully completed......................................
2023-08-10 17:05:12,181:INFO:SubProcess create_model() end ==================================
2023-08-10 17:05:12,182:INFO:Creating Dashboard logs
2023-08-10 17:05:12,184:INFO:Model: Bagging Classifier
2023-08-10 17:05:13,012:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:05:18,353:INFO:Initializing predict_model()
2023-08-10 17:05:18,353:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F3F51A60>)
2023-08-10 17:05:18,354:INFO:Checking exceptions
2023-08-10 17:05:18,355:INFO:Preloading libraries
2023-08-10 17:05:20,130:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:05:20,140:INFO:Initializing plot_model()
2023-08-10 17:05:20,140:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpz73dl80f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:05:20,140:INFO:Checking exceptions
2023-08-10 17:05:20,145:INFO:Preloading libraries
2023-08-10 17:05:20,148:INFO:Copying training dataset
2023-08-10 17:05:20,149:INFO:Plot type: auc
2023-08-10 17:05:21,069:INFO:Fitting Model
2023-08-10 17:05:21,073:INFO:Scoring test/hold-out set
2023-08-10 17:05:21,200:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpz73dl80f\AUC.png'
2023-08-10 17:05:22,195:INFO:Visual Rendered Successfully
2023-08-10 17:05:22,657:INFO:plot_model() successfully completed......................................
2023-08-10 17:05:23,468:INFO:Initializing plot_model()
2023-08-10 17:05:23,468:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpz73dl80f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:05:23,469:INFO:Checking exceptions
2023-08-10 17:05:23,478:INFO:Preloading libraries
2023-08-10 17:05:23,482:INFO:Copying training dataset
2023-08-10 17:05:23,482:INFO:Plot type: confusion_matrix
2023-08-10 17:05:25,049:INFO:Fitting Model
2023-08-10 17:05:25,050:INFO:Scoring test/hold-out set
2023-08-10 17:05:25,417:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpz73dl80f\Confusion Matrix.png'
2023-08-10 17:05:26,718:INFO:Visual Rendered Successfully
2023-08-10 17:05:27,397:INFO:plot_model() successfully completed......................................
2023-08-10 17:05:28,034:INFO:Initializing plot_model()
2023-08-10 17:05:28,035:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpz73dl80f, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:05:28,035:INFO:Checking exceptions
2023-08-10 17:05:28,036:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:05:28,037:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:05:39,360:INFO:_master_model_container: 25
2023-08-10 17:05:39,361:INFO:_display_container: 16
2023-08-10 17:05:39,395:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:05:39,395:INFO:ensemble_model() successfully completed......................................
2023-08-10 17:05:39,927:INFO:Initializing tune_model()
2023-08-10 17:05:39,927:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 17:05:39,928:INFO:Checking exceptions
2023-08-10 17:05:40,009:INFO:Copying training dataset
2023-08-10 17:05:40,028:INFO:Checking base model
2023-08-10 17:05:40,029:INFO:Base model : Bagging Classifier
2023-08-10 17:05:40,055:INFO:Declaring metric variables
2023-08-10 17:05:40,072:INFO:Defining Hyperparameters
2023-08-10 17:05:40,773:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 17:05:40,774:INFO:Tuning with n_jobs=-1
2023-08-10 17:05:40,774:INFO:Initializing RandomizedSearchCV
2023-08-10 17:05:58,312:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:05:58,362:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:06:46,230:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:06:47,921:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:06:52,026:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:07:02,826:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:07:05,962:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:17,078:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:07:21,125:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:24,856:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:28,093:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:31,173:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:32,407:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:07:34,809:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:38,594:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:41,622:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:42,761:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:07:45,028:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:46,267:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:07:48,212:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:49,519:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:07:51,925:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:07:53,141:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:12,890:INFO:best_params: {'actual_estimator__n_estimators': 150}
2023-08-10 17:08:12,892:INFO:Hyperparameter search completed
2023-08-10 17:08:12,894:INFO:SubProcess create_model() called ==================================
2023-08-10 17:08:12,915:INFO:Initializing create_model()
2023-08-10 17:08:12,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F12ECEB0>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150})
2023-08-10 17:08:12,915:INFO:Checking exceptions
2023-08-10 17:08:12,916:INFO:Importing libraries
2023-08-10 17:08:12,916:INFO:Copying training dataset
2023-08-10 17:08:12,935:INFO:Defining folds
2023-08-10 17:08:12,935:INFO:Declaring metric variables
2023-08-10 17:08:12,948:INFO:Importing untrained model
2023-08-10 17:08:12,949:INFO:Declaring custom model
2023-08-10 17:08:12,968:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:08:13,003:INFO:Starting cross validation
2023-08-10 17:08:13,079:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:08:15,459:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:15,507:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:15,609:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:15,783:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:17,789:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:17,807:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:17,892:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:18,249:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:27,821:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:27,975:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:28,180:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:29,787:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:30,721:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:30,982:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:31,446:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:39,347:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:41,149:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:41,402:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:08:53,952:INFO:Calculating mean and std
2023-08-10 17:08:53,956:INFO:Creating metrics dataframe
2023-08-10 17:08:53,983:INFO:Finalizing model
2023-08-10 17:08:57,882:INFO:Initializing predict_model()
2023-08-10 17:08:57,882:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=6661,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=150,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=6661,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2C7C700>)
2023-08-10 17:08:57,882:INFO:Checking exceptions
2023-08-10 17:08:57,883:INFO:Preloading libraries
2023-08-10 17:08:57,883:INFO:Set up data.
2023-08-10 17:08:57,903:INFO:Set up index.
2023-08-10 17:09:01,519:INFO:Uploading results into container
2023-08-10 17:09:01,521:INFO:Uploading model into container now
2023-08-10 17:09:01,529:INFO:_master_model_container: 26
2023-08-10 17:09:01,529:INFO:_display_container: 17
2023-08-10 17:09:01,553:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:09:01,556:INFO:create_model() successfully completed......................................
2023-08-10 17:09:02,036:INFO:SubProcess create_model() end ==================================
2023-08-10 17:09:02,036:INFO:choose_better activated
2023-08-10 17:09:02,048:INFO:SubProcess create_model() called ==================================
2023-08-10 17:09:02,057:INFO:Initializing create_model()
2023-08-10 17:09:02,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:09:02,058:INFO:Checking exceptions
2023-08-10 17:09:02,065:INFO:Importing libraries
2023-08-10 17:09:02,066:INFO:Copying training dataset
2023-08-10 17:09:02,084:INFO:Defining folds
2023-08-10 17:09:02,085:INFO:Declaring metric variables
2023-08-10 17:09:02,085:INFO:Importing untrained model
2023-08-10 17:09:02,086:INFO:Declaring custom model
2023-08-10 17:09:02,091:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:09:02,093:INFO:Starting cross validation
2023-08-10 17:09:02,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:09:29,897:INFO:Calculating mean and std
2023-08-10 17:09:29,898:INFO:Creating metrics dataframe
2023-08-10 17:09:29,904:INFO:Finalizing model
2023-08-10 17:09:33,341:INFO:Uploading results into container
2023-08-10 17:09:33,343:INFO:Uploading model into container now
2023-08-10 17:09:33,344:INFO:_master_model_container: 27
2023-08-10 17:09:33,345:INFO:_display_container: 18
2023-08-10 17:09:33,354:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:09:33,355:INFO:create_model() successfully completed......................................
2023-08-10 17:09:33,779:INFO:SubProcess create_model() end ==================================
2023-08-10 17:09:33,789:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.6366
2023-08-10 17:09:33,800:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.7035
2023-08-10 17:09:33,809:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) is best model
2023-08-10 17:09:33,810:INFO:choose_better completed
2023-08-10 17:09:33,811:INFO:Creating Dashboard logs
2023-08-10 17:09:33,821:INFO:Model: Bagging Classifier
2023-08-10 17:09:34,655:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:09:40,022:INFO:Initializing predict_model()
2023-08-10 17:09:40,022:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5B5E9D0>)
2023-08-10 17:09:40,023:INFO:Checking exceptions
2023-08-10 17:09:40,024:INFO:Preloading libraries
2023-08-10 17:09:41,646:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:09:41,654:INFO:Initializing plot_model()
2023-08-10 17:09:41,655:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp7o8cit6y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:09:41,655:INFO:Checking exceptions
2023-08-10 17:09:41,662:INFO:Preloading libraries
2023-08-10 17:09:41,711:INFO:Copying training dataset
2023-08-10 17:09:41,711:INFO:Plot type: auc
2023-08-10 17:09:42,430:INFO:Fitting Model
2023-08-10 17:09:42,432:INFO:Scoring test/hold-out set
2023-08-10 17:09:42,714:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp7o8cit6y\AUC.png'
2023-08-10 17:09:43,518:INFO:Visual Rendered Successfully
2023-08-10 17:09:43,935:INFO:plot_model() successfully completed......................................
2023-08-10 17:09:44,722:INFO:Initializing plot_model()
2023-08-10 17:09:44,722:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp7o8cit6y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:09:44,723:INFO:Checking exceptions
2023-08-10 17:09:44,732:INFO:Preloading libraries
2023-08-10 17:09:44,792:INFO:Copying training dataset
2023-08-10 17:09:44,793:INFO:Plot type: confusion_matrix
2023-08-10 17:09:45,512:INFO:Fitting Model
2023-08-10 17:09:45,513:INFO:Scoring test/hold-out set
2023-08-10 17:09:45,783:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp7o8cit6y\Confusion Matrix.png'
2023-08-10 17:09:46,182:INFO:Visual Rendered Successfully
2023-08-10 17:09:46,611:INFO:plot_model() successfully completed......................................
2023-08-10 17:09:47,169:INFO:Initializing plot_model()
2023-08-10 17:09:47,170:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp7o8cit6y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:09:47,170:INFO:Checking exceptions
2023-08-10 17:09:47,171:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:09:47,171:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:10:06,162:INFO:_master_model_container: 27
2023-08-10 17:10:06,163:INFO:_display_container: 17
2023-08-10 17:10:06,180:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:10:06,180:INFO:tune_model() successfully completed......................................
2023-08-10 17:11:52,794:INFO:Initializing ensemble_model()
2023-08-10 17:11:52,795:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 17:11:52,795:INFO:Checking exceptions
2023-08-10 17:11:52,809:INFO:Importing libraries
2023-08-10 17:11:52,809:INFO:Copying training dataset
2023-08-10 17:11:52,809:INFO:Checking base model
2023-08-10 17:11:52,809:INFO:Base model : Naive Bayes
2023-08-10 17:11:52,810:INFO:Importing untrained ensembler
2023-08-10 17:11:52,810:INFO:Ensemble method set to Bagging
2023-08-10 17:11:52,811:INFO:SubProcess create_model() called ==================================
2023-08-10 17:11:52,812:INFO:Initializing create_model()
2023-08-10 17:11:52,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GaussianNB(priors=None, var_smoothing=1e-09),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EAE09F40>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:11:52,813:INFO:Checking exceptions
2023-08-10 17:11:52,813:INFO:Importing libraries
2023-08-10 17:11:52,813:INFO:Copying training dataset
2023-08-10 17:11:52,832:INFO:Defining folds
2023-08-10 17:11:52,832:INFO:Declaring metric variables
2023-08-10 17:11:52,833:INFO:Importing untrained model
2023-08-10 17:11:52,833:INFO:Declaring custom model
2023-08-10 17:11:52,836:INFO:Bagging Classifier Imported successfully
2023-08-10 17:11:52,837:INFO:Starting cross validation
2023-08-10 17:11:52,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:12:23,579:INFO:Calculating mean and std
2023-08-10 17:12:23,580:INFO:Creating metrics dataframe
2023-08-10 17:12:23,589:INFO:Finalizing model
2023-08-10 17:12:27,363:INFO:Uploading results into container
2023-08-10 17:12:27,366:INFO:Uploading model into container now
2023-08-10 17:12:27,367:INFO:_master_model_container: 28
2023-08-10 17:12:27,368:INFO:_display_container: 18
2023-08-10 17:12:27,372:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:12:27,373:INFO:create_model() successfully completed......................................
2023-08-10 17:12:27,826:INFO:SubProcess create_model() end ==================================
2023-08-10 17:12:27,828:INFO:Creating Dashboard logs
2023-08-10 17:12:27,829:INFO:Model: Bagging Classifier
2023-08-10 17:12:28,621:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__priors': None, 'estimator__var_smoothing': 1e-09, 'estimator': GaussianNB(priors=None, var_smoothing=1e-09), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:12:33,879:INFO:Initializing predict_model()
2023-08-10 17:12:33,879:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F4715B80>)
2023-08-10 17:12:33,879:INFO:Checking exceptions
2023-08-10 17:12:33,880:INFO:Preloading libraries
2023-08-10 17:12:35,307:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:12:35,311:INFO:Initializing plot_model()
2023-08-10 17:12:35,311:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp2nz40bz3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:12:35,311:INFO:Checking exceptions
2023-08-10 17:12:35,318:INFO:Preloading libraries
2023-08-10 17:12:35,321:INFO:Copying training dataset
2023-08-10 17:12:35,321:INFO:Plot type: auc
2023-08-10 17:12:36,068:INFO:Fitting Model
2023-08-10 17:12:36,069:INFO:Scoring test/hold-out set
2023-08-10 17:12:36,178:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp2nz40bz3\AUC.png'
2023-08-10 17:12:37,025:INFO:Visual Rendered Successfully
2023-08-10 17:12:37,473:INFO:plot_model() successfully completed......................................
2023-08-10 17:12:38,228:INFO:Initializing plot_model()
2023-08-10 17:12:38,228:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp2nz40bz3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:12:38,229:INFO:Checking exceptions
2023-08-10 17:12:38,238:INFO:Preloading libraries
2023-08-10 17:12:38,240:INFO:Copying training dataset
2023-08-10 17:12:38,240:INFO:Plot type: confusion_matrix
2023-08-10 17:12:38,973:INFO:Fitting Model
2023-08-10 17:12:38,974:INFO:Scoring test/hold-out set
2023-08-10 17:12:39,068:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp2nz40bz3\Confusion Matrix.png'
2023-08-10 17:12:39,486:INFO:Visual Rendered Successfully
2023-08-10 17:12:39,925:INFO:plot_model() successfully completed......................................
2023-08-10 17:12:40,529:INFO:Initializing plot_model()
2023-08-10 17:12:40,529:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp2nz40bz3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:12:40,530:INFO:Checking exceptions
2023-08-10 17:12:40,532:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:12:40,532:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:12:50,494:INFO:_master_model_container: 28
2023-08-10 17:12:50,494:INFO:_display_container: 18
2023-08-10 17:12:50,499:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:12:50,500:INFO:ensemble_model() successfully completed......................................
2023-08-10 17:12:50,936:INFO:Initializing tune_model()
2023-08-10 17:12:50,936:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 17:12:50,936:INFO:Checking exceptions
2023-08-10 17:12:51,003:INFO:Copying training dataset
2023-08-10 17:12:51,016:INFO:Checking base model
2023-08-10 17:12:51,016:INFO:Base model : Bagging Classifier
2023-08-10 17:12:51,031:INFO:Declaring metric variables
2023-08-10 17:12:51,042:INFO:Defining Hyperparameters
2023-08-10 17:12:51,970:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 17:12:51,970:INFO:Tuning with n_jobs=-1
2023-08-10 17:12:51,970:INFO:Initializing RandomizedSearchCV
2023-08-10 17:14:29,190:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:14:32,126:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:14:46,061:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:14:47,195:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:14:50,366:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:15:17,068:INFO:best_params: {'actual_estimator__n_estimators': 100}
2023-08-10 17:15:17,075:INFO:Hyperparameter search completed
2023-08-10 17:15:17,075:INFO:SubProcess create_model() called ==================================
2023-08-10 17:15:17,082:INFO:Initializing create_model()
2023-08-10 17:15:17,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDEC6790>, model_only=True, return_train_score=True, kwargs={'n_estimators': 100})
2023-08-10 17:15:17,084:INFO:Checking exceptions
2023-08-10 17:15:17,084:INFO:Importing libraries
2023-08-10 17:15:17,084:INFO:Copying training dataset
2023-08-10 17:15:17,102:INFO:Defining folds
2023-08-10 17:15:17,103:INFO:Declaring metric variables
2023-08-10 17:15:17,115:INFO:Importing untrained model
2023-08-10 17:15:17,116:INFO:Declaring custom model
2023-08-10 17:15:17,131:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:15:17,162:INFO:Starting cross validation
2023-08-10 17:15:17,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:15:19,014:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:19,057:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:19,066:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:19,282:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:21,036:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:30,216:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:30,276:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:30,765:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:31,302:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:33,344:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:33,620:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:34,260:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:34,724:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:15:59,571:INFO:Calculating mean and std
2023-08-10 17:15:59,577:INFO:Creating metrics dataframe
2023-08-10 17:15:59,614:INFO:Finalizing model
2023-08-10 17:16:01,757:INFO:Initializing predict_model()
2023-08-10 17:16:01,757:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                                        var_smoothing=1e-09),
                                                                                   max_features=1.0,
                                                                                   max_samples=1.0,
                                                                                   n_estimators=100,
                                                                                   n_jobs=None,
                                                                                   oob_score=False,
                                                                                   random_state=6661,
                                                                                   verbose=0,
                                                                                   warm_start=False),
                                                      estimator=GaussianNB(priors=None,
                                                                           var_smoothing=1e-09),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=6661,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F4824790>)
2023-08-10 17:16:01,758:INFO:Checking exceptions
2023-08-10 17:16:01,758:INFO:Preloading libraries
2023-08-10 17:16:01,759:INFO:Set up data.
2023-08-10 17:16:01,782:INFO:Set up index.
2023-08-10 17:16:07,148:INFO:Uploading results into container
2023-08-10 17:16:07,155:INFO:Uploading model into container now
2023-08-10 17:16:07,157:INFO:_master_model_container: 29
2023-08-10 17:16:07,157:INFO:_display_container: 19
2023-08-10 17:16:07,164:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:16:07,165:INFO:create_model() successfully completed......................................
2023-08-10 17:16:07,631:INFO:SubProcess create_model() end ==================================
2023-08-10 17:16:07,631:INFO:choose_better activated
2023-08-10 17:16:07,644:INFO:SubProcess create_model() called ==================================
2023-08-10 17:16:07,648:INFO:Initializing create_model()
2023-08-10 17:16:07,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:16:07,649:INFO:Checking exceptions
2023-08-10 17:16:07,657:INFO:Importing libraries
2023-08-10 17:16:07,657:INFO:Copying training dataset
2023-08-10 17:16:07,672:INFO:Defining folds
2023-08-10 17:16:07,672:INFO:Declaring metric variables
2023-08-10 17:16:07,673:INFO:Importing untrained model
2023-08-10 17:16:07,673:INFO:Declaring custom model
2023-08-10 17:16:07,677:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:16:07,678:INFO:Starting cross validation
2023-08-10 17:16:07,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:16:38,146:INFO:Calculating mean and std
2023-08-10 17:16:38,148:INFO:Creating metrics dataframe
2023-08-10 17:16:38,156:INFO:Finalizing model
2023-08-10 17:16:41,842:INFO:Uploading results into container
2023-08-10 17:16:41,844:INFO:Uploading model into container now
2023-08-10 17:16:41,845:INFO:_master_model_container: 30
2023-08-10 17:16:41,846:INFO:_display_container: 20
2023-08-10 17:16:41,852:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:16:41,853:INFO:create_model() successfully completed......................................
2023-08-10 17:16:42,296:INFO:SubProcess create_model() end ==================================
2023-08-10 17:16:42,301:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.3139
2023-08-10 17:16:42,307:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.319
2023-08-10 17:16:42,311:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) is best model
2023-08-10 17:16:42,312:INFO:choose_better completed
2023-08-10 17:16:42,313:INFO:Creating Dashboard logs
2023-08-10 17:16:42,325:INFO:Model: Bagging Classifier
2023-08-10 17:16:43,248:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__priors': None, 'estimator__var_smoothing': 1e-09, 'estimator': GaussianNB(priors=None, var_smoothing=1e-09), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:16:48,739:INFO:Initializing predict_model()
2023-08-10 17:16:48,739:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F2B66550>)
2023-08-10 17:16:48,739:INFO:Checking exceptions
2023-08-10 17:16:48,739:INFO:Preloading libraries
2023-08-10 17:16:50,438:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:16:50,445:INFO:Initializing plot_model()
2023-08-10 17:16:50,445:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpfrs6x47z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:16:50,446:INFO:Checking exceptions
2023-08-10 17:16:50,454:INFO:Preloading libraries
2023-08-10 17:16:50,472:INFO:Copying training dataset
2023-08-10 17:16:50,472:INFO:Plot type: auc
2023-08-10 17:16:51,235:INFO:Fitting Model
2023-08-10 17:16:51,237:INFO:Scoring test/hold-out set
2023-08-10 17:16:51,598:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpfrs6x47z\AUC.png'
2023-08-10 17:16:52,454:INFO:Visual Rendered Successfully
2023-08-10 17:16:52,905:INFO:plot_model() successfully completed......................................
2023-08-10 17:16:54,814:INFO:Initializing plot_model()
2023-08-10 17:16:54,814:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpfrs6x47z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:16:54,815:INFO:Checking exceptions
2023-08-10 17:16:54,821:INFO:Preloading libraries
2023-08-10 17:16:54,831:INFO:Copying training dataset
2023-08-10 17:16:54,831:INFO:Plot type: confusion_matrix
2023-08-10 17:16:55,599:INFO:Fitting Model
2023-08-10 17:16:55,602:INFO:Scoring test/hold-out set
2023-08-10 17:16:55,952:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpfrs6x47z\Confusion Matrix.png'
2023-08-10 17:16:56,375:INFO:Visual Rendered Successfully
2023-08-10 17:16:56,846:INFO:plot_model() successfully completed......................................
2023-08-10 17:16:57,441:INFO:Initializing plot_model()
2023-08-10 17:16:57,441:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpfrs6x47z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:16:57,441:INFO:Checking exceptions
2023-08-10 17:16:57,442:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:16:57,442:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:17:14,044:INFO:_master_model_container: 30
2023-08-10 17:17:14,045:INFO:_display_container: 19
2023-08-10 17:17:14,054:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:17:14,057:INFO:tune_model() successfully completed......................................
2023-08-10 17:23:40,685:INFO:Initializing tune_model()
2023-08-10 17:23:40,685:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=F2, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 17:23:40,686:INFO:Checking exceptions
2023-08-10 17:23:40,758:INFO:Copying training dataset
2023-08-10 17:23:40,771:INFO:Checking base model
2023-08-10 17:23:40,771:INFO:Base model : Extreme Gradient Boosting
2023-08-10 17:23:40,787:INFO:Declaring metric variables
2023-08-10 17:23:40,801:INFO:Defining Hyperparameters
2023-08-10 17:23:41,439:INFO:Tuning with n_jobs=-1
2023-08-10 17:23:41,439:INFO:Initializing RandomizedSearchCV
2023-08-10 17:26:50,057:INFO:best_params: {'actual_estimator__subsample': 0.3, 'actual_estimator__scale_pos_weight': 33.1, 'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__n_estimators': 290, 'actual_estimator__min_child_weight': 4, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__colsample_bytree': 0.5}
2023-08-10 17:26:50,061:INFO:Hyperparameter search completed
2023-08-10 17:26:50,062:INFO:SubProcess create_model() called ==================================
2023-08-10 17:26:50,065:INFO:Initializing create_model()
2023-08-10 17:26:50,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3ED944280>, model_only=True, return_train_score=False, kwargs={'subsample': 0.3, 'scale_pos_weight': 33.1, 'reg_lambda': 1e-06, 'reg_alpha': 0.005, 'n_estimators': 290, 'min_child_weight': 4, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5})
2023-08-10 17:26:50,067:INFO:Checking exceptions
2023-08-10 17:26:50,068:INFO:Importing libraries
2023-08-10 17:26:50,068:INFO:Copying training dataset
2023-08-10 17:26:50,096:INFO:Defining folds
2023-08-10 17:26:50,096:INFO:Declaring metric variables
2023-08-10 17:26:50,111:INFO:Importing untrained model
2023-08-10 17:26:50,111:INFO:Declaring custom model
2023-08-10 17:26:50,132:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 17:26:50,164:INFO:Starting cross validation
2023-08-10 17:26:50,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:27:24,366:INFO:Calculating mean and std
2023-08-10 17:27:24,373:INFO:Creating metrics dataframe
2023-08-10 17:27:24,407:INFO:Finalizing model
2023-08-10 17:27:29,488:INFO:Uploading results into container
2023-08-10 17:27:29,496:INFO:Uploading model into container now
2023-08-10 17:27:29,497:INFO:_master_model_container: 31
2023-08-10 17:27:29,498:INFO:_display_container: 20
2023-08-10 17:27:29,503:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 17:27:29,503:INFO:create_model() successfully completed......................................
2023-08-10 17:27:30,003:INFO:SubProcess create_model() end ==================================
2023-08-10 17:27:30,004:INFO:choose_better activated
2023-08-10 17:27:30,014:INFO:SubProcess create_model() called ==================================
2023-08-10 17:27:30,016:INFO:Initializing create_model()
2023-08-10 17:27:30,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:27:30,020:INFO:Checking exceptions
2023-08-10 17:27:30,025:INFO:Importing libraries
2023-08-10 17:27:30,026:INFO:Copying training dataset
2023-08-10 17:27:30,040:INFO:Defining folds
2023-08-10 17:27:30,041:INFO:Declaring metric variables
2023-08-10 17:27:30,041:INFO:Importing untrained model
2023-08-10 17:27:30,041:INFO:Declaring custom model
2023-08-10 17:27:30,046:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 17:27:30,047:INFO:Starting cross validation
2023-08-10 17:27:30,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:28:05,801:INFO:Calculating mean and std
2023-08-10 17:28:05,803:INFO:Creating metrics dataframe
2023-08-10 17:28:05,808:INFO:Finalizing model
2023-08-10 17:28:09,589:INFO:Uploading results into container
2023-08-10 17:28:09,591:INFO:Uploading model into container now
2023-08-10 17:28:09,592:INFO:_master_model_container: 32
2023-08-10 17:28:09,593:INFO:_display_container: 21
2023-08-10 17:28:09,595:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 17:28:09,595:INFO:create_model() successfully completed......................................
2023-08-10 17:28:10,056:INFO:SubProcess create_model() end ==================================
2023-08-10 17:28:10,058:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for F2 is 0.6473
2023-08-10 17:28:10,061:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for F2 is 0.7205
2023-08-10 17:28:10,063:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) is best model
2023-08-10 17:28:10,063:INFO:choose_better completed
2023-08-10 17:28:10,064:INFO:Creating Dashboard logs
2023-08-10 17:28:10,078:INFO:Model: Extreme Gradient Boosting
2023-08-10 17:28:11,104:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': 4, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 290, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 6661, 'reg_alpha': 0.005, 'reg_lambda': 1e-06, 'sampling_method': None, 'scale_pos_weight': 33.1, 'subsample': 0.3, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-08-10 17:28:16,718:INFO:Initializing predict_model()
2023-08-10 17:28:16,718:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C69310>)
2023-08-10 17:28:16,718:INFO:Checking exceptions
2023-08-10 17:28:16,718:INFO:Preloading libraries
2023-08-10 17:28:23,810:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:28:23,815:INFO:Initializing plot_model()
2023-08-10 17:28:23,815:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpj733agkj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:28:23,816:INFO:Checking exceptions
2023-08-10 17:28:23,826:INFO:Preloading libraries
2023-08-10 17:28:23,867:INFO:Copying training dataset
2023-08-10 17:28:23,867:INFO:Plot type: auc
2023-08-10 17:28:24,619:INFO:Fitting Model
2023-08-10 17:28:24,624:INFO:Scoring test/hold-out set
2023-08-10 17:28:24,706:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpj733agkj\AUC.png'
2023-08-10 17:28:25,577:INFO:Visual Rendered Successfully
2023-08-10 17:28:26,036:INFO:plot_model() successfully completed......................................
2023-08-10 17:28:26,911:INFO:Initializing plot_model()
2023-08-10 17:28:26,911:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpj733agkj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:28:26,911:INFO:Checking exceptions
2023-08-10 17:28:26,922:INFO:Preloading libraries
2023-08-10 17:28:26,955:INFO:Copying training dataset
2023-08-10 17:28:26,955:INFO:Plot type: confusion_matrix
2023-08-10 17:28:27,698:INFO:Fitting Model
2023-08-10 17:28:27,702:INFO:Scoring test/hold-out set
2023-08-10 17:28:27,773:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpj733agkj\Confusion Matrix.png'
2023-08-10 17:28:28,193:INFO:Visual Rendered Successfully
2023-08-10 17:28:28,640:INFO:plot_model() successfully completed......................................
2023-08-10 17:28:30,367:INFO:Initializing plot_model()
2023-08-10 17:28:30,367:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpj733agkj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:28:30,368:INFO:Checking exceptions
2023-08-10 17:28:30,375:INFO:Preloading libraries
2023-08-10 17:28:30,404:INFO:Copying training dataset
2023-08-10 17:28:30,405:INFO:Plot type: feature
2023-08-10 17:28:30,407:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 17:28:30,686:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpj733agkj\Feature Importance.png'
2023-08-10 17:28:31,311:INFO:Visual Rendered Successfully
2023-08-10 17:28:31,757:INFO:plot_model() successfully completed......................................
2023-08-10 17:28:32,611:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:28:54,095:INFO:_master_model_container: 32
2023-08-10 17:28:54,096:INFO:_display_container: 20
2023-08-10 17:28:54,102:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=4, missing=nan, monotone_constraints=None,
              n_estimators=290, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 17:28:54,103:INFO:tune_model() successfully completed......................................
2023-08-10 17:31:39,922:INFO:Initializing ensemble_model()
2023-08-10 17:31:39,924:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 17:31:39,925:INFO:Checking exceptions
2023-08-10 17:31:39,940:INFO:Importing libraries
2023-08-10 17:31:39,940:INFO:Copying training dataset
2023-08-10 17:31:39,941:INFO:Checking base model
2023-08-10 17:31:39,941:INFO:Base model : Extreme Gradient Boosting
2023-08-10 17:31:39,942:INFO:Importing untrained ensembler
2023-08-10 17:31:39,942:INFO:Ensemble method set to Bagging
2023-08-10 17:31:39,942:INFO:SubProcess create_model() called ==================================
2023-08-10 17:31:39,951:INFO:Initializing create_model()
2023-08-10 17:31:39,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=XGBClassifier(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None,
                                          early_stopping_rounds=None,
                                          enable_categorical=False,
                                          eval_metric=None, feature_types=None,
                                          gamma=None, gpu_id=None,
                                          grow_policy=No...
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          n_estimators=100, n_jobs=-1,
                                          num_parallel_tree=None,
                                          objective='binary:logistic',
                                          predictor=None, ...),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F44510A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:31:39,952:INFO:Checking exceptions
2023-08-10 17:31:39,952:INFO:Importing libraries
2023-08-10 17:31:39,953:INFO:Copying training dataset
2023-08-10 17:31:39,968:INFO:Defining folds
2023-08-10 17:31:39,968:INFO:Declaring metric variables
2023-08-10 17:31:39,969:INFO:Importing untrained model
2023-08-10 17:31:39,969:INFO:Declaring custom model
2023-08-10 17:31:39,975:INFO:Bagging Classifier Imported successfully
2023-08-10 17:31:39,976:INFO:Starting cross validation
2023-08-10 17:31:40,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:31:49,324:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:32:22,599:INFO:Calculating mean and std
2023-08-10 17:32:22,602:INFO:Creating metrics dataframe
2023-08-10 17:32:22,610:INFO:Finalizing model
2023-08-10 17:32:30,291:INFO:Uploading results into container
2023-08-10 17:32:30,293:INFO:Uploading model into container now
2023-08-10 17:32:30,294:INFO:_master_model_container: 33
2023-08-10 17:32:30,294:INFO:_display_container: 21
2023-08-10 17:32:30,316:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:32:30,317:INFO:create_model() successfully completed......................................
2023-08-10 17:32:30,771:INFO:SubProcess create_model() end ==================================
2023-08-10 17:32:30,772:INFO:Creating Dashboard logs
2023-08-10 17:32:30,774:INFO:Model: Bagging Classifier
2023-08-10 17:32:31,626:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 6661, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:32:36,806:INFO:Initializing predict_model()
2023-08-10 17:32:36,807:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C97EE0>)
2023-08-10 17:32:36,807:INFO:Checking exceptions
2023-08-10 17:32:36,807:INFO:Preloading libraries
2023-08-10 17:32:40,738:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:32:40,766:INFO:Initializing plot_model()
2023-08-10 17:32:40,766:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpetuojcsc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:32:40,767:INFO:Checking exceptions
2023-08-10 17:32:40,773:INFO:Preloading libraries
2023-08-10 17:32:40,902:INFO:Copying training dataset
2023-08-10 17:32:40,902:INFO:Plot type: auc
2023-08-10 17:32:41,620:INFO:Fitting Model
2023-08-10 17:32:41,621:INFO:Scoring test/hold-out set
2023-08-10 17:32:41,782:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpetuojcsc\AUC.png'
2023-08-10 17:32:42,600:INFO:Visual Rendered Successfully
2023-08-10 17:32:43,032:INFO:plot_model() successfully completed......................................
2023-08-10 17:32:43,710:INFO:Initializing plot_model()
2023-08-10 17:32:43,710:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpetuojcsc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:32:43,710:INFO:Checking exceptions
2023-08-10 17:32:43,719:INFO:Preloading libraries
2023-08-10 17:32:43,845:INFO:Copying training dataset
2023-08-10 17:32:43,846:INFO:Plot type: confusion_matrix
2023-08-10 17:32:44,564:INFO:Fitting Model
2023-08-10 17:32:44,565:INFO:Scoring test/hold-out set
2023-08-10 17:32:44,722:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpetuojcsc\Confusion Matrix.png'
2023-08-10 17:32:45,115:INFO:Visual Rendered Successfully
2023-08-10 17:32:45,532:INFO:plot_model() successfully completed......................................
2023-08-10 17:32:46,109:INFO:Initializing plot_model()
2023-08-10 17:32:46,110:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpetuojcsc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:32:46,110:INFO:Checking exceptions
2023-08-10 17:32:46,111:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:32:46,111:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:32:58,344:INFO:_master_model_container: 33
2023-08-10 17:32:58,344:INFO:_display_container: 21
2023-08-10 17:32:58,369:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:32:58,370:INFO:ensemble_model() successfully completed......................................
2023-08-10 17:32:58,912:INFO:Initializing tune_model()
2023-08-10 17:32:58,913:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 17:32:58,913:INFO:Checking exceptions
2023-08-10 17:32:58,985:INFO:Copying training dataset
2023-08-10 17:32:59,002:INFO:Checking base model
2023-08-10 17:32:59,003:INFO:Base model : Bagging Classifier
2023-08-10 17:32:59,023:INFO:Declaring metric variables
2023-08-10 17:32:59,039:INFO:Defining Hyperparameters
2023-08-10 17:32:59,902:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 17:32:59,902:INFO:Tuning with n_jobs=-1
2023-08-10 17:32:59,902:INFO:Initializing RandomizedSearchCV
2023-08-10 17:33:02,077:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:33:02,096:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:33:02,229:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:33:02,370:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:33:09,744:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:33:57,506:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:33:58,977:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:34:01,538:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:34:06,105:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:34:08,764:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:34:10,663:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:34:12,654:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:34:37,732:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:34:41,297:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:34:43,276:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:34:46,408:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:34:48,370:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:34:50,491:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:34:52,444:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:35:17,264:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:35:18,755:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:35:22,298:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:35:24,287:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:35:56,947:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:35:59,693:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:35:59,846:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:36:03,361:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:36:27,458:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:36:30,161:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:36:31,577:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:36:35,153:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:37:10,894:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:37:14,618:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:37:45,307:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:37:48,677:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:37:50,373:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:37:54,607:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:38:29,363:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:38:32,404:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:38:33,470:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:38:37,188:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:39:34,001:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:39:37,372:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:40:15,390:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:40:18,201:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:40:19,478:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:40:23,014:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:41:21,182:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:41:27,098:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:42:09,741:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:42:13,299:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:42:13,699:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:42:18,157:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:03,077:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:43:06,973:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:43:10,827:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:15,875:INFO:best_params: {'actual_estimator__n_estimators': 150}
2023-08-10 17:43:15,878:INFO:Hyperparameter search completed
2023-08-10 17:43:15,878:INFO:SubProcess create_model() called ==================================
2023-08-10 17:43:15,904:INFO:Initializing create_model()
2023-08-10 17:43:15,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3EDDC29D0>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150})
2023-08-10 17:43:15,906:INFO:Checking exceptions
2023-08-10 17:43:15,907:INFO:Importing libraries
2023-08-10 17:43:15,908:INFO:Copying training dataset
2023-08-10 17:43:15,935:INFO:Defining folds
2023-08-10 17:43:15,936:INFO:Declaring metric variables
2023-08-10 17:43:15,948:INFO:Importing untrained model
2023-08-10 17:43:15,948:INFO:Declaring custom model
2023-08-10 17:43:15,975:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:43:16,003:INFO:Starting cross validation
2023-08-10 17:43:16,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:43:22,698:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:22,912:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:22,913:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:27,958:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:29,848:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:30,132:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:30,197:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:52,742:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:52,771:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:56,147:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:43:58,513:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:44:00,953:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:44:01,055:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:44:18,455:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:44:20,811:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:44:25,673:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:44:27,891:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:44:39,117:INFO:Calculating mean and std
2023-08-10 17:44:39,124:INFO:Creating metrics dataframe
2023-08-10 17:44:39,178:INFO:Finalizing model
2023-08-10 17:45:32,469:INFO:Initializing predict_model()
2023-08-10 17:45:32,469:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                              max_depth=None,
                                                                              max_leaves=None,
                                                                              min_child_weight=None,
                                                                              missing=nan,
                                                                              monotone_constraints=None,
                                                                              n_estimators=100,
                                                                              n_jobs=-1,
                                                                              num_parallel_tree=None,
                                                                              objective='binary:logistic',
                                                                              predictor=None, ...),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=150,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=6661,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C979D0>)
2023-08-10 17:45:32,469:INFO:Checking exceptions
2023-08-10 17:45:32,470:INFO:Preloading libraries
2023-08-10 17:45:32,470:INFO:Set up data.
2023-08-10 17:45:32,496:INFO:Set up index.
2023-08-10 17:45:38,319:INFO:Uploading results into container
2023-08-10 17:45:38,322:INFO:Uploading model into container now
2023-08-10 17:45:38,325:INFO:_master_model_container: 34
2023-08-10 17:45:38,330:INFO:_display_container: 22
2023-08-10 17:45:38,358:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:45:38,358:INFO:create_model() successfully completed......................................
2023-08-10 17:45:38,836:INFO:SubProcess create_model() end ==================================
2023-08-10 17:45:38,837:INFO:choose_better activated
2023-08-10 17:45:38,849:INFO:SubProcess create_model() called ==================================
2023-08-10 17:45:38,871:INFO:Initializing create_model()
2023-08-10 17:45:38,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:45:38,872:INFO:Checking exceptions
2023-08-10 17:45:38,881:INFO:Importing libraries
2023-08-10 17:45:38,881:INFO:Copying training dataset
2023-08-10 17:45:38,896:INFO:Defining folds
2023-08-10 17:45:38,897:INFO:Declaring metric variables
2023-08-10 17:45:38,897:INFO:Importing untrained model
2023-08-10 17:45:38,897:INFO:Declaring custom model
2023-08-10 17:45:38,908:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:45:38,911:INFO:Starting cross validation
2023-08-10 17:45:38,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:45:40,891:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:46:14,288:INFO:Calculating mean and std
2023-08-10 17:46:14,290:INFO:Creating metrics dataframe
2023-08-10 17:46:14,299:INFO:Finalizing model
2023-08-10 17:46:18,625:INFO:Uploading results into container
2023-08-10 17:46:18,628:INFO:Uploading model into container now
2023-08-10 17:46:18,629:INFO:_master_model_container: 35
2023-08-10 17:46:18,629:INFO:_display_container: 23
2023-08-10 17:46:18,654:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:46:18,654:INFO:create_model() successfully completed......................................
2023-08-10 17:46:19,119:INFO:SubProcess create_model() end ==================================
2023-08-10 17:46:19,145:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.7657
2023-08-10 17:46:19,169:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) result for Prec. is 0.7751
2023-08-10 17:46:19,197:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False) is best model
2023-08-10 17:46:19,197:INFO:choose_better completed
2023-08-10 17:46:19,198:INFO:Creating Dashboard logs
2023-08-10 17:46:19,213:INFO:Model: Bagging Classifier
2023-08-10 17:46:20,369:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 6661, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:46:25,636:INFO:Initializing predict_model()
2023-08-10 17:46:25,636:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F5C979D0>)
2023-08-10 17:46:25,636:INFO:Checking exceptions
2023-08-10 17:46:25,636:INFO:Preloading libraries
2023-08-10 17:46:28,609:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:46:28,643:INFO:Initializing plot_model()
2023-08-10 17:46:28,643:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmprkzcn7ov, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:46:28,643:INFO:Checking exceptions
2023-08-10 17:46:28,648:INFO:Preloading libraries
2023-08-10 17:46:30,663:INFO:Copying training dataset
2023-08-10 17:46:30,663:INFO:Plot type: auc
2023-08-10 17:46:31,405:INFO:Fitting Model
2023-08-10 17:46:31,408:INFO:Scoring test/hold-out set
2023-08-10 17:46:32,877:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmprkzcn7ov\AUC.png'
2023-08-10 17:46:33,727:INFO:Visual Rendered Successfully
2023-08-10 17:46:34,164:INFO:plot_model() successfully completed......................................
2023-08-10 17:46:34,984:INFO:Initializing plot_model()
2023-08-10 17:46:34,984:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmprkzcn7ov, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:46:34,984:INFO:Checking exceptions
2023-08-10 17:46:34,993:INFO:Preloading libraries
2023-08-10 17:46:37,095:INFO:Copying training dataset
2023-08-10 17:46:37,096:INFO:Plot type: confusion_matrix
2023-08-10 17:46:37,843:INFO:Fitting Model
2023-08-10 17:46:37,844:INFO:Scoring test/hold-out set
2023-08-10 17:46:39,351:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmprkzcn7ov\Confusion Matrix.png'
2023-08-10 17:46:39,770:INFO:Visual Rendered Successfully
2023-08-10 17:46:40,215:INFO:plot_model() successfully completed......................................
2023-08-10 17:46:42,431:INFO:Initializing plot_model()
2023-08-10 17:46:42,432:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmprkzcn7ov, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:46:42,432:INFO:Checking exceptions
2023-08-10 17:46:42,432:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:46:42,433:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:47:47,251:INFO:_master_model_container: 35
2023-08-10 17:47:47,252:INFO:_display_container: 22
2023-08-10 17:47:47,279:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:47:47,279:INFO:tune_model() successfully completed......................................
2023-08-10 17:49:00,810:INFO:Initializing compare_models()
2023-08-10 17:49:00,811:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, include=[CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, 'include': [CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 17:49:00,811:INFO:Checking exceptions
2023-08-10 17:49:00,819:INFO:Preparing display monitor
2023-08-10 17:49:00,917:INFO:Initializing custom model Bagging Classifier
2023-08-10 17:49:00,918:INFO:Total runtime is 3.331104914347331e-05 minutes
2023-08-10 17:49:00,933:INFO:SubProcess create_model() called ==================================
2023-08-10 17:49:00,946:INFO:Initializing create_model()
2023-08-10 17:49:00,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F2845130>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:49:00,949:INFO:Checking exceptions
2023-08-10 17:49:00,950:INFO:Importing libraries
2023-08-10 17:49:00,951:INFO:Copying training dataset
2023-08-10 17:49:00,969:INFO:Defining folds
2023-08-10 17:49:00,969:INFO:Declaring metric variables
2023-08-10 17:49:00,985:INFO:Importing untrained model
2023-08-10 17:49:00,985:INFO:Declaring custom model
2023-08-10 17:49:01,007:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:49:01,043:INFO:Starting cross validation
2023-08-10 17:49:01,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:49:12,958:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:49:20,156:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:49:39,666:INFO:Calculating mean and std
2023-08-10 17:49:39,669:INFO:Creating metrics dataframe
2023-08-10 17:49:43,531:INFO:Uploading results into container
2023-08-10 17:49:43,534:INFO:Uploading model into container now
2023-08-10 17:49:43,535:INFO:_master_model_container: 36
2023-08-10 17:49:43,535:INFO:_display_container: 23
2023-08-10 17:49:43,547:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:49:43,548:INFO:create_model() successfully completed......................................
2023-08-10 17:49:44,015:INFO:SubProcess create_model() end ==================================
2023-08-10 17:49:44,016:INFO:Creating metrics dataframe
2023-08-10 17:49:44,060:INFO:Initializing custom model Bagging Classifier
2023-08-10 17:49:44,061:INFO:Total runtime is 0.7190832734107971 minutes
2023-08-10 17:49:44,079:INFO:SubProcess create_model() called ==================================
2023-08-10 17:49:44,087:INFO:Initializing create_model()
2023-08-10 17:49:44,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F2845130>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:49:44,088:INFO:Checking exceptions
2023-08-10 17:49:44,088:INFO:Importing libraries
2023-08-10 17:49:44,090:INFO:Copying training dataset
2023-08-10 17:49:44,112:INFO:Defining folds
2023-08-10 17:49:44,114:INFO:Declaring metric variables
2023-08-10 17:49:44,139:INFO:Importing untrained model
2023-08-10 17:49:44,139:INFO:Declaring custom model
2023-08-10 17:49:44,172:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:49:44,212:INFO:Starting cross validation
2023-08-10 17:49:44,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:50:18,756:INFO:Calculating mean and std
2023-08-10 17:50:18,759:INFO:Creating metrics dataframe
2023-08-10 17:50:22,322:INFO:Uploading results into container
2023-08-10 17:50:22,325:INFO:Uploading model into container now
2023-08-10 17:50:22,326:INFO:_master_model_container: 37
2023-08-10 17:50:22,326:INFO:_display_container: 23
2023-08-10 17:50:22,332:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=100,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=6661,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:50:22,332:INFO:create_model() successfully completed......................................
2023-08-10 17:50:22,769:INFO:SubProcess create_model() end ==================================
2023-08-10 17:50:22,769:INFO:Creating metrics dataframe
2023-08-10 17:50:22,820:INFO:Initializing custom model Bagging Classifier
2023-08-10 17:50:22,821:INFO:Total runtime is 1.3650832931200663 minutes
2023-08-10 17:50:22,834:INFO:SubProcess create_model() called ==================================
2023-08-10 17:50:22,863:INFO:Initializing create_model()
2023-08-10 17:50:22,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F2845130>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:50:22,864:INFO:Checking exceptions
2023-08-10 17:50:22,865:INFO:Importing libraries
2023-08-10 17:50:22,865:INFO:Copying training dataset
2023-08-10 17:50:22,886:INFO:Defining folds
2023-08-10 17:50:22,886:INFO:Declaring metric variables
2023-08-10 17:50:22,902:INFO:Importing untrained model
2023-08-10 17:50:22,903:INFO:Declaring custom model
2023-08-10 17:50:22,950:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:50:22,992:INFO:Starting cross validation
2023-08-10 17:50:23,058:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:51:10,673:INFO:Calculating mean and std
2023-08-10 17:51:10,679:INFO:Creating metrics dataframe
2023-08-10 17:51:14,519:INFO:Uploading results into container
2023-08-10 17:51:14,521:INFO:Uploading model into container now
2023-08-10 17:51:14,523:INFO:_master_model_container: 38
2023-08-10 17:51:14,523:INFO:_display_container: 23
2023-08-10 17:51:14,549:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:51:14,549:INFO:create_model() successfully completed......................................
2023-08-10 17:51:15,013:INFO:SubProcess create_model() end ==================================
2023-08-10 17:51:15,015:INFO:Creating metrics dataframe
2023-08-10 17:51:15,115:INFO:Initializing create_model()
2023-08-10 17:51:15,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:51:15,116:INFO:Checking exceptions
2023-08-10 17:51:15,122:INFO:Importing libraries
2023-08-10 17:51:15,123:INFO:Copying training dataset
2023-08-10 17:51:15,142:INFO:Defining folds
2023-08-10 17:51:15,143:INFO:Declaring metric variables
2023-08-10 17:51:15,144:INFO:Importing untrained model
2023-08-10 17:51:15,145:INFO:Declaring custom model
2023-08-10 17:51:15,149:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 17:51:15,256:INFO:Cross validation set to False
2023-08-10 17:51:15,257:INFO:Fitting Model
2023-08-10 17:51:19,031:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:51:19,031:INFO:create_model() successfully completed......................................
2023-08-10 17:51:19,501:INFO:Creating Dashboard logs
2023-08-10 17:51:19,523:INFO:Model: Bagging Classifier
2023-08-10 17:51:20,330:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 6661, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 17:51:25,619:INFO:Initializing predict_model()
2023-08-10 17:51:25,619:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3ED414F70>)
2023-08-10 17:51:25,619:INFO:Checking exceptions
2023-08-10 17:51:25,619:INFO:Preloading libraries
2023-08-10 17:51:27,318:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:51:27,330:INFO:Initializing plot_model()
2023-08-10 17:51:27,330:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpr6aglqwq, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:51:27,331:INFO:Checking exceptions
2023-08-10 17:51:27,336:INFO:Preloading libraries
2023-08-10 17:51:27,387:INFO:Copying training dataset
2023-08-10 17:51:27,387:INFO:Plot type: auc
2023-08-10 17:51:28,167:INFO:Fitting Model
2023-08-10 17:51:28,168:INFO:Scoring test/hold-out set
2023-08-10 17:51:28,463:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpr6aglqwq\AUC.png'
2023-08-10 17:51:29,312:INFO:Visual Rendered Successfully
2023-08-10 17:51:29,784:INFO:plot_model() successfully completed......................................
2023-08-10 17:51:32,183:INFO:Initializing plot_model()
2023-08-10 17:51:32,184:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpr6aglqwq, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:51:32,184:INFO:Checking exceptions
2023-08-10 17:51:32,189:INFO:Preloading libraries
2023-08-10 17:51:32,235:INFO:Copying training dataset
2023-08-10 17:51:32,236:INFO:Plot type: confusion_matrix
2023-08-10 17:51:32,980:INFO:Fitting Model
2023-08-10 17:51:32,981:INFO:Scoring test/hold-out set
2023-08-10 17:51:33,277:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpr6aglqwq\Confusion Matrix.png'
2023-08-10 17:51:33,685:INFO:Visual Rendered Successfully
2023-08-10 17:51:34,142:INFO:plot_model() successfully completed......................................
2023-08-10 17:51:34,756:INFO:Initializing plot_model()
2023-08-10 17:51:34,757:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpr6aglqwq, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:51:34,757:INFO:Checking exceptions
2023-08-10 17:51:34,759:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 17:51:34,759:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:51:55,000:INFO:Creating Dashboard logs
2023-08-10 17:51:55,021:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 17:51:55,899:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 17:51:55,900:INFO:Logged params: {}
2023-08-10 17:52:11,529:INFO:Creating Dashboard logs
2023-08-10 17:52:11,547:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 17:52:12,383:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 17:52:12,384:INFO:Logged params: {}
2023-08-10 17:52:29,065:INFO:_master_model_container: 38
2023-08-10 17:52:29,066:INFO:_display_container: 23
2023-08-10 17:52:29,080:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=6661,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 17:52:29,080:INFO:compare_models() successfully completed......................................
2023-08-10 17:54:11,866:INFO:Initializing ensemble_model()
2023-08-10 17:54:11,867:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 17:54:11,868:INFO:Checking exceptions
2023-08-10 17:54:14,354:INFO:Importing libraries
2023-08-10 17:54:14,354:INFO:Copying training dataset
2023-08-10 17:54:14,354:INFO:Checking base model
2023-08-10 17:54:14,355:INFO:Base model : Extreme Gradient Boosting
2023-08-10 17:54:14,356:INFO:Importing untrained ensembler
2023-08-10 17:54:14,356:INFO:Ensemble method set to Boosting
2023-08-10 17:54:14,356:INFO:SubProcess create_model() called ==================================
2023-08-10 17:54:14,363:INFO:Initializing create_model()
2023-08-10 17:54:14,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=XGBClassifier(base_score=None, booster='gbtree',
                                           callbacks=None,
                                           colsample_bylevel=None,
                                           colsample_bynode=None,
                                           colsample_bytree=None,
                                           early_stopping_rounds=None,
                                           enable_categorical=False,
                                           eval_metric=None, feature_types=None,
                                           gamma=None, gpu_id=None,
                                           grow_policy=None,
                                           importance_type=...
                                           interaction_constraints=None,
                                           learning_rate=None, max_bin=None,
                                           max_cat_threshold=None,
                                           max_cat_to_onehot=None,
                                           max_delta_step=None, max_depth=None,
                                           max_leaves=None,
                                           min_child_weight=None, missing=nan,
                                           monotone_constraints=None,
                                           n_estimators=100, n_jobs=-1,
                                           num_parallel_tree=None,
                                           objective='binary:logistic',
                                           predictor=None, ...),
                   learning_rate=1.0, n_estimators=10, random_state=6661), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3ED8AA550>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 17:54:14,364:INFO:Checking exceptions
2023-08-10 17:54:14,364:INFO:Importing libraries
2023-08-10 17:54:14,364:INFO:Copying training dataset
2023-08-10 17:54:14,381:INFO:Defining folds
2023-08-10 17:54:14,383:INFO:Declaring metric variables
2023-08-10 17:54:14,385:INFO:Importing untrained model
2023-08-10 17:54:14,385:INFO:Declaring custom model
2023-08-10 17:54:14,389:INFO:Ada Boost Classifier Imported successfully
2023-08-10 17:54:14,390:INFO:Starting cross validation
2023-08-10 17:54:14,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 17:54:35,290:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:54:35,310:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:54:35,407:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:54:54,507:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:54:55,175:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:54:56,682:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:54:57,232:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:55:37,834:INFO:Calculating mean and std
2023-08-10 17:55:37,835:INFO:Creating metrics dataframe
2023-08-10 17:55:37,841:INFO:Finalizing model
2023-08-10 17:55:43,004:INFO:Uploading results into container
2023-08-10 17:55:43,006:INFO:Uploading model into container now
2023-08-10 17:55:43,007:INFO:_master_model_container: 39
2023-08-10 17:55:43,007:INFO:_display_container: 24
2023-08-10 17:55:43,030:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661)
2023-08-10 17:55:43,030:INFO:create_model() successfully completed......................................
2023-08-10 17:55:43,462:INFO:SubProcess create_model() end ==================================
2023-08-10 17:55:43,463:INFO:Creating Dashboard logs
2023-08-10 17:55:43,464:INFO:Model: Ada Boost Classifier
2023-08-10 17:55:44,310:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 6661, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'learning_rate': 1.0, 'n_estimators': 10, 'random_state': 6661}
2023-08-10 17:55:51,889:INFO:Initializing predict_model()
2023-08-10 17:55:51,889:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F49D5670>)
2023-08-10 17:55:51,890:INFO:Checking exceptions
2023-08-10 17:55:51,890:INFO:Preloading libraries
2023-08-10 17:55:53,296:INFO:SubProcess plot_model() called ==================================
2023-08-10 17:55:53,329:INFO:Initializing plot_model()
2023-08-10 17:55:53,329:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp8dhqfp3c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:55:53,330:INFO:Checking exceptions
2023-08-10 17:55:53,339:INFO:Preloading libraries
2023-08-10 17:55:53,449:INFO:Copying training dataset
2023-08-10 17:55:53,449:INFO:Plot type: auc
2023-08-10 17:55:54,158:INFO:Fitting Model
2023-08-10 17:55:54,161:INFO:Scoring test/hold-out set
2023-08-10 17:55:54,282:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp8dhqfp3c\AUC.png'
2023-08-10 17:55:55,101:INFO:Visual Rendered Successfully
2023-08-10 17:55:55,537:INFO:plot_model() successfully completed......................................
2023-08-10 17:55:56,100:INFO:Initializing plot_model()
2023-08-10 17:55:56,100:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp8dhqfp3c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:55:56,100:INFO:Checking exceptions
2023-08-10 17:55:56,116:INFO:Preloading libraries
2023-08-10 17:55:56,219:INFO:Copying training dataset
2023-08-10 17:55:56,219:INFO:Plot type: confusion_matrix
2023-08-10 17:55:56,943:INFO:Fitting Model
2023-08-10 17:55:56,945:INFO:Scoring test/hold-out set
2023-08-10 17:55:57,067:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp8dhqfp3c\Confusion Matrix.png'
2023-08-10 17:55:57,456:INFO:Visual Rendered Successfully
2023-08-10 17:55:57,891:INFO:plot_model() successfully completed......................................
2023-08-10 17:55:58,421:INFO:Initializing plot_model()
2023-08-10 17:55:58,422:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp8dhqfp3c, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 17:55:58,422:INFO:Checking exceptions
2023-08-10 17:55:58,437:INFO:Preloading libraries
2023-08-10 17:55:58,546:INFO:Copying training dataset
2023-08-10 17:55:58,547:INFO:Plot type: feature
2023-08-10 17:55:58,548:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 17:55:58,828:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp8dhqfp3c\Feature Importance.png'
2023-08-10 17:55:59,471:INFO:Visual Rendered Successfully
2023-08-10 17:55:59,895:INFO:plot_model() successfully completed......................................
2023-08-10 17:56:00,433:INFO:SubProcess plot_model() end ==================================
2023-08-10 17:56:10,379:INFO:_master_model_container: 39
2023-08-10 17:56:10,380:INFO:_display_container: 24
2023-08-10 17:56:10,400:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661)
2023-08-10 17:56:10,400:INFO:ensemble_model() successfully completed......................................
2023-08-10 17:56:10,853:INFO:Initializing tune_model()
2023-08-10 17:56:10,853:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 17:56:10,853:INFO:Checking exceptions
2023-08-10 17:56:10,907:INFO:Copying training dataset
2023-08-10 17:56:10,924:INFO:Checking base model
2023-08-10 17:56:10,925:INFO:Base model : Ada Boost Classifier
2023-08-10 17:56:10,944:INFO:Declaring metric variables
2023-08-10 17:56:10,956:INFO:Defining Hyperparameters
2023-08-10 17:56:11,461:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 17:56:11,461:INFO:Tuning with n_jobs=-1
2023-08-10 17:56:11,462:INFO:Initializing RandomizedSearchCV
2023-08-10 17:56:22,337:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:56:22,535:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:56:22,716:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:56:22,952:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:56:49,088:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:56:50,506:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:56:55,428:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:56:57,302:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:57:00,857:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:57:04,035:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:57:10,483:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:57:14,310:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:57:19,096:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:57:22,030:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:57:28,504:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:57:31,336:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:57:37,825:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:57:40,969:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:57:45,542:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:57:47,585:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:57:52,357:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:57:55,652:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:58:01,698:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:58:03,726:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:58:22,600:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:58:26,173:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:58:28,938:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:58:32,112:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:58:34,397:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:58:37,564:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:58:40,536:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:58:44,615:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:59:00,182:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:59:07,122:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:59:10,630:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:59:13,828:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:59:17,334:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:59:20,323:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:59:24,041:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:59:37,638:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:59:40,947:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 17:59:47,226:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 17:59:51,287:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:00:07,478:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:00:11,945:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:00:13,376:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:00:18,856:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:00:31,139:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:00:37,506:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:00:41,625:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:00:46,081:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:00:58,445:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:01:03,680:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:01:07,619:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:01:18,002:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:01:21,816:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:01:24,286:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:01:28,800:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:01:41,640:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:01:49,679:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:01:58,187:INFO:best_params: {'actual_estimator__n_estimators': 10}
2023-08-10 18:01:58,194:INFO:Hyperparameter search completed
2023-08-10 18:01:58,194:INFO:SubProcess create_model() called ==================================
2023-08-10 18:01:58,251:INFO:Initializing create_model()
2023-08-10 18:01:58,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F47862E0>, model_only=True, return_train_score=True, kwargs={'n_estimators': 10})
2023-08-10 18:01:58,253:INFO:Checking exceptions
2023-08-10 18:01:58,254:INFO:Importing libraries
2023-08-10 18:01:58,254:INFO:Copying training dataset
2023-08-10 18:01:58,301:INFO:Defining folds
2023-08-10 18:01:58,302:INFO:Declaring metric variables
2023-08-10 18:01:58,331:INFO:Importing untrained model
2023-08-10 18:01:58,332:INFO:Declaring custom model
2023-08-10 18:01:58,406:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:01:58,448:INFO:Starting cross validation
2023-08-10 18:01:58,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:02:01,703:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:02:01,848:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:02:01,936:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:02:02,413:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:02:13,635:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:02:42,050:INFO:Calculating mean and std
2023-08-10 18:02:42,055:INFO:Creating metrics dataframe
2023-08-10 18:02:42,086:INFO:Finalizing model
2023-08-10 18:02:42,486:INFO:Initializing predict_model()
2023-08-10 18:02:42,486:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                              max_cat_threshold=None,
                                                                              max_cat_to_onehot=None,
                                                                              max_delta_step=None,
                                                                              max_depth=None,
                                                                              max_leaves=None,
                                                                              min_child_weight=None,
                                                                              missing=nan,
                                                                              monotone_constraints=None,
                                                                              n_estimators=100,
                                                                              n_jobs=-1,
                                                                              num_parallel_tree=None,
                                                                              objective='binary:logistic',
                                                                              predictor=None, ...),
                                                      learning_rate=1.0,
                                                      n_estimators=10,
                                                      probability_threshold=0.4,
                                                      random_state=6661))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3ED414310>)
2023-08-10 18:02:42,487:INFO:Checking exceptions
2023-08-10 18:02:42,487:INFO:Preloading libraries
2023-08-10 18:02:42,487:INFO:Set up data.
2023-08-10 18:02:42,511:INFO:Set up index.
2023-08-10 18:02:47,164:INFO:Uploading results into container
2023-08-10 18:02:47,173:INFO:Uploading model into container now
2023-08-10 18:02:47,176:INFO:_master_model_container: 40
2023-08-10 18:02:47,176:INFO:_display_container: 25
2023-08-10 18:02:47,204:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661)
2023-08-10 18:02:47,207:INFO:create_model() successfully completed......................................
2023-08-10 18:02:47,727:INFO:SubProcess create_model() end ==================================
2023-08-10 18:02:47,727:INFO:choose_better activated
2023-08-10 18:02:47,737:INFO:SubProcess create_model() called ==================================
2023-08-10 18:02:47,761:INFO:Initializing create_model()
2023-08-10 18:02:47,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:02:47,763:INFO:Checking exceptions
2023-08-10 18:02:47,768:INFO:Importing libraries
2023-08-10 18:02:47,769:INFO:Copying training dataset
2023-08-10 18:02:47,784:INFO:Defining folds
2023-08-10 18:02:47,784:INFO:Declaring metric variables
2023-08-10 18:02:47,785:INFO:Importing untrained model
2023-08-10 18:02:47,786:INFO:Declaring custom model
2023-08-10 18:02:47,798:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:02:47,798:INFO:Starting cross validation
2023-08-10 18:02:47,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:03:23,775:INFO:Calculating mean and std
2023-08-10 18:03:23,777:INFO:Creating metrics dataframe
2023-08-10 18:03:23,784:INFO:Finalizing model
2023-08-10 18:03:28,262:INFO:Uploading results into container
2023-08-10 18:03:28,264:INFO:Uploading model into container now
2023-08-10 18:03:28,265:INFO:_master_model_container: 41
2023-08-10 18:03:28,265:INFO:_display_container: 26
2023-08-10 18:03:28,291:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661)
2023-08-10 18:03:28,292:INFO:create_model() successfully completed......................................
2023-08-10 18:03:28,765:INFO:SubProcess create_model() end ==================================
2023-08-10 18:03:28,792:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661) result for Prec. is 0.1699
2023-08-10 18:03:28,818:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661) result for Prec. is 0.1699
2023-08-10 18:03:28,844:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661) is best model
2023-08-10 18:03:28,844:INFO:choose_better completed
2023-08-10 18:03:28,844:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-10 18:03:28,846:INFO:Creating Dashboard logs
2023-08-10 18:03:28,860:INFO:Model: Ada Boost Classifier
2023-08-10 18:03:29,684:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 6661, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'learning_rate': 1.0, 'n_estimators': 10, 'random_state': 6661}
2023-08-10 18:03:35,179:INFO:Initializing predict_model()
2023-08-10 18:03:35,180:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F289A430>)
2023-08-10 18:03:35,180:INFO:Checking exceptions
2023-08-10 18:03:35,180:INFO:Preloading libraries
2023-08-10 18:03:36,639:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:03:36,660:INFO:Initializing plot_model()
2023-08-10 18:03:36,660:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp0v05vyww, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 18:03:36,660:INFO:Checking exceptions
2023-08-10 18:03:36,673:INFO:Preloading libraries
2023-08-10 18:03:36,783:INFO:Copying training dataset
2023-08-10 18:03:36,784:INFO:Plot type: auc
2023-08-10 18:03:37,532:INFO:Fitting Model
2023-08-10 18:03:37,533:INFO:Scoring test/hold-out set
2023-08-10 18:03:37,669:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp0v05vyww\AUC.png'
2023-08-10 18:03:38,517:INFO:Visual Rendered Successfully
2023-08-10 18:03:38,965:INFO:plot_model() successfully completed......................................
2023-08-10 18:03:39,604:INFO:Initializing plot_model()
2023-08-10 18:03:39,605:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp0v05vyww, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 18:03:39,606:INFO:Checking exceptions
2023-08-10 18:03:39,614:INFO:Preloading libraries
2023-08-10 18:03:39,725:INFO:Copying training dataset
2023-08-10 18:03:39,725:INFO:Plot type: confusion_matrix
2023-08-10 18:03:40,481:INFO:Fitting Model
2023-08-10 18:03:40,482:INFO:Scoring test/hold-out set
2023-08-10 18:03:40,610:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp0v05vyww\Confusion Matrix.png'
2023-08-10 18:03:41,024:INFO:Visual Rendered Successfully
2023-08-10 18:03:41,473:INFO:plot_model() successfully completed......................................
2023-08-10 18:03:42,026:INFO:Initializing plot_model()
2023-08-10 18:03:42,027:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp0v05vyww, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 18:03:42,027:INFO:Checking exceptions
2023-08-10 18:03:42,041:INFO:Preloading libraries
2023-08-10 18:03:42,158:INFO:Copying training dataset
2023-08-10 18:03:42,159:INFO:Plot type: feature
2023-08-10 18:03:42,160:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 18:03:42,457:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp0v05vyww\Feature Importance.png'
2023-08-10 18:03:43,093:INFO:Visual Rendered Successfully
2023-08-10 18:03:43,544:INFO:plot_model() successfully completed......................................
2023-08-10 18:03:44,072:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:03:55,313:INFO:_master_model_container: 41
2023-08-10 18:03:55,314:INFO:_display_container: 25
2023-08-10 18:03:55,342:INFO:CustomProbabilityThresholdClassifier(algorithm='SAMME.R',
                                     base_estimator='deprecated',
                                     classifier=AdaBoostClassifier(algorithm='SAMME.R',
                                                                   base_estimator='deprecated',
                                                                   estimator=XGBClassifier(base_score=None,
                                                                                           booster='gbtree',
                                                                                           callbacks=None,
                                                                                           colsample_bylevel=None,
                                                                                           colsample_bynode=None,
                                                                                           colsample_bytree=None,
                                                                                           early_stopping_rounds=None,
                                                                                           enable_categorical=Fa...
                                                             learning_rate=None,
                                                             max_bin=None,
                                                             max_cat_threshold=None,
                                                             max_cat_to_onehot=None,
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     learning_rate=1.0, n_estimators=10,
                                     probability_threshold=0.4,
                                     random_state=6661)
2023-08-10 18:03:55,343:INFO:tune_model() successfully completed......................................
2023-08-10 18:03:59,626:INFO:Initializing ensemble_model()
2023-08-10 18:03:59,627:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), method=clf, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 18:03:59,627:INFO:Checking exceptions
2023-08-10 18:04:51,922:INFO:Initializing tune_model()
2023-08-10 18:04:51,922:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 18:04:51,922:INFO:Checking exceptions
2023-08-10 18:04:51,985:INFO:Copying training dataset
2023-08-10 18:04:52,001:INFO:Checking base model
2023-08-10 18:04:52,002:INFO:Base model : Naive Bayes
2023-08-10 18:04:52,017:INFO:Declaring metric variables
2023-08-10 18:04:52,029:INFO:Defining Hyperparameters
2023-08-10 18:04:52,654:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 18:04:52,655:INFO:Tuning with n_jobs=-1
2023-08-10 18:04:52,655:INFO:Initializing RandomizedSearchCV
2023-08-10 18:07:10,476:INFO:Initializing ensemble_model()
2023-08-10 18:07:10,477:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 18:07:10,477:INFO:Checking exceptions
2023-08-10 18:07:10,492:INFO:Importing libraries
2023-08-10 18:07:10,493:INFO:Copying training dataset
2023-08-10 18:07:10,493:INFO:Checking base model
2023-08-10 18:07:10,493:INFO:Base model : Naive Bayes
2023-08-10 18:07:10,494:INFO:Importing untrained ensembler
2023-08-10 18:07:10,494:INFO:Ensemble method set to Bagging
2023-08-10 18:07:10,494:INFO:SubProcess create_model() called ==================================
2023-08-10 18:07:10,496:INFO:Initializing create_model()
2023-08-10 18:07:10,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GaussianNB(priors=None, var_smoothing=1e-09),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F151ED30>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:07:10,497:INFO:Checking exceptions
2023-08-10 18:07:10,497:INFO:Importing libraries
2023-08-10 18:07:10,497:INFO:Copying training dataset
2023-08-10 18:07:10,517:INFO:Defining folds
2023-08-10 18:07:10,518:INFO:Declaring metric variables
2023-08-10 18:07:10,519:INFO:Importing untrained model
2023-08-10 18:07:10,519:INFO:Declaring custom model
2023-08-10 18:07:10,521:INFO:Bagging Classifier Imported successfully
2023-08-10 18:07:10,522:INFO:Starting cross validation
2023-08-10 18:07:10,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:07:38,263:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:08:17,626:INFO:Initializing ensemble_model()
2023-08-10 18:08:17,626:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 18:08:17,626:INFO:Checking exceptions
2023-08-10 18:08:17,640:INFO:Importing libraries
2023-08-10 18:08:17,641:INFO:Copying training dataset
2023-08-10 18:08:17,641:INFO:Checking base model
2023-08-10 18:08:17,642:INFO:Base model : Extreme Gradient Boosting
2023-08-10 18:08:17,642:INFO:Importing untrained ensembler
2023-08-10 18:08:17,642:INFO:Ensemble method set to Bagging
2023-08-10 18:08:17,643:INFO:SubProcess create_model() called ==================================
2023-08-10 18:08:17,649:INFO:Initializing create_model()
2023-08-10 18:08:17,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=XGBClassifier(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None,
                                          early_stopping_rounds=None,
                                          enable_categorical=False,
                                          eval_metric=None, feature_types=None,
                                          gamma=None, gpu_id=None,
                                          grow_policy=No...
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          n_estimators=100, n_jobs=-1,
                                          num_parallel_tree=None,
                                          objective='binary:logistic',
                                          predictor=None, ...),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6661, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3F5EADFD0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:08:17,649:INFO:Checking exceptions
2023-08-10 18:08:17,649:INFO:Importing libraries
2023-08-10 18:08:17,649:INFO:Copying training dataset
2023-08-10 18:08:17,665:INFO:Defining folds
2023-08-10 18:08:17,666:INFO:Declaring metric variables
2023-08-10 18:08:17,666:INFO:Importing untrained model
2023-08-10 18:08:17,666:INFO:Declaring custom model
2023-08-10 18:08:17,674:INFO:Bagging Classifier Imported successfully
2023-08-10 18:08:17,676:INFO:Starting cross validation
2023-08-10 18:08:17,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:09:04,924:INFO:Calculating mean and std
2023-08-10 18:09:04,926:INFO:Creating metrics dataframe
2023-08-10 18:09:04,933:INFO:Finalizing model
2023-08-10 18:09:10,031:INFO:Uploading results into container
2023-08-10 18:09:10,033:INFO:Uploading model into container now
2023-08-10 18:09:10,035:INFO:_master_model_container: 42
2023-08-10 18:09:10,036:INFO:_display_container: 26
2023-08-10 18:09:10,078:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 18:09:10,079:INFO:create_model() successfully completed......................................
2023-08-10 18:09:13,293:INFO:SubProcess create_model() end ==================================
2023-08-10 18:09:13,294:INFO:Creating Dashboard logs
2023-08-10 18:09:13,296:INFO:Model: Bagging Classifier
2023-08-10 18:09:14,146:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 6661, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 6661, 'verbose': 0, 'warm_start': False}
2023-08-10 18:09:19,574:INFO:Initializing predict_model()
2023-08-10 18:09:19,575:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C3F4301430>)
2023-08-10 18:09:19,575:INFO:Checking exceptions
2023-08-10 18:09:19,575:INFO:Preloading libraries
2023-08-10 18:09:21,062:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:09:21,083:INFO:Initializing plot_model()
2023-08-10 18:09:21,083:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmplzwf9bki, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 18:09:21,083:INFO:Checking exceptions
2023-08-10 18:09:21,089:INFO:Preloading libraries
2023-08-10 18:09:21,221:INFO:Copying training dataset
2023-08-10 18:09:21,222:INFO:Plot type: auc
2023-08-10 18:09:21,953:INFO:Fitting Model
2023-08-10 18:09:21,955:INFO:Scoring test/hold-out set
2023-08-10 18:09:22,141:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmplzwf9bki\AUC.png'
2023-08-10 18:09:23,030:INFO:Visual Rendered Successfully
2023-08-10 18:09:23,463:INFO:plot_model() successfully completed......................................
2023-08-10 18:09:24,047:INFO:Initializing plot_model()
2023-08-10 18:09:24,048:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmplzwf9bki, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 18:09:24,048:INFO:Checking exceptions
2023-08-10 18:09:24,054:INFO:Preloading libraries
2023-08-10 18:09:24,188:INFO:Copying training dataset
2023-08-10 18:09:24,188:INFO:Plot type: confusion_matrix
2023-08-10 18:09:24,921:INFO:Fitting Model
2023-08-10 18:09:24,922:INFO:Scoring test/hold-out set
2023-08-10 18:09:25,094:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmplzwf9bki\Confusion Matrix.png'
2023-08-10 18:09:25,496:INFO:Visual Rendered Successfully
2023-08-10 18:09:25,924:INFO:plot_model() successfully completed......................................
2023-08-10 18:09:26,480:INFO:Initializing plot_model()
2023-08-10 18:09:26,481:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmplzwf9bki, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>, system=False)
2023-08-10 18:09:26,481:INFO:Checking exceptions
2023-08-10 18:09:26,482:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 18:09:26,482:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:09:38,627:INFO:_master_model_container: 42
2023-08-10 18:09:38,627:INFO:_display_container: 26
2023-08-10 18:09:38,651:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False)
2023-08-10 18:09:38,651:INFO:ensemble_model() successfully completed......................................
2023-08-10 18:09:39,092:INFO:Initializing tune_model()
2023-08-10 18:09:39,093:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=6661, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3ED652BB0>)
2023-08-10 18:09:39,093:INFO:Checking exceptions
2023-08-10 18:09:39,145:INFO:Copying training dataset
2023-08-10 18:09:39,157:INFO:Checking base model
2023-08-10 18:09:39,158:INFO:Base model : Bagging Classifier
2023-08-10 18:09:39,173:INFO:Declaring metric variables
2023-08-10 18:09:39,189:INFO:Defining Hyperparameters
2023-08-10 18:09:39,656:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 18:09:39,656:INFO:Tuning with n_jobs=-1
2023-08-10 18:09:39,656:INFO:Initializing RandomizedSearchCV
2023-08-10 18:09:49,009:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:13:58,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 18:13:58,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 18:13:58,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 18:13:58,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 18:14:29,394:INFO:PyCaret AnomalyExperiment
2023-08-10 18:14:29,394:INFO:Logging name: anomaly-default-name
2023-08-10 18:14:29,395:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 18:14:29,395:INFO:version 3.0.4
2023-08-10 18:14:29,395:INFO:Initializing setup()
2023-08-10 18:14:29,396:INFO:self.USI: 29ab
2023-08-10 18:14:29,396:INFO:self._variable_keys: {'exp_name_log', 'seed', 'data', 'pipeline', 'gpu_n_jobs_param', 'X', 'USI', 'memory', 'exp_id', '_available_plots', 'html_param', 'logging_param', 'n_jobs_param', 'gpu_param', 'idx', '_ml_usecase', 'log_plots_param'}
2023-08-10 18:14:29,396:INFO:Checking environment
2023-08-10 18:14:29,396:INFO:python_version: 3.9.13
2023-08-10 18:14:29,396:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 18:14:29,396:INFO:machine: AMD64
2023-08-10 18:14:29,396:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 18:14:29,409:INFO:Memory: svmem(total=7480111104, available=1025863680, percent=86.3, used=6454247424, free=1025863680)
2023-08-10 18:14:29,409:INFO:Physical Core: 4
2023-08-10 18:14:29,410:INFO:Logical Core: 4
2023-08-10 18:14:29,410:INFO:Checking libraries
2023-08-10 18:14:29,410:INFO:System:
2023-08-10 18:14:29,411:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 18:14:29,411:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 18:14:29,412:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 18:14:29,412:INFO:PyCaret required dependencies:
2023-08-10 18:14:29,711:INFO:                 pip: 23.1.2
2023-08-10 18:14:29,711:INFO:          setuptools: 58.1.0
2023-08-10 18:14:29,711:INFO:             pycaret: 3.0.4
2023-08-10 18:14:29,712:INFO:             IPython: 8.13.2
2023-08-10 18:14:29,712:INFO:          ipywidgets: 8.0.7
2023-08-10 18:14:29,712:INFO:                tqdm: 4.65.0
2023-08-10 18:14:29,713:INFO:               numpy: 1.23.5
2023-08-10 18:14:29,713:INFO:              pandas: 1.5.3
2023-08-10 18:14:29,713:INFO:              jinja2: 3.1.2
2023-08-10 18:14:29,713:INFO:               scipy: 1.10.1
2023-08-10 18:14:29,713:INFO:              joblib: 1.2.0
2023-08-10 18:14:29,713:INFO:             sklearn: 1.2.2
2023-08-10 18:14:29,713:INFO:                pyod: 1.1.0
2023-08-10 18:14:29,714:INFO:            imblearn: 0.11.0
2023-08-10 18:14:29,715:INFO:   category_encoders: 2.6.1
2023-08-10 18:14:29,715:INFO:            lightgbm: 4.0.0
2023-08-10 18:14:29,715:INFO:               numba: 0.57.1
2023-08-10 18:14:29,715:INFO:            requests: 2.31.0
2023-08-10 18:14:29,716:INFO:          matplotlib: 3.7.1
2023-08-10 18:14:29,721:INFO:          scikitplot: 0.3.7
2023-08-10 18:14:29,721:INFO:         yellowbrick: 1.5
2023-08-10 18:14:29,722:INFO:              plotly: 5.15.0
2023-08-10 18:14:29,722:INFO:    plotly-resampler: Not installed
2023-08-10 18:14:29,722:INFO:             kaleido: 0.2.1
2023-08-10 18:14:29,722:INFO:           schemdraw: 0.15
2023-08-10 18:14:29,722:INFO:         statsmodels: 0.14.0
2023-08-10 18:14:29,722:INFO:              sktime: 0.20.1
2023-08-10 18:14:29,722:INFO:               tbats: 1.1.3
2023-08-10 18:14:29,722:INFO:            pmdarima: 2.0.3
2023-08-10 18:14:29,723:INFO:              psutil: 5.9.5
2023-08-10 18:14:29,744:INFO:          markupsafe: 2.1.3
2023-08-10 18:14:29,744:INFO:             pickle5: Not installed
2023-08-10 18:14:29,744:INFO:         cloudpickle: 2.2.1
2023-08-10 18:14:29,744:INFO:         deprecation: 2.1.0
2023-08-10 18:14:29,744:INFO:              xxhash: 3.2.0
2023-08-10 18:14:29,744:INFO:           wurlitzer: Not installed
2023-08-10 18:14:29,745:INFO:PyCaret optional dependencies:
2023-08-10 18:14:29,845:INFO:                shap: Not installed
2023-08-10 18:14:29,846:INFO:           interpret: 0.4.2
2023-08-10 18:14:29,846:INFO:                umap: 0.5.3
2023-08-10 18:14:29,846:INFO:    pandas_profiling: Not installed
2023-08-10 18:14:29,846:INFO:  explainerdashboard: Not installed
2023-08-10 18:14:29,846:INFO:             autoviz: Not installed
2023-08-10 18:14:29,846:INFO:           fairlearn: Not installed
2023-08-10 18:14:29,846:INFO:          deepchecks: Not installed
2023-08-10 18:14:29,846:INFO:             xgboost: 1.7.6
2023-08-10 18:14:29,847:INFO:            catboost: Not installed
2023-08-10 18:14:29,847:INFO:              kmodes: Not installed
2023-08-10 18:14:29,847:INFO:             mlxtend: 0.22.0
2023-08-10 18:14:29,847:INFO:       statsforecast: Not installed
2023-08-10 18:14:29,847:INFO:        tune_sklearn: Not installed
2023-08-10 18:14:29,847:INFO:                 ray: Not installed
2023-08-10 18:14:29,847:INFO:            hyperopt: Not installed
2023-08-10 18:14:29,848:INFO:              optuna: Not installed
2023-08-10 18:14:29,848:INFO:               skopt: Not installed
2023-08-10 18:14:29,848:INFO:              mlflow: 2.4.2
2023-08-10 18:14:29,848:INFO:              gradio: Not installed
2023-08-10 18:14:29,848:INFO:             fastapi: Not installed
2023-08-10 18:14:29,849:INFO:             uvicorn: Not installed
2023-08-10 18:14:29,849:INFO:              m2cgen: Not installed
2023-08-10 18:14:29,849:INFO:           evidently: Not installed
2023-08-10 18:14:29,849:INFO:               fugue: Not installed
2023-08-10 18:14:29,849:INFO:           streamlit: 1.25.0
2023-08-10 18:14:29,849:INFO:             prophet: Not installed
2023-08-10 18:14:29,852:INFO:None
2023-08-10 18:14:29,853:INFO:Set up data.
2023-08-10 18:14:29,881:INFO:Set up index.
2023-08-10 18:14:29,881:INFO:Assigning column types.
2023-08-10 18:14:29,895:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 18:14:34,393:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 18:14:34,405:INFO:Preparing preprocessing pipeline...
2023-08-10 18:14:34,406:INFO:Set up simple imputation.
2023-08-10 18:14:34,414:INFO:Set up encoding of categorical features.
2023-08-10 18:14:34,620:INFO:Finished creating preprocessing pipeline.
2023-08-10 18:14:34,681:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 18:14:34,682:INFO:Creating final display dataframe.
2023-08-10 18:14:34,773:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  2298
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  29ab
2023-08-10 18:14:34,776:INFO:setup() successfully completed in 10.65s...............
2023-08-10 18:14:34,777:INFO:Initializing create_model()
2023-08-10 18:14:34,777:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000027EE4A6CD00>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 18:14:34,778:INFO:Checking exceptions
2023-08-10 18:14:34,898:INFO:Importing untrained model
2023-08-10 18:14:34,905:INFO:Isolation Forest Imported successfully
2023-08-10 18:14:34,909:INFO:Fitting Model
2023-08-10 18:14:37,740:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2298, verbose=0)
2023-08-10 18:14:37,741:INFO:create_models() successfully completed......................................
2023-08-10 18:14:37,741:INFO:Uploading results into container
2023-08-10 18:14:37,741:INFO:Uploading model into container now
2023-08-10 18:14:37,741:INFO:_master_model_container: 1
2023-08-10 18:14:37,741:INFO:_display_container: 1
2023-08-10 18:14:37,742:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2298, verbose=0)
2023-08-10 18:14:37,742:INFO:create_model() successfully completed......................................
2023-08-10 18:14:41,010:INFO:Initializing plot_model()
2023-08-10 18:14:41,010:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2298, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000027EE4A6CD00>, system=True)
2023-08-10 18:14:41,010:INFO:Checking exceptions
2023-08-10 18:14:47,326:INFO:Preloading libraries
2023-08-10 18:14:47,395:INFO:Copying training dataset
2023-08-10 18:14:47,395:INFO:Plot type: umap
2023-08-10 18:14:47,396:INFO:SubProcess assign_model() called ==================================
2023-08-10 18:14:47,397:INFO:Initializing assign_model()
2023-08-10 18:14:47,397:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000027EE4A6CD00>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2298, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 18:14:47,397:INFO:Checking exceptions
2023-08-10 18:14:47,398:INFO:Determining Trained Model
2023-08-10 18:14:47,399:INFO:Trained Model : Isolation Forest
2023-08-10 18:14:47,402:INFO:Copying data
2023-08-10 18:14:47,439:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 18:14:47,440:INFO:(3941, 18)
2023-08-10 18:14:47,441:INFO:assign_model() successfully completed......................................
2023-08-10 18:14:47,441:INFO:SubProcess assign_model() end ==================================
2023-08-10 18:14:47,446:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 18:15:06,594:INFO:Fitting UMAP()
2023-08-10 18:16:05,352:INFO:Rendering Visual
2023-08-10 18:16:10,083:INFO:Visual Rendered Successfully
2023-08-10 18:16:10,752:INFO:plot_model() successfully completed......................................
2023-08-10 18:16:10,833:INFO:Initializing assign_model()
2023-08-10 18:16:10,833:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000027EE4A6CD00>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=2298, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 18:16:10,833:INFO:Checking exceptions
2023-08-10 18:16:10,834:INFO:Determining Trained Model
2023-08-10 18:16:10,838:INFO:Trained Model : Isolation Forest
2023-08-10 18:16:10,839:INFO:Copying data
2023-08-10 18:16:10,846:INFO:(3941, 13)
2023-08-10 18:16:10,847:INFO:assign_model() successfully completed......................................
2023-08-10 18:16:15,917:INFO:PyCaret ClassificationExperiment
2023-08-10 18:16:15,918:INFO:Logging name: Customer Churn
2023-08-10 18:16:15,918:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 18:16:15,918:INFO:version 3.0.4
2023-08-10 18:16:15,918:INFO:Initializing setup()
2023-08-10 18:16:15,918:INFO:self.USI: 1b17
2023-08-10 18:16:15,918:INFO:self._variable_keys: {'y_train', 'exp_name_log', 'seed', 'data', 'is_multiclass', 'pipeline', 'gpu_n_jobs_param', 'y_test', 'X', 'USI', 'memory', 'fold_groups_param', 'exp_id', '_available_plots', 'fold_shuffle_param', 'fix_imbalance', 'fold_generator', 'html_param', 'X_test', 'target_param', 'X_train', 'logging_param', 'n_jobs_param', 'gpu_param', 'idx', '_ml_usecase', 'log_plots_param', 'y'}
2023-08-10 18:16:15,919:INFO:Checking environment
2023-08-10 18:16:15,919:INFO:python_version: 3.9.13
2023-08-10 18:16:15,919:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 18:16:15,919:INFO:machine: AMD64
2023-08-10 18:16:15,919:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 18:16:15,929:INFO:Memory: svmem(total=7480111104, available=771440640, percent=89.7, used=6708670464, free=771440640)
2023-08-10 18:16:15,929:INFO:Physical Core: 4
2023-08-10 18:16:15,930:INFO:Logical Core: 4
2023-08-10 18:16:15,930:INFO:Checking libraries
2023-08-10 18:16:15,930:INFO:System:
2023-08-10 18:16:15,930:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 18:16:15,930:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 18:16:15,931:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 18:16:15,931:INFO:PyCaret required dependencies:
2023-08-10 18:16:15,931:INFO:                 pip: 23.1.2
2023-08-10 18:16:15,931:INFO:          setuptools: 58.1.0
2023-08-10 18:16:15,931:INFO:             pycaret: 3.0.4
2023-08-10 18:16:15,931:INFO:             IPython: 8.13.2
2023-08-10 18:16:15,932:INFO:          ipywidgets: 8.0.7
2023-08-10 18:16:15,932:INFO:                tqdm: 4.65.0
2023-08-10 18:16:15,932:INFO:               numpy: 1.23.5
2023-08-10 18:16:15,932:INFO:              pandas: 1.5.3
2023-08-10 18:16:15,932:INFO:              jinja2: 3.1.2
2023-08-10 18:16:15,932:INFO:               scipy: 1.10.1
2023-08-10 18:16:15,932:INFO:              joblib: 1.2.0
2023-08-10 18:16:15,932:INFO:             sklearn: 1.2.2
2023-08-10 18:16:15,932:INFO:                pyod: 1.1.0
2023-08-10 18:16:15,932:INFO:            imblearn: 0.11.0
2023-08-10 18:16:15,933:INFO:   category_encoders: 2.6.1
2023-08-10 18:16:15,933:INFO:            lightgbm: 4.0.0
2023-08-10 18:16:15,933:INFO:               numba: 0.57.1
2023-08-10 18:16:15,933:INFO:            requests: 2.31.0
2023-08-10 18:16:15,933:INFO:          matplotlib: 3.7.1
2023-08-10 18:16:15,933:INFO:          scikitplot: 0.3.7
2023-08-10 18:16:15,933:INFO:         yellowbrick: 1.5
2023-08-10 18:16:15,933:INFO:              plotly: 5.15.0
2023-08-10 18:16:15,933:INFO:    plotly-resampler: Not installed
2023-08-10 18:16:15,933:INFO:             kaleido: 0.2.1
2023-08-10 18:16:15,933:INFO:           schemdraw: 0.15
2023-08-10 18:16:15,934:INFO:         statsmodels: 0.14.0
2023-08-10 18:16:15,934:INFO:              sktime: 0.20.1
2023-08-10 18:16:15,934:INFO:               tbats: 1.1.3
2023-08-10 18:16:15,934:INFO:            pmdarima: 2.0.3
2023-08-10 18:16:15,934:INFO:              psutil: 5.9.5
2023-08-10 18:16:15,934:INFO:          markupsafe: 2.1.3
2023-08-10 18:16:15,934:INFO:             pickle5: Not installed
2023-08-10 18:16:15,934:INFO:         cloudpickle: 2.2.1
2023-08-10 18:16:15,934:INFO:         deprecation: 2.1.0
2023-08-10 18:16:15,934:INFO:              xxhash: 3.2.0
2023-08-10 18:16:15,935:INFO:           wurlitzer: Not installed
2023-08-10 18:16:15,935:INFO:PyCaret optional dependencies:
2023-08-10 18:16:15,935:INFO:                shap: Not installed
2023-08-10 18:16:15,935:INFO:           interpret: 0.4.2
2023-08-10 18:16:15,935:INFO:                umap: 0.5.3
2023-08-10 18:16:15,935:INFO:    pandas_profiling: Not installed
2023-08-10 18:16:15,935:INFO:  explainerdashboard: Not installed
2023-08-10 18:16:15,936:INFO:             autoviz: Not installed
2023-08-10 18:16:15,936:INFO:           fairlearn: Not installed
2023-08-10 18:16:15,936:INFO:          deepchecks: Not installed
2023-08-10 18:16:15,936:INFO:             xgboost: 1.7.6
2023-08-10 18:16:15,936:INFO:            catboost: Not installed
2023-08-10 18:16:15,936:INFO:              kmodes: Not installed
2023-08-10 18:16:15,936:INFO:             mlxtend: 0.22.0
2023-08-10 18:16:15,936:INFO:       statsforecast: Not installed
2023-08-10 18:16:15,936:INFO:        tune_sklearn: Not installed
2023-08-10 18:16:15,937:INFO:                 ray: Not installed
2023-08-10 18:16:15,937:INFO:            hyperopt: Not installed
2023-08-10 18:16:15,937:INFO:              optuna: Not installed
2023-08-10 18:16:15,937:INFO:               skopt: Not installed
2023-08-10 18:16:15,937:INFO:              mlflow: 2.4.2
2023-08-10 18:16:15,937:INFO:              gradio: Not installed
2023-08-10 18:16:15,937:INFO:             fastapi: Not installed
2023-08-10 18:16:15,937:INFO:             uvicorn: Not installed
2023-08-10 18:16:15,937:INFO:              m2cgen: Not installed
2023-08-10 18:16:15,937:INFO:           evidently: Not installed
2023-08-10 18:16:15,937:INFO:               fugue: Not installed
2023-08-10 18:16:15,938:INFO:           streamlit: 1.25.0
2023-08-10 18:16:15,938:INFO:             prophet: Not installed
2023-08-10 18:16:15,938:INFO:None
2023-08-10 18:16:15,938:INFO:Set up data.
2023-08-10 18:16:15,966:INFO:Set up train/test split.
2023-08-10 18:16:15,986:INFO:Set up index.
2023-08-10 18:16:15,986:INFO:Set up folding strategy.
2023-08-10 18:16:15,987:INFO:Assigning column types.
2023-08-10 18:16:16,001:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 18:16:16,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 18:16:16,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 18:16:16,314:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:16,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:16,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 18:16:16,499:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 18:16:16,607:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:16,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:16,618:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 18:16:16,791:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 18:16:16,897:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:16,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:17,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 18:16:17,180:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:17,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:17,192:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 18:16:17,484:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:17,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:17,772:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:17,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:17,790:INFO:Preparing preprocessing pipeline...
2023-08-10 18:16:17,793:INFO:Set up simple imputation.
2023-08-10 18:16:17,804:INFO:Set up encoding of categorical features.
2023-08-10 18:16:17,805:INFO:Set up removing outliers.
2023-08-10 18:16:18,114:INFO:Finished creating preprocessing pipeline.
2023-08-10 18:16:18,137:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 18:16:18,137:INFO:Creating final display dataframe.
2023-08-10 18:16:24,830:INFO:Setup _display_container:                     Description            Value
0                    Session id              619
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2523, 17)
5   Transformed train set shape       (1738, 17)
6    Transformed test set shape        (785, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15              Remove outliers          iforest
16           Outliers threshold             0.05
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment    DagshubLogger
22              Experiment Name   Customer Churn
23                          USI             1b17
2023-08-10 18:16:25,217:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:25,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:25,512:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:16:25,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:16:25,522:INFO:Logging experiment in loggers
2023-08-10 18:16:51,241:INFO:SubProcess save_model() called ==================================
2023-08-10 18:16:51,282:INFO:Initializing save_model()
2023-08-10 18:16:51,282:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05)))],
         verbose=False), model_name=C:\Users\HP\AppData\Local\Temp\tmpyxm0xb5f\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-10 18:16:51,282:INFO:Adding model into prep_pipe
2023-08-10 18:16:51,283:WARNING:Only Model saved as it was a pipeline.
2023-08-10 18:16:51,430:INFO:C:\Users\HP\AppData\Local\Temp\tmpyxm0xb5f\Transformation Pipeline.pkl saved in current working directory
2023-08-10 18:16:51,449:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 18:16:51,450:INFO:save_model() successfully completed......................................
2023-08-10 18:16:51,796:INFO:SubProcess save_model() end ==================================
2023-08-10 18:17:05,380:INFO:setup() successfully completed in 14.03s...............
2023-08-10 18:17:05,425:INFO:Initializing get_config()
2023-08-10 18:17:05,428:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, variable=pipeline)
2023-08-10 18:17:05,450:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 18:17:05,450:INFO:get_config() successfully completed......................................
2023-08-10 18:17:05,665:INFO:gpu_param set to False
2023-08-10 18:17:05,989:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:17:06,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:17:06,314:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 18:17:06,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 18:17:06,380:INFO:Initializing compare_models()
2023-08-10 18:17:06,380:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, include=['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt', 'nb'], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, 'include': ['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt', 'nb'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 18:17:06,381:INFO:Checking exceptions
2023-08-10 18:17:06,395:INFO:Preparing display monitor
2023-08-10 18:17:06,514:INFO:Initializing Ada Boost Classifier
2023-08-10 18:17:06,515:INFO:Total runtime is 1.6681353251139323e-05 minutes
2023-08-10 18:17:06,531:INFO:SubProcess create_model() called ==================================
2023-08-10 18:17:06,532:INFO:Initializing create_model()
2023-08-10 18:17:06,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:17:06,533:INFO:Checking exceptions
2023-08-10 18:17:06,533:INFO:Importing libraries
2023-08-10 18:17:06,533:INFO:Copying training dataset
2023-08-10 18:17:06,554:INFO:Defining folds
2023-08-10 18:17:06,554:INFO:Declaring metric variables
2023-08-10 18:17:06,580:INFO:Importing untrained model
2023-08-10 18:17:06,601:INFO:Ada Boost Classifier Imported successfully
2023-08-10 18:17:06,640:INFO:Starting cross validation
2023-08-10 18:17:06,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:17:16,640:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:16,702:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:16,833:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:16,933:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:18,686:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 18:17:18,747:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 18:17:21,185:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:21,289:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:21,317:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:21,336:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:30,646:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:30,704:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:30,768:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:31,060:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:32,355:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 18:17:32,446:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 18:17:32,588:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-10 18:17:35,581:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:35,638:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:35,758:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:35,898:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:17:44,695:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:17:44,702:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 18:18:04,810:INFO:Calculating mean and std
2023-08-10 18:18:04,813:INFO:Creating metrics dataframe
2023-08-10 18:18:09,095:INFO:Uploading results into container
2023-08-10 18:18:09,098:INFO:Uploading model into container now
2023-08-10 18:18:09,107:INFO:_master_model_container: 1
2023-08-10 18:18:09,112:INFO:_display_container: 2
2023-08-10 18:18:09,113:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=619)
2023-08-10 18:18:09,113:INFO:create_model() successfully completed......................................
2023-08-10 18:18:09,477:INFO:SubProcess create_model() end ==================================
2023-08-10 18:18:09,477:INFO:Creating metrics dataframe
2023-08-10 18:18:09,513:INFO:Initializing Gradient Boosting Classifier
2023-08-10 18:18:09,513:INFO:Total runtime is 1.0499857624371847 minutes
2023-08-10 18:18:09,530:INFO:SubProcess create_model() called ==================================
2023-08-10 18:18:09,531:INFO:Initializing create_model()
2023-08-10 18:18:09,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:18:09,533:INFO:Checking exceptions
2023-08-10 18:18:09,533:INFO:Importing libraries
2023-08-10 18:18:09,533:INFO:Copying training dataset
2023-08-10 18:18:09,557:INFO:Defining folds
2023-08-10 18:18:09,558:INFO:Declaring metric variables
2023-08-10 18:18:09,571:INFO:Importing untrained model
2023-08-10 18:18:09,586:INFO:Gradient Boosting Classifier Imported successfully
2023-08-10 18:18:09,618:INFO:Starting cross validation
2023-08-10 18:18:09,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:18:23,611:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:18:50,651:INFO:Calculating mean and std
2023-08-10 18:18:50,657:INFO:Creating metrics dataframe
2023-08-10 18:18:54,656:INFO:Uploading results into container
2023-08-10 18:18:54,659:INFO:Uploading model into container now
2023-08-10 18:18:54,661:INFO:_master_model_container: 2
2023-08-10 18:18:54,663:INFO:_display_container: 2
2023-08-10 18:18:54,665:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=619, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-10 18:18:54,667:INFO:create_model() successfully completed......................................
2023-08-10 18:18:55,025:INFO:SubProcess create_model() end ==================================
2023-08-10 18:18:55,025:INFO:Creating metrics dataframe
2023-08-10 18:18:55,062:INFO:Initializing Extreme Gradient Boosting
2023-08-10 18:18:55,063:INFO:Total runtime is 1.8091522137324016 minutes
2023-08-10 18:18:55,078:INFO:SubProcess create_model() called ==================================
2023-08-10 18:18:55,080:INFO:Initializing create_model()
2023-08-10 18:18:55,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:18:55,084:INFO:Checking exceptions
2023-08-10 18:18:55,085:INFO:Importing libraries
2023-08-10 18:18:55,085:INFO:Copying training dataset
2023-08-10 18:18:55,148:INFO:Defining folds
2023-08-10 18:18:55,148:INFO:Declaring metric variables
2023-08-10 18:18:55,168:INFO:Importing untrained model
2023-08-10 18:18:55,259:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 18:18:55,331:INFO:Starting cross validation
2023-08-10 18:18:55,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:19:32,980:INFO:Calculating mean and std
2023-08-10 18:19:32,989:INFO:Creating metrics dataframe
2023-08-10 18:19:37,270:INFO:Uploading results into container
2023-08-10 18:19:37,273:INFO:Uploading model into container now
2023-08-10 18:19:37,275:INFO:_master_model_container: 3
2023-08-10 18:19:37,275:INFO:_display_container: 2
2023-08-10 18:19:37,284:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 18:19:37,291:INFO:create_model() successfully completed......................................
2023-08-10 18:19:37,758:INFO:SubProcess create_model() end ==================================
2023-08-10 18:19:37,759:INFO:Creating metrics dataframe
2023-08-10 18:19:37,804:INFO:Initializing Random Forest Classifier
2023-08-10 18:19:37,805:INFO:Total runtime is 2.521518894036611 minutes
2023-08-10 18:19:37,816:INFO:SubProcess create_model() called ==================================
2023-08-10 18:19:37,817:INFO:Initializing create_model()
2023-08-10 18:19:37,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:19:37,819:INFO:Checking exceptions
2023-08-10 18:19:37,820:INFO:Importing libraries
2023-08-10 18:19:37,821:INFO:Copying training dataset
2023-08-10 18:19:37,841:INFO:Defining folds
2023-08-10 18:19:37,841:INFO:Declaring metric variables
2023-08-10 18:19:37,863:INFO:Importing untrained model
2023-08-10 18:19:37,895:INFO:Random Forest Classifier Imported successfully
2023-08-10 18:19:37,924:INFO:Starting cross validation
2023-08-10 18:19:38,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:19:50,412:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:19:50,428:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:19:52,573:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:19:52,649:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:20:20,176:INFO:Calculating mean and std
2023-08-10 18:20:20,179:INFO:Creating metrics dataframe
2023-08-10 18:20:24,152:INFO:Uploading results into container
2023-08-10 18:20:24,153:INFO:Uploading model into container now
2023-08-10 18:20:24,155:INFO:_master_model_container: 4
2023-08-10 18:20:24,156:INFO:_display_container: 2
2023-08-10 18:20:24,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=619, verbose=0, warm_start=False)
2023-08-10 18:20:24,160:INFO:create_model() successfully completed......................................
2023-08-10 18:20:24,519:INFO:SubProcess create_model() end ==================================
2023-08-10 18:20:24,519:INFO:Creating metrics dataframe
2023-08-10 18:20:24,557:INFO:Initializing Logistic Regression
2023-08-10 18:20:24,557:INFO:Total runtime is 3.3007200439771016 minutes
2023-08-10 18:20:24,573:INFO:SubProcess create_model() called ==================================
2023-08-10 18:20:24,574:INFO:Initializing create_model()
2023-08-10 18:20:24,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:20:24,575:INFO:Checking exceptions
2023-08-10 18:20:24,575:INFO:Importing libraries
2023-08-10 18:20:24,576:INFO:Copying training dataset
2023-08-10 18:20:24,596:INFO:Defining folds
2023-08-10 18:20:24,597:INFO:Declaring metric variables
2023-08-10 18:20:24,622:INFO:Importing untrained model
2023-08-10 18:20:24,643:INFO:Logistic Regression Imported successfully
2023-08-10 18:20:24,711:INFO:Starting cross validation
2023-08-10 18:20:24,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:21:03,255:INFO:Calculating mean and std
2023-08-10 18:21:03,260:INFO:Creating metrics dataframe
2023-08-10 18:21:07,705:INFO:Uploading results into container
2023-08-10 18:21:07,707:INFO:Uploading model into container now
2023-08-10 18:21:07,711:INFO:_master_model_container: 5
2023-08-10 18:21:07,711:INFO:_display_container: 2
2023-08-10 18:21:07,714:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=619, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 18:21:07,714:INFO:create_model() successfully completed......................................
2023-08-10 18:21:08,077:INFO:SubProcess create_model() end ==================================
2023-08-10 18:21:08,077:INFO:Creating metrics dataframe
2023-08-10 18:21:08,124:INFO:Initializing K Neighbors Classifier
2023-08-10 18:21:08,124:INFO:Total runtime is 4.026837587356567 minutes
2023-08-10 18:21:08,138:INFO:SubProcess create_model() called ==================================
2023-08-10 18:21:08,139:INFO:Initializing create_model()
2023-08-10 18:21:08,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:21:08,141:INFO:Checking exceptions
2023-08-10 18:21:08,141:INFO:Importing libraries
2023-08-10 18:21:08,141:INFO:Copying training dataset
2023-08-10 18:21:08,164:INFO:Defining folds
2023-08-10 18:21:08,165:INFO:Declaring metric variables
2023-08-10 18:21:08,182:INFO:Importing untrained model
2023-08-10 18:21:08,206:INFO:K Neighbors Classifier Imported successfully
2023-08-10 18:21:08,261:INFO:Starting cross validation
2023-08-10 18:21:08,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:21:46,666:INFO:Calculating mean and std
2023-08-10 18:21:46,670:INFO:Creating metrics dataframe
2023-08-10 18:21:50,714:INFO:Uploading results into container
2023-08-10 18:21:50,716:INFO:Uploading model into container now
2023-08-10 18:21:50,718:INFO:_master_model_container: 6
2023-08-10 18:21:50,718:INFO:_display_container: 2
2023-08-10 18:21:50,720:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-10 18:21:50,725:INFO:create_model() successfully completed......................................
2023-08-10 18:21:51,082:INFO:SubProcess create_model() end ==================================
2023-08-10 18:21:51,083:INFO:Creating metrics dataframe
2023-08-10 18:21:51,130:INFO:Initializing Decision Tree Classifier
2023-08-10 18:21:51,130:INFO:Total runtime is 4.743602255980174 minutes
2023-08-10 18:21:51,142:INFO:SubProcess create_model() called ==================================
2023-08-10 18:21:51,143:INFO:Initializing create_model()
2023-08-10 18:21:51,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:21:51,145:INFO:Checking exceptions
2023-08-10 18:21:51,146:INFO:Importing libraries
2023-08-10 18:21:51,146:INFO:Copying training dataset
2023-08-10 18:21:51,164:INFO:Defining folds
2023-08-10 18:21:51,164:INFO:Declaring metric variables
2023-08-10 18:21:51,181:INFO:Importing untrained model
2023-08-10 18:21:51,203:INFO:Decision Tree Classifier Imported successfully
2023-08-10 18:21:51,267:INFO:Starting cross validation
2023-08-10 18:21:51,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:21:53,242:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:21:53,873:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:21:53,969:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:22:32,559:INFO:Calculating mean and std
2023-08-10 18:22:32,563:INFO:Creating metrics dataframe
2023-08-10 18:22:37,146:INFO:Uploading results into container
2023-08-10 18:22:37,153:INFO:Uploading model into container now
2023-08-10 18:22:37,154:INFO:_master_model_container: 7
2023-08-10 18:22:37,155:INFO:_display_container: 2
2023-08-10 18:22:37,161:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=619, splitter='best')
2023-08-10 18:22:37,162:INFO:create_model() successfully completed......................................
2023-08-10 18:22:37,499:INFO:SubProcess create_model() end ==================================
2023-08-10 18:22:37,499:INFO:Creating metrics dataframe
2023-08-10 18:22:37,539:INFO:Initializing Naive Bayes
2023-08-10 18:22:37,539:INFO:Total runtime is 5.517085699240367 minutes
2023-08-10 18:22:37,554:INFO:SubProcess create_model() called ==================================
2023-08-10 18:22:37,555:INFO:Initializing create_model()
2023-08-10 18:22:37,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB9B3B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:22:37,555:INFO:Checking exceptions
2023-08-10 18:22:37,556:INFO:Importing libraries
2023-08-10 18:22:37,556:INFO:Copying training dataset
2023-08-10 18:22:37,577:INFO:Defining folds
2023-08-10 18:22:37,577:INFO:Declaring metric variables
2023-08-10 18:22:37,593:INFO:Importing untrained model
2023-08-10 18:22:37,612:INFO:Naive Bayes Imported successfully
2023-08-10 18:22:37,655:INFO:Starting cross validation
2023-08-10 18:22:37,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:23:15,338:INFO:Calculating mean and std
2023-08-10 18:23:15,343:INFO:Creating metrics dataframe
2023-08-10 18:23:19,458:INFO:Uploading results into container
2023-08-10 18:23:19,460:INFO:Uploading model into container now
2023-08-10 18:23:19,462:INFO:_master_model_container: 8
2023-08-10 18:23:19,463:INFO:_display_container: 2
2023-08-10 18:23:19,464:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 18:23:19,464:INFO:create_model() successfully completed......................................
2023-08-10 18:23:19,827:INFO:SubProcess create_model() end ==================================
2023-08-10 18:23:19,827:INFO:Creating metrics dataframe
2023-08-10 18:23:19,909:INFO:Initializing create_model()
2023-08-10 18:23:19,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:23:19,910:INFO:Checking exceptions
2023-08-10 18:23:19,918:INFO:Importing libraries
2023-08-10 18:23:19,919:INFO:Copying training dataset
2023-08-10 18:23:19,932:INFO:Defining folds
2023-08-10 18:23:19,932:INFO:Declaring metric variables
2023-08-10 18:23:19,933:INFO:Importing untrained model
2023-08-10 18:23:19,933:INFO:Declaring custom model
2023-08-10 18:23:19,937:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 18:23:19,983:INFO:Cross validation set to False
2023-08-10 18:23:19,984:INFO:Fitting Model
2023-08-10 18:23:23,781:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 18:23:23,781:INFO:create_model() successfully completed......................................
2023-08-10 18:23:24,129:INFO:Creating Dashboard logs
2023-08-10 18:23:24,146:INFO:Model: Extreme Gradient Boosting
2023-08-10 18:23:24,991:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 619, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-08-10 18:23:30,291:INFO:Initializing predict_model()
2023-08-10 18:23:30,292:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECF9CC10>)
2023-08-10 18:23:30,292:INFO:Checking exceptions
2023-08-10 18:23:30,292:INFO:Preloading libraries
2023-08-10 18:23:31,601:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:23:31,603:INFO:Initializing plot_model()
2023-08-10 18:23:31,603:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpvw_87tzo, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:23:31,603:INFO:Checking exceptions
2023-08-10 18:23:31,612:INFO:Preloading libraries
2023-08-10 18:23:31,626:INFO:Copying training dataset
2023-08-10 18:23:31,626:INFO:Plot type: auc
2023-08-10 18:23:32,363:INFO:Fitting Model
2023-08-10 18:23:32,366:INFO:Scoring test/hold-out set
2023-08-10 18:23:32,446:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpvw_87tzo\AUC.png'
2023-08-10 18:23:33,314:INFO:Visual Rendered Successfully
2023-08-10 18:23:33,653:INFO:plot_model() successfully completed......................................
2023-08-10 18:23:34,163:INFO:Initializing plot_model()
2023-08-10 18:23:34,164:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpvw_87tzo, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:23:34,164:INFO:Checking exceptions
2023-08-10 18:23:34,170:INFO:Preloading libraries
2023-08-10 18:23:34,184:INFO:Copying training dataset
2023-08-10 18:23:34,185:INFO:Plot type: confusion_matrix
2023-08-10 18:23:34,914:INFO:Fitting Model
2023-08-10 18:23:34,916:INFO:Scoring test/hold-out set
2023-08-10 18:23:34,989:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpvw_87tzo\Confusion Matrix.png'
2023-08-10 18:23:35,403:INFO:Visual Rendered Successfully
2023-08-10 18:23:35,740:INFO:plot_model() successfully completed......................................
2023-08-10 18:23:36,327:INFO:Initializing plot_model()
2023-08-10 18:23:36,328:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpvw_87tzo, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:23:36,328:INFO:Checking exceptions
2023-08-10 18:23:36,336:INFO:Preloading libraries
2023-08-10 18:23:36,354:INFO:Copying training dataset
2023-08-10 18:23:36,355:INFO:Plot type: feature
2023-08-10 18:23:36,358:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 18:23:36,632:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpvw_87tzo\Feature Importance.png'
2023-08-10 18:23:37,328:INFO:Visual Rendered Successfully
2023-08-10 18:23:37,667:INFO:plot_model() successfully completed......................................
2023-08-10 18:23:38,172:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:23:47,194:INFO:Creating Dashboard logs
2023-08-10 18:23:47,207:INFO:Model: Gradient Boosting Classifier
2023-08-10 18:23:48,026:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 619, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-08-10 18:24:03,103:INFO:Creating Dashboard logs
2023-08-10 18:24:03,116:INFO:Model: Random Forest Classifier
2023-08-10 18:24:03,956:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 18:24:18,691:INFO:Creating Dashboard logs
2023-08-10 18:24:18,701:INFO:Model: Naive Bayes
2023-08-10 18:24:19,495:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-08-10 18:24:33,553:INFO:Creating Dashboard logs
2023-08-10 18:24:33,563:INFO:Model: Ada Boost Classifier
2023-08-10 18:24:34,391:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 619}
2023-08-10 18:24:48,531:INFO:Creating Dashboard logs
2023-08-10 18:24:48,542:INFO:Model: Decision Tree Classifier
2023-08-10 18:24:49,367:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 619, 'splitter': 'best'}
2023-08-10 18:25:04,177:INFO:Creating Dashboard logs
2023-08-10 18:25:04,189:INFO:Model: Logistic Regression
2023-08-10 18:25:04,987:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 619, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 18:25:19,954:INFO:Creating Dashboard logs
2023-08-10 18:25:19,964:INFO:Model: K Neighbors Classifier
2023-08-10 18:25:20,855:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-08-10 18:25:34,941:INFO:_master_model_container: 8
2023-08-10 18:25:34,942:INFO:_display_container: 2
2023-08-10 18:25:34,945:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 18:25:34,945:INFO:compare_models() successfully completed......................................
2023-08-10 18:25:35,092:INFO:Initializing create_model()
2023-08-10 18:25:35,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=xgboost, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 18:25:35,093:INFO:Checking exceptions
2023-08-10 18:25:35,155:INFO:Importing libraries
2023-08-10 18:25:35,155:INFO:Copying training dataset
2023-08-10 18:25:35,186:INFO:Defining folds
2023-08-10 18:25:35,186:INFO:Declaring metric variables
2023-08-10 18:25:35,206:INFO:Importing untrained model
2023-08-10 18:25:35,227:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 18:25:35,295:INFO:Cross validation set to False
2023-08-10 18:25:35,295:INFO:Fitting Model
2023-08-10 18:25:35,981:INFO:Initializing predict_model()
2023-08-10 18:25:35,981:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EDF7F7EE0>)
2023-08-10 18:25:35,982:INFO:Checking exceptions
2023-08-10 18:25:35,983:INFO:Preloading libraries
2023-08-10 18:25:35,985:INFO:Set up data.
2023-08-10 18:25:36,006:INFO:Set up index.
2023-08-10 18:25:37,105:INFO:Initializing predict_model()
2023-08-10 18:25:37,105:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EDF7F7EE0>)
2023-08-10 18:25:37,105:INFO:Checking exceptions
2023-08-10 18:25:37,106:INFO:Preloading libraries
2023-08-10 18:25:38,009:INFO:_display_container: 3
2023-08-10 18:25:41,292:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 18:25:41,292:INFO:create_model() successfully completed......................................
2023-08-10 18:25:41,776:INFO:Initializing ensemble_model()
2023-08-10 18:25:41,777:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 18:25:41,777:INFO:Checking exceptions
2023-08-10 18:25:41,791:INFO:Importing libraries
2023-08-10 18:25:41,792:INFO:Copying training dataset
2023-08-10 18:25:41,792:INFO:Checking base model
2023-08-10 18:25:41,793:INFO:Base model : Extreme Gradient Boosting
2023-08-10 18:25:41,794:INFO:Importing untrained ensembler
2023-08-10 18:25:41,794:INFO:Ensemble method set to Bagging
2023-08-10 18:25:41,795:INFO:SubProcess create_model() called ==================================
2023-08-10 18:25:41,807:INFO:Initializing create_model()
2023-08-10 18:25:41,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=XGBClassifier(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None,
                                          early_stopping_rounds=None,
                                          enable_categorical=False,
                                          eval_metric=None, feature_types=None,
                                          gamma=None, gpu_id=None,
                                          grow_policy=No...
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          n_estimators=100, n_jobs=-1,
                                          num_parallel_tree=None,
                                          objective='binary:logistic',
                                          predictor=None, ...),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=619, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EE78F1040>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:25:41,808:INFO:Checking exceptions
2023-08-10 18:25:41,808:INFO:Importing libraries
2023-08-10 18:25:41,808:INFO:Copying training dataset
2023-08-10 18:25:41,826:INFO:Defining folds
2023-08-10 18:25:41,826:INFO:Declaring metric variables
2023-08-10 18:25:41,827:INFO:Importing untrained model
2023-08-10 18:25:41,828:INFO:Declaring custom model
2023-08-10 18:25:41,839:INFO:Bagging Classifier Imported successfully
2023-08-10 18:25:41,840:INFO:Starting cross validation
2023-08-10 18:25:41,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:26:30,579:INFO:Calculating mean and std
2023-08-10 18:26:30,582:INFO:Creating metrics dataframe
2023-08-10 18:26:30,589:INFO:Finalizing model
2023-08-10 18:26:39,936:INFO:Uploading results into container
2023-08-10 18:26:39,938:INFO:Uploading model into container now
2023-08-10 18:26:39,939:INFO:_master_model_container: 9
2023-08-10 18:26:39,939:INFO:_display_container: 4
2023-08-10 18:26:39,967:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:26:39,968:INFO:create_model() successfully completed......................................
2023-08-10 18:26:40,312:INFO:SubProcess create_model() end ==================================
2023-08-10 18:26:40,313:INFO:Creating Dashboard logs
2023-08-10 18:26:40,316:INFO:Model: Bagging Classifier
2023-08-10 18:26:41,216:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 619, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 18:26:46,649:INFO:Initializing predict_model()
2023-08-10 18:26:46,649:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDCAF70>)
2023-08-10 18:26:46,650:INFO:Checking exceptions
2023-08-10 18:26:46,650:INFO:Preloading libraries
2023-08-10 18:26:47,985:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:26:48,020:INFO:Initializing plot_model()
2023-08-10 18:26:48,020:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpmibvymny, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:26:48,021:INFO:Checking exceptions
2023-08-10 18:26:48,026:INFO:Preloading libraries
2023-08-10 18:26:48,149:INFO:Copying training dataset
2023-08-10 18:26:48,149:INFO:Plot type: auc
2023-08-10 18:26:48,866:INFO:Fitting Model
2023-08-10 18:26:48,867:INFO:Scoring test/hold-out set
2023-08-10 18:26:49,024:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpmibvymny\AUC.png'
2023-08-10 18:26:49,839:INFO:Visual Rendered Successfully
2023-08-10 18:26:50,170:INFO:plot_model() successfully completed......................................
2023-08-10 18:26:50,750:INFO:Initializing plot_model()
2023-08-10 18:26:50,750:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpmibvymny, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:26:50,750:INFO:Checking exceptions
2023-08-10 18:26:50,755:INFO:Preloading libraries
2023-08-10 18:26:50,878:INFO:Copying training dataset
2023-08-10 18:26:50,879:INFO:Plot type: confusion_matrix
2023-08-10 18:26:51,599:INFO:Fitting Model
2023-08-10 18:26:51,600:INFO:Scoring test/hold-out set
2023-08-10 18:26:51,758:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpmibvymny\Confusion Matrix.png'
2023-08-10 18:26:52,158:INFO:Visual Rendered Successfully
2023-08-10 18:26:52,490:INFO:plot_model() successfully completed......................................
2023-08-10 18:26:53,097:INFO:Initializing plot_model()
2023-08-10 18:26:53,097:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpmibvymny, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:26:53,098:INFO:Checking exceptions
2023-08-10 18:26:53,105:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 18:26:53,105:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:27:05,363:INFO:_master_model_container: 9
2023-08-10 18:27:05,363:INFO:_display_container: 4
2023-08-10 18:27:05,385:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:27:05,385:INFO:ensemble_model() successfully completed......................................
2023-08-10 18:27:05,734:INFO:Initializing tune_model()
2023-08-10 18:27:05,735:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>)
2023-08-10 18:27:05,735:INFO:Checking exceptions
2023-08-10 18:27:05,803:INFO:Copying training dataset
2023-08-10 18:27:05,817:INFO:Checking base model
2023-08-10 18:27:05,817:INFO:Base model : Bagging Classifier
2023-08-10 18:27:05,833:INFO:Declaring metric variables
2023-08-10 18:27:05,848:INFO:Defining Hyperparameters
2023-08-10 18:27:06,236:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 18:27:06,237:INFO:Tuning with n_jobs=-1
2023-08-10 18:27:06,237:INFO:Initializing RandomizedSearchCV
2023-08-10 18:27:07,749:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:27:15,200:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:27:59,773:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:01,288:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:28:04,147:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:06,549:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:28:10,155:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:12,151:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:28:15,653:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:17,903:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:28:44,006:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:45,497:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:28:48,430:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:50,268:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:28:52,839:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:54,752:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:28:57,833:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:28:59,712:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:29:26,407:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:29:27,840:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:29:29,626:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:29:31,468:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:30:08,610:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:30:12,415:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:30:15,391:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:30:19,246:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-10 18:30:23,246:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:30:58,661:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:31:03,542:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:31:03,679:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:31:10,318:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:32:08,768:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:32:11,803:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:32:14,309:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:32:18,152:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:32:45,433:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:32:48,236:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:32:49,022:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:32:52,073:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:33:54,775:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:33:58,760:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:33:59,987:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:34:03,968:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:35:13,238:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:35:15,880:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:35:17,781:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:35:20,310:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:35:54,118:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:35:57,681:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:35:58,247:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:36:02,295:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:36:55,211:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:36:58,051:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:36:59,165:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:37:02,797:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:37:35,966:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:37:38,523:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:37:39,887:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:37:43,067:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:38:32,156:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:38:34,321:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:38:35,570:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:38:38,133:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:38:45,632:INFO:best_params: {'actual_estimator__n_estimators': 150}
2023-08-10 18:38:45,635:INFO:Hyperparameter search completed
2023-08-10 18:38:45,636:INFO:SubProcess create_model() called ==================================
2023-08-10 18:38:45,675:INFO:Initializing create_model()
2023-08-10 18:38:45,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB59FE50>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150})
2023-08-10 18:38:45,676:INFO:Checking exceptions
2023-08-10 18:38:45,677:INFO:Importing libraries
2023-08-10 18:38:45,678:INFO:Copying training dataset
2023-08-10 18:38:45,695:INFO:Defining folds
2023-08-10 18:38:45,695:INFO:Declaring metric variables
2023-08-10 18:38:45,712:INFO:Importing untrained model
2023-08-10 18:38:45,712:INFO:Declaring custom model
2023-08-10 18:38:45,747:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:38:45,790:INFO:Starting cross validation
2023-08-10 18:38:45,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:38:52,877:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:38:52,886:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:38:52,921:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:38:58,235:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:00,125:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:00,179:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:00,204:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:20,847:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:23,332:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:23,337:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:23,367:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:30,359:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:32,142:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:32,173:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:32,198:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:51,534:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:53,249:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:39:58,742:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:40:00,089:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:40:09,582:INFO:Calculating mean and std
2023-08-10 18:40:09,590:INFO:Creating metrics dataframe
2023-08-10 18:40:09,654:INFO:Finalizing model
2023-08-10 18:41:00,433:INFO:Initializing predict_model()
2023-08-10 18:41:00,433:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                              max_depth=None,
                                                                              max_leaves=None,
                                                                              min_child_weight=None,
                                                                              missing=nan,
                                                                              monotone_constraints=None,
                                                                              n_estimators=100,
                                                                              n_jobs=-1,
                                                                              num_parallel_tree=None,
                                                                              objective='binary:logistic',
                                                                              predictor=None, ...),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=150,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDCACA0>)
2023-08-10 18:41:00,434:INFO:Checking exceptions
2023-08-10 18:41:00,434:INFO:Preloading libraries
2023-08-10 18:41:00,435:INFO:Set up data.
2023-08-10 18:41:00,458:INFO:Set up index.
2023-08-10 18:41:07,430:INFO:Uploading results into container
2023-08-10 18:41:07,432:INFO:Uploading model into container now
2023-08-10 18:41:07,437:INFO:_master_model_container: 10
2023-08-10 18:41:07,438:INFO:_display_container: 5
2023-08-10 18:41:07,463:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:41:07,464:INFO:create_model() successfully completed......................................
2023-08-10 18:41:07,890:INFO:SubProcess create_model() end ==================================
2023-08-10 18:41:07,891:INFO:choose_better activated
2023-08-10 18:41:07,911:INFO:SubProcess create_model() called ==================================
2023-08-10 18:41:07,996:INFO:Initializing create_model()
2023-08-10 18:41:07,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:41:08,010:INFO:Checking exceptions
2023-08-10 18:41:08,026:INFO:Importing libraries
2023-08-10 18:41:08,026:INFO:Copying training dataset
2023-08-10 18:41:08,059:INFO:Defining folds
2023-08-10 18:41:08,059:INFO:Declaring metric variables
2023-08-10 18:41:08,060:INFO:Importing untrained model
2023-08-10 18:41:08,060:INFO:Declaring custom model
2023-08-10 18:41:08,085:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:41:08,091:INFO:Starting cross validation
2023-08-10 18:41:08,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:41:54,447:INFO:Calculating mean and std
2023-08-10 18:41:54,448:INFO:Creating metrics dataframe
2023-08-10 18:41:54,456:INFO:Finalizing model
2023-08-10 18:42:00,071:INFO:Uploading results into container
2023-08-10 18:42:00,073:INFO:Uploading model into container now
2023-08-10 18:42:00,074:INFO:_master_model_container: 11
2023-08-10 18:42:00,074:INFO:_display_container: 6
2023-08-10 18:42:00,095:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:42:00,096:INFO:create_model() successfully completed......................................
2023-08-10 18:42:00,425:INFO:SubProcess create_model() end ==================================
2023-08-10 18:42:00,447:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) result for Prec. is 0.7371
2023-08-10 18:42:00,471:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) result for Prec. is 0.7432
2023-08-10 18:42:00,491:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) is best model
2023-08-10 18:42:00,492:INFO:choose_better completed
2023-08-10 18:42:00,492:INFO:Creating Dashboard logs
2023-08-10 18:42:00,504:INFO:Model: Bagging Classifier
2023-08-10 18:42:01,567:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 619, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 18:42:07,255:INFO:Initializing predict_model()
2023-08-10 18:42:07,255:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EED0B64C0>)
2023-08-10 18:42:07,256:INFO:Checking exceptions
2023-08-10 18:42:07,256:INFO:Preloading libraries
2023-08-10 18:42:09,907:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:42:09,932:INFO:Initializing plot_model()
2023-08-10 18:42:09,933:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmprue5y5iv, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:42:09,933:INFO:Checking exceptions
2023-08-10 18:42:09,938:INFO:Preloading libraries
2023-08-10 18:42:11,786:INFO:Copying training dataset
2023-08-10 18:42:11,786:INFO:Plot type: auc
2023-08-10 18:42:12,614:INFO:Fitting Model
2023-08-10 18:42:12,616:INFO:Scoring test/hold-out set
2023-08-10 18:42:14,123:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmprue5y5iv\AUC.png'
2023-08-10 18:42:15,011:INFO:Visual Rendered Successfully
2023-08-10 18:42:15,414:INFO:plot_model() successfully completed......................................
2023-08-10 18:42:28,080:INFO:Initializing plot_model()
2023-08-10 18:42:28,081:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmprue5y5iv, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:42:28,081:INFO:Checking exceptions
2023-08-10 18:42:28,086:INFO:Preloading libraries
2023-08-10 18:42:29,917:INFO:Copying training dataset
2023-08-10 18:42:29,918:INFO:Plot type: confusion_matrix
2023-08-10 18:42:30,638:INFO:Fitting Model
2023-08-10 18:42:30,639:INFO:Scoring test/hold-out set
2023-08-10 18:42:32,104:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmprue5y5iv\Confusion Matrix.png'
2023-08-10 18:42:32,554:INFO:Visual Rendered Successfully
2023-08-10 18:42:32,893:INFO:plot_model() successfully completed......................................
2023-08-10 18:42:33,483:INFO:Initializing plot_model()
2023-08-10 18:42:33,483:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmprue5y5iv, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:42:33,484:INFO:Checking exceptions
2023-08-10 18:42:33,484:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 18:42:33,485:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:43:44,000:INFO:_master_model_container: 11
2023-08-10 18:43:44,001:INFO:_display_container: 5
2023-08-10 18:43:44,044:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:43:44,044:INFO:tune_model() successfully completed......................................
2023-08-10 18:43:48,707:INFO:Initializing create_model()
2023-08-10 18:43:48,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=nb, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 18:43:48,709:INFO:Checking exceptions
2023-08-10 18:43:48,768:INFO:Importing libraries
2023-08-10 18:43:48,769:INFO:Copying training dataset
2023-08-10 18:43:48,798:INFO:Defining folds
2023-08-10 18:43:48,798:INFO:Declaring metric variables
2023-08-10 18:43:48,813:INFO:Importing untrained model
2023-08-10 18:43:48,828:INFO:Naive Bayes Imported successfully
2023-08-10 18:43:48,897:INFO:Cross validation set to False
2023-08-10 18:43:48,897:INFO:Fitting Model
2023-08-10 18:43:49,269:INFO:Initializing predict_model()
2023-08-10 18:43:49,269:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDCAEE0>)
2023-08-10 18:43:49,269:INFO:Checking exceptions
2023-08-10 18:43:49,269:INFO:Preloading libraries
2023-08-10 18:43:49,270:INFO:Set up data.
2023-08-10 18:43:49,289:INFO:Set up index.
2023-08-10 18:43:49,797:INFO:Initializing predict_model()
2023-08-10 18:43:49,797:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECD92820>)
2023-08-10 18:43:49,797:INFO:Checking exceptions
2023-08-10 18:43:49,797:INFO:Preloading libraries
2023-08-10 18:43:50,639:INFO:_display_container: 6
2023-08-10 18:43:54,196:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 18:43:54,196:INFO:create_model() successfully completed......................................
2023-08-10 18:43:54,640:INFO:Initializing ensemble_model()
2023-08-10 18:43:54,642:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 18:43:54,644:INFO:Checking exceptions
2023-08-10 18:43:54,657:INFO:Importing libraries
2023-08-10 18:43:54,658:INFO:Copying training dataset
2023-08-10 18:43:54,658:INFO:Checking base model
2023-08-10 18:43:54,658:INFO:Base model : Naive Bayes
2023-08-10 18:43:54,660:INFO:Importing untrained ensembler
2023-08-10 18:43:54,660:INFO:Ensemble method set to Bagging
2023-08-10 18:43:54,661:INFO:SubProcess create_model() called ==================================
2023-08-10 18:43:54,662:INFO:Initializing create_model()
2023-08-10 18:43:54,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GaussianNB(priors=None, var_smoothing=1e-09),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=619, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EE7F71250>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:43:54,663:INFO:Checking exceptions
2023-08-10 18:43:54,663:INFO:Importing libraries
2023-08-10 18:43:54,663:INFO:Copying training dataset
2023-08-10 18:43:54,680:INFO:Defining folds
2023-08-10 18:43:54,680:INFO:Declaring metric variables
2023-08-10 18:43:54,681:INFO:Importing untrained model
2023-08-10 18:43:54,681:INFO:Declaring custom model
2023-08-10 18:43:54,684:INFO:Bagging Classifier Imported successfully
2023-08-10 18:43:54,685:INFO:Starting cross validation
2023-08-10 18:43:54,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:44:40,787:INFO:Calculating mean and std
2023-08-10 18:44:40,791:INFO:Creating metrics dataframe
2023-08-10 18:44:40,798:INFO:Finalizing model
2023-08-10 18:44:46,202:INFO:Uploading results into container
2023-08-10 18:44:46,207:INFO:Uploading model into container now
2023-08-10 18:44:46,209:INFO:_master_model_container: 12
2023-08-10 18:44:46,209:INFO:_display_container: 7
2023-08-10 18:44:46,216:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:44:46,216:INFO:create_model() successfully completed......................................
2023-08-10 18:44:46,610:INFO:SubProcess create_model() end ==================================
2023-08-10 18:44:46,611:INFO:Creating Dashboard logs
2023-08-10 18:44:46,612:INFO:Model: Bagging Classifier
2023-08-10 18:44:47,481:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__priors': None, 'estimator__var_smoothing': 1e-09, 'estimator': GaussianNB(priors=None, var_smoothing=1e-09), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 18:44:52,847:INFO:Initializing predict_model()
2023-08-10 18:44:52,847:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECD8F310>)
2023-08-10 18:44:52,847:INFO:Checking exceptions
2023-08-10 18:44:52,848:INFO:Preloading libraries
2023-08-10 18:44:56,018:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:44:56,027:INFO:Initializing plot_model()
2023-08-10 18:44:56,027:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmps7wwj8tp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:44:56,027:INFO:Checking exceptions
2023-08-10 18:44:56,035:INFO:Preloading libraries
2023-08-10 18:44:56,039:INFO:Copying training dataset
2023-08-10 18:44:56,039:INFO:Plot type: auc
2023-08-10 18:44:56,761:INFO:Fitting Model
2023-08-10 18:44:56,762:INFO:Scoring test/hold-out set
2023-08-10 18:44:56,860:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmps7wwj8tp\AUC.png'
2023-08-10 18:44:57,898:INFO:Visual Rendered Successfully
2023-08-10 18:44:58,283:INFO:plot_model() successfully completed......................................
2023-08-10 18:45:00,947:INFO:Initializing plot_model()
2023-08-10 18:45:00,948:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmps7wwj8tp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:45:00,948:INFO:Checking exceptions
2023-08-10 18:45:00,958:INFO:Preloading libraries
2023-08-10 18:45:00,960:INFO:Copying training dataset
2023-08-10 18:45:00,960:INFO:Plot type: confusion_matrix
2023-08-10 18:45:02,000:INFO:Fitting Model
2023-08-10 18:45:02,001:INFO:Scoring test/hold-out set
2023-08-10 18:45:02,100:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmps7wwj8tp\Confusion Matrix.png'
2023-08-10 18:45:02,540:INFO:Visual Rendered Successfully
2023-08-10 18:45:02,899:INFO:plot_model() successfully completed......................................
2023-08-10 18:45:19,494:INFO:Initializing plot_model()
2023-08-10 18:45:19,494:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmps7wwj8tp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:45:19,494:INFO:Checking exceptions
2023-08-10 18:45:19,495:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 18:45:19,495:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:45:33,851:INFO:_master_model_container: 12
2023-08-10 18:45:33,851:INFO:_display_container: 7
2023-08-10 18:45:33,867:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:45:33,867:INFO:ensemble_model() successfully completed......................................
2023-08-10 18:45:34,249:INFO:Initializing tune_model()
2023-08-10 18:45:34,250:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>)
2023-08-10 18:45:34,250:INFO:Checking exceptions
2023-08-10 18:45:34,312:INFO:Copying training dataset
2023-08-10 18:45:34,329:INFO:Checking base model
2023-08-10 18:45:34,331:INFO:Base model : Bagging Classifier
2023-08-10 18:45:34,347:INFO:Declaring metric variables
2023-08-10 18:45:34,362:INFO:Defining Hyperparameters
2023-08-10 18:45:34,788:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 18:45:34,788:INFO:Tuning with n_jobs=-1
2023-08-10 18:45:34,788:INFO:Initializing RandomizedSearchCV
2023-08-10 18:46:32,790:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:47:13,753:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:47:14,966:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:47:21,268:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:47:27,244:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:47:28,447:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:47:36,901:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:48:05,862:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:07,184:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:48:17,174:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:18,463:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:48:24,144:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:33,990:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:38,724:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:39,855:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:48:43,553:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:44,651:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:48:48,181:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:52,713:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:48:53,777:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:49:25,704:INFO:best_params: {'actual_estimator__n_estimators': 50}
2023-08-10 18:49:25,710:INFO:Hyperparameter search completed
2023-08-10 18:49:25,711:INFO:SubProcess create_model() called ==================================
2023-08-10 18:49:25,718:INFO:Initializing create_model()
2023-08-10 18:49:25,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EE5E72E20>, model_only=True, return_train_score=True, kwargs={'n_estimators': 50})
2023-08-10 18:49:25,720:INFO:Checking exceptions
2023-08-10 18:49:25,721:INFO:Importing libraries
2023-08-10 18:49:25,721:INFO:Copying training dataset
2023-08-10 18:49:25,741:INFO:Defining folds
2023-08-10 18:49:25,742:INFO:Declaring metric variables
2023-08-10 18:49:25,755:INFO:Importing untrained model
2023-08-10 18:49:25,757:INFO:Declaring custom model
2023-08-10 18:49:25,779:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:49:25,817:INFO:Starting cross validation
2023-08-10 18:49:25,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:49:27,652:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:50:16,446:INFO:Calculating mean and std
2023-08-10 18:50:16,450:INFO:Creating metrics dataframe
2023-08-10 18:50:16,478:INFO:Finalizing model
2023-08-10 18:50:17,432:INFO:Initializing predict_model()
2023-08-10 18:50:17,432:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                                        var_smoothing=1e-09),
                                                                                   max_features=1.0,
                                                                                   max_samples=1.0,
                                                                                   n_estimators=50,
                                                                                   n_jobs=None,
                                                                                   oob_score=False,
                                                                                   random_state=619,
                                                                                   verbose=0,
                                                                                   warm_start=False),
                                                      estimator=GaussianNB(priors=None,
                                                                           var_smoothing=1e-09),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=50,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EEBB2A8B0>)
2023-08-10 18:50:17,433:INFO:Checking exceptions
2023-08-10 18:50:17,433:INFO:Preloading libraries
2023-08-10 18:50:17,434:INFO:Set up data.
2023-08-10 18:50:17,455:INFO:Set up index.
2023-08-10 18:50:24,223:INFO:Uploading results into container
2023-08-10 18:50:24,226:INFO:Uploading model into container now
2023-08-10 18:50:24,228:INFO:_master_model_container: 13
2023-08-10 18:50:24,229:INFO:_display_container: 8
2023-08-10 18:50:24,241:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:50:24,241:INFO:create_model() successfully completed......................................
2023-08-10 18:50:24,750:INFO:SubProcess create_model() end ==================================
2023-08-10 18:50:24,751:INFO:choose_better activated
2023-08-10 18:50:24,766:INFO:SubProcess create_model() called ==================================
2023-08-10 18:50:24,778:INFO:Initializing create_model()
2023-08-10 18:50:24,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:50:24,779:INFO:Checking exceptions
2023-08-10 18:50:24,783:INFO:Importing libraries
2023-08-10 18:50:24,783:INFO:Copying training dataset
2023-08-10 18:50:24,801:INFO:Defining folds
2023-08-10 18:50:24,802:INFO:Declaring metric variables
2023-08-10 18:50:24,802:INFO:Importing untrained model
2023-08-10 18:50:24,803:INFO:Declaring custom model
2023-08-10 18:50:24,808:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:50:24,809:INFO:Starting cross validation
2023-08-10 18:50:24,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:51:17,377:INFO:Calculating mean and std
2023-08-10 18:51:17,379:INFO:Creating metrics dataframe
2023-08-10 18:51:17,387:INFO:Finalizing model
2023-08-10 18:51:21,856:INFO:Uploading results into container
2023-08-10 18:51:21,858:INFO:Uploading model into container now
2023-08-10 18:51:21,859:INFO:_master_model_container: 14
2023-08-10 18:51:21,859:INFO:_display_container: 9
2023-08-10 18:51:21,863:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:51:21,864:INFO:create_model() successfully completed......................................
2023-08-10 18:51:22,212:INFO:SubProcess create_model() end ==================================
2023-08-10 18:51:22,219:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) result for Prec. is 0.2255
2023-08-10 18:51:22,224:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) result for Prec. is 0.229
2023-08-10 18:51:22,228:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) is best model
2023-08-10 18:51:22,228:INFO:choose_better completed
2023-08-10 18:51:22,229:INFO:Creating Dashboard logs
2023-08-10 18:51:22,241:INFO:Model: Bagging Classifier
2023-08-10 18:51:23,070:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__priors': None, 'estimator__var_smoothing': 1e-09, 'estimator': GaussianNB(priors=None, var_smoothing=1e-09), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 18:51:37,447:INFO:Initializing predict_model()
2023-08-10 18:51:37,447:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECD8F3A0>)
2023-08-10 18:51:37,448:INFO:Checking exceptions
2023-08-10 18:51:37,448:INFO:Preloading libraries
2023-08-10 18:51:41,212:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:51:41,220:INFO:Initializing plot_model()
2023-08-10 18:51:41,220:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpdf65qgdy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:51:41,220:INFO:Checking exceptions
2023-08-10 18:51:41,227:INFO:Preloading libraries
2023-08-10 18:51:41,234:INFO:Copying training dataset
2023-08-10 18:51:41,235:INFO:Plot type: auc
2023-08-10 18:51:42,073:INFO:Fitting Model
2023-08-10 18:51:42,074:INFO:Scoring test/hold-out set
2023-08-10 18:51:42,290:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpdf65qgdy\AUC.png'
2023-08-10 18:51:43,120:INFO:Visual Rendered Successfully
2023-08-10 18:51:43,470:INFO:plot_model() successfully completed......................................
2023-08-10 18:51:44,498:INFO:Initializing plot_model()
2023-08-10 18:51:44,498:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpdf65qgdy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:51:44,499:INFO:Checking exceptions
2023-08-10 18:51:44,507:INFO:Preloading libraries
2023-08-10 18:51:44,514:INFO:Copying training dataset
2023-08-10 18:51:44,515:INFO:Plot type: confusion_matrix
2023-08-10 18:51:45,358:INFO:Fitting Model
2023-08-10 18:51:45,359:INFO:Scoring test/hold-out set
2023-08-10 18:51:45,728:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpdf65qgdy\Confusion Matrix.png'
2023-08-10 18:51:46,138:INFO:Visual Rendered Successfully
2023-08-10 18:51:46,479:INFO:plot_model() successfully completed......................................
2023-08-10 18:51:46,991:INFO:Initializing plot_model()
2023-08-10 18:51:46,991:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpdf65qgdy, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:51:46,992:INFO:Checking exceptions
2023-08-10 18:51:46,992:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 18:51:46,993:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:51:57,604:INFO:_master_model_container: 14
2023-08-10 18:51:57,605:INFO:_display_container: 8
2023-08-10 18:51:57,611:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:51:57,611:INFO:tune_model() successfully completed......................................
2023-08-10 18:52:02,717:INFO:Initializing create_model()
2023-08-10 18:52:02,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=dt, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 18:52:02,719:INFO:Checking exceptions
2023-08-10 18:52:02,775:INFO:Importing libraries
2023-08-10 18:52:02,776:INFO:Copying training dataset
2023-08-10 18:52:02,803:INFO:Defining folds
2023-08-10 18:52:02,804:INFO:Declaring metric variables
2023-08-10 18:52:02,819:INFO:Importing untrained model
2023-08-10 18:52:02,837:INFO:Decision Tree Classifier Imported successfully
2023-08-10 18:52:02,886:INFO:Cross validation set to False
2023-08-10 18:52:02,887:INFO:Fitting Model
2023-08-10 18:52:03,324:INFO:Initializing predict_model()
2023-08-10 18:52:03,324:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=619, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECE8AD30>)
2023-08-10 18:52:03,325:INFO:Checking exceptions
2023-08-10 18:52:03,325:INFO:Preloading libraries
2023-08-10 18:52:03,326:INFO:Set up data.
2023-08-10 18:52:03,354:INFO:Set up index.
2023-08-10 18:52:03,974:INFO:Initializing predict_model()
2023-08-10 18:52:03,974:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=619, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECE8AD30>)
2023-08-10 18:52:03,974:INFO:Checking exceptions
2023-08-10 18:52:03,974:INFO:Preloading libraries
2023-08-10 18:52:05,141:INFO:_display_container: 9
2023-08-10 18:52:09,402:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=619, splitter='best')
2023-08-10 18:52:09,402:INFO:create_model() successfully completed......................................
2023-08-10 18:52:10,020:INFO:Initializing ensemble_model()
2023-08-10 18:52:10,020:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=619, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 18:52:10,021:INFO:Checking exceptions
2023-08-10 18:52:10,037:INFO:Importing libraries
2023-08-10 18:52:10,037:INFO:Copying training dataset
2023-08-10 18:52:10,037:INFO:Checking base model
2023-08-10 18:52:10,038:INFO:Base model : Decision Tree Classifier
2023-08-10 18:52:10,039:INFO:Importing untrained ensembler
2023-08-10 18:52:10,039:INFO:Ensemble method set to Bagging
2023-08-10 18:52:10,040:INFO:SubProcess create_model() called ==================================
2023-08-10 18:52:10,043:INFO:Initializing create_model()
2023-08-10 18:52:10,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   random_state=619,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=619, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EE5E72D30>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:52:10,043:INFO:Checking exceptions
2023-08-10 18:52:10,044:INFO:Importing libraries
2023-08-10 18:52:10,044:INFO:Copying training dataset
2023-08-10 18:52:10,068:INFO:Defining folds
2023-08-10 18:52:10,068:INFO:Declaring metric variables
2023-08-10 18:52:10,069:INFO:Importing untrained model
2023-08-10 18:52:10,069:INFO:Declaring custom model
2023-08-10 18:52:10,072:INFO:Bagging Classifier Imported successfully
2023-08-10 18:52:10,073:INFO:Starting cross validation
2023-08-10 18:52:10,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:52:55,568:INFO:Calculating mean and std
2023-08-10 18:52:55,570:INFO:Creating metrics dataframe
2023-08-10 18:52:55,578:INFO:Finalizing model
2023-08-10 18:53:00,882:INFO:Uploading results into container
2023-08-10 18:53:00,884:INFO:Uploading model into container now
2023-08-10 18:53:00,886:INFO:_master_model_container: 15
2023-08-10 18:53:00,886:INFO:_display_container: 10
2023-08-10 18:53:00,896:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:53:00,896:INFO:create_model() successfully completed......................................
2023-08-10 18:53:01,249:INFO:SubProcess create_model() end ==================================
2023-08-10 18:53:01,250:INFO:Creating Dashboard logs
2023-08-10 18:53:01,251:INFO:Model: Bagging Classifier
2023-08-10 18:53:02,151:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 619, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 18:53:09,524:INFO:Initializing predict_model()
2023-08-10 18:53:09,525:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EED0E1B80>)
2023-08-10 18:53:09,525:INFO:Checking exceptions
2023-08-10 18:53:09,525:INFO:Preloading libraries
2023-08-10 18:53:11,626:INFO:SubProcess plot_model() called ==================================
2023-08-10 18:53:11,640:INFO:Initializing plot_model()
2023-08-10 18:53:11,640:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp5_3oao91, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:53:11,641:INFO:Checking exceptions
2023-08-10 18:53:11,649:INFO:Preloading libraries
2023-08-10 18:53:11,653:INFO:Copying training dataset
2023-08-10 18:53:11,654:INFO:Plot type: auc
2023-08-10 18:53:13,891:INFO:Fitting Model
2023-08-10 18:53:13,896:INFO:Scoring test/hold-out set
2023-08-10 18:53:14,219:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp5_3oao91\AUC.png'
2023-08-10 18:53:16,307:INFO:Visual Rendered Successfully
2023-08-10 18:53:16,975:INFO:plot_model() successfully completed......................................
2023-08-10 18:53:17,928:INFO:Initializing plot_model()
2023-08-10 18:53:17,928:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp5_3oao91, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:53:17,930:INFO:Checking exceptions
2023-08-10 18:53:17,942:INFO:Preloading libraries
2023-08-10 18:53:17,958:INFO:Copying training dataset
2023-08-10 18:53:17,959:INFO:Plot type: confusion_matrix
2023-08-10 18:53:19,635:INFO:Fitting Model
2023-08-10 18:53:19,637:INFO:Scoring test/hold-out set
2023-08-10 18:53:19,739:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp5_3oao91\Confusion Matrix.png'
2023-08-10 18:53:20,806:INFO:Visual Rendered Successfully
2023-08-10 18:53:21,433:INFO:plot_model() successfully completed......................................
2023-08-10 18:53:22,041:INFO:Initializing plot_model()
2023-08-10 18:53:22,042:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp5_3oao91, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 18:53:22,042:INFO:Checking exceptions
2023-08-10 18:53:22,044:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 18:53:22,045:INFO:SubProcess plot_model() end ==================================
2023-08-10 18:53:44,471:INFO:_master_model_container: 15
2023-08-10 18:53:44,472:INFO:_display_container: 10
2023-08-10 18:53:44,496:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:53:44,497:INFO:ensemble_model() successfully completed......................................
2023-08-10 18:53:45,197:INFO:Initializing tune_model()
2023-08-10 18:53:45,197:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>)
2023-08-10 18:53:45,198:INFO:Checking exceptions
2023-08-10 18:53:45,318:INFO:Copying training dataset
2023-08-10 18:53:45,348:INFO:Checking base model
2023-08-10 18:53:45,348:INFO:Base model : Bagging Classifier
2023-08-10 18:53:45,378:INFO:Declaring metric variables
2023-08-10 18:53:45,397:INFO:Defining Hyperparameters
2023-08-10 18:53:46,588:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 18:53:46,589:INFO:Tuning with n_jobs=-1
2023-08-10 18:53:46,589:INFO:Initializing RandomizedSearchCV
2023-08-10 18:53:49,656:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:53:49,699:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:54:07,304:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:54:07,516:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:54:07,765:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:54:07,849:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:54:35,344:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:54:36,354:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:54:42,908:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:54:44,043:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:55:07,750:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:55:21,056:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:55:43,025:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:55:53,361:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:55:54,612:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:56:01,840:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:56:03,608:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:56:15,475:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:56:16,631:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:56:26,640:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:56:34,420:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:56:36,346:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:56:41,008:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:56:47,951:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:56:54,834:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:03,384:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:05,177:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:11,638:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:18,035:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:20,013:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:25,925:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:27,925:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:34,185:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:35,829:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:40,583:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:41,986:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:46,167:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:47,388:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:51,268:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:52,632:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:57:56,113:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:57:57,367:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:00,855:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 18:58:02,310:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:31,315:INFO:best_params: {'actual_estimator__n_estimators': 100}
2023-08-10 18:58:31,322:INFO:Hyperparameter search completed
2023-08-10 18:58:31,322:INFO:SubProcess create_model() called ==================================
2023-08-10 18:58:31,351:INFO:Initializing create_model()
2023-08-10 18:58:31,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EEB23DA30>, model_only=True, return_train_score=True, kwargs={'n_estimators': 100})
2023-08-10 18:58:31,353:INFO:Checking exceptions
2023-08-10 18:58:31,354:INFO:Importing libraries
2023-08-10 18:58:31,357:INFO:Copying training dataset
2023-08-10 18:58:31,399:INFO:Defining folds
2023-08-10 18:58:31,399:INFO:Declaring metric variables
2023-08-10 18:58:31,452:INFO:Importing untrained model
2023-08-10 18:58:31,453:INFO:Declaring custom model
2023-08-10 18:58:31,486:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:58:31,559:INFO:Starting cross validation
2023-08-10 18:58:31,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 18:58:36,419:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:36,420:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:36,439:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:36,622:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:47,863:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:48,063:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:48,165:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:48,268:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:49,456:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:49,588:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:49,596:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:58:49,804:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 18:59:21,731:INFO:Calculating mean and std
2023-08-10 18:59:21,737:INFO:Creating metrics dataframe
2023-08-10 18:59:21,771:INFO:Finalizing model
2023-08-10 18:59:24,720:INFO:Initializing predict_model()
2023-08-10 18:59:24,720:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EED0C05E0>)
2023-08-10 18:59:24,721:INFO:Checking exceptions
2023-08-10 18:59:24,721:INFO:Preloading libraries
2023-08-10 18:59:24,722:INFO:Set up data.
2023-08-10 18:59:24,743:INFO:Set up index.
2023-08-10 18:59:29,722:INFO:Uploading results into container
2023-08-10 18:59:29,727:INFO:Uploading model into container now
2023-08-10 18:59:29,731:INFO:_master_model_container: 16
2023-08-10 18:59:29,731:INFO:_display_container: 11
2023-08-10 18:59:29,744:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 18:59:29,745:INFO:create_model() successfully completed......................................
2023-08-10 18:59:30,186:INFO:SubProcess create_model() end ==================================
2023-08-10 18:59:30,187:INFO:choose_better activated
2023-08-10 18:59:30,198:INFO:SubProcess create_model() called ==================================
2023-08-10 18:59:30,211:INFO:Initializing create_model()
2023-08-10 18:59:30,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 18:59:30,211:INFO:Checking exceptions
2023-08-10 18:59:30,216:INFO:Importing libraries
2023-08-10 18:59:30,216:INFO:Copying training dataset
2023-08-10 18:59:30,233:INFO:Defining folds
2023-08-10 18:59:30,233:INFO:Declaring metric variables
2023-08-10 18:59:30,234:INFO:Importing untrained model
2023-08-10 18:59:30,234:INFO:Declaring custom model
2023-08-10 18:59:30,243:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 18:59:30,245:INFO:Starting cross validation
2023-08-10 18:59:30,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 19:00:09,620:INFO:Calculating mean and std
2023-08-10 19:00:09,623:INFO:Creating metrics dataframe
2023-08-10 19:00:09,631:INFO:Finalizing model
2023-08-10 19:00:15,016:INFO:Uploading results into container
2023-08-10 19:00:15,018:INFO:Uploading model into container now
2023-08-10 19:00:15,019:INFO:_master_model_container: 17
2023-08-10 19:00:15,019:INFO:_display_container: 12
2023-08-10 19:00:15,029:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:00:15,030:INFO:create_model() successfully completed......................................
2023-08-10 19:00:15,362:INFO:SubProcess create_model() end ==================================
2023-08-10 19:00:15,373:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) result for Prec. is 0.6282
2023-08-10 19:00:15,383:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) result for Prec. is 0.681
2023-08-10 19:00:15,395:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False) is best model
2023-08-10 19:00:15,395:INFO:choose_better completed
2023-08-10 19:00:15,396:INFO:Creating Dashboard logs
2023-08-10 19:00:15,408:INFO:Model: Bagging Classifier
2023-08-10 19:00:16,270:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 619, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 19:00:22,521:INFO:Initializing predict_model()
2023-08-10 19:00:22,521:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EED0B2430>)
2023-08-10 19:00:22,522:INFO:Checking exceptions
2023-08-10 19:00:22,522:INFO:Preloading libraries
2023-08-10 19:00:24,278:INFO:SubProcess plot_model() called ==================================
2023-08-10 19:00:24,291:INFO:Initializing plot_model()
2023-08-10 19:00:24,291:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpyi5fyt1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:00:24,292:INFO:Checking exceptions
2023-08-10 19:00:24,297:INFO:Preloading libraries
2023-08-10 19:00:24,342:INFO:Copying training dataset
2023-08-10 19:00:24,342:INFO:Plot type: auc
2023-08-10 19:00:25,224:INFO:Fitting Model
2023-08-10 19:00:25,226:INFO:Scoring test/hold-out set
2023-08-10 19:00:25,495:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpyi5fyt1a\AUC.png'
2023-08-10 19:00:26,351:INFO:Visual Rendered Successfully
2023-08-10 19:00:26,697:INFO:plot_model() successfully completed......................................
2023-08-10 19:00:28,893:INFO:Initializing plot_model()
2023-08-10 19:00:28,894:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpyi5fyt1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:00:28,894:INFO:Checking exceptions
2023-08-10 19:00:28,901:INFO:Preloading libraries
2023-08-10 19:00:28,936:INFO:Copying training dataset
2023-08-10 19:00:28,936:INFO:Plot type: confusion_matrix
2023-08-10 19:00:29,647:INFO:Fitting Model
2023-08-10 19:00:29,648:INFO:Scoring test/hold-out set
2023-08-10 19:00:29,850:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpyi5fyt1a\Confusion Matrix.png'
2023-08-10 19:00:30,240:INFO:Visual Rendered Successfully
2023-08-10 19:00:30,565:INFO:plot_model() successfully completed......................................
2023-08-10 19:00:31,155:INFO:Initializing plot_model()
2023-08-10 19:00:31,155:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpyi5fyt1a, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:00:31,156:INFO:Checking exceptions
2023-08-10 19:00:31,157:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 19:00:31,158:INFO:SubProcess plot_model() end ==================================
2023-08-10 19:00:55,417:INFO:_master_model_container: 17
2023-08-10 19:00:55,417:INFO:_display_container: 11
2023-08-10 19:00:55,431:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:00:55,431:INFO:tune_model() successfully completed......................................
2023-08-10 19:01:00,464:INFO:Initializing compare_models()
2023-08-10 19:01:00,465:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, include=[CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, 'include': [CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 19:01:00,465:INFO:Checking exceptions
2023-08-10 19:01:00,474:INFO:Preparing display monitor
2023-08-10 19:01:00,596:INFO:Initializing custom model Bagging Classifier
2023-08-10 19:01:00,597:INFO:Total runtime is 3.383557001749674e-05 minutes
2023-08-10 19:01:00,614:INFO:SubProcess create_model() called ==================================
2023-08-10 19:01:00,637:INFO:Initializing create_model()
2023-08-10 19:01:00,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EE5D60070>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 19:01:00,639:INFO:Checking exceptions
2023-08-10 19:01:00,639:INFO:Importing libraries
2023-08-10 19:01:00,640:INFO:Copying training dataset
2023-08-10 19:01:00,666:INFO:Defining folds
2023-08-10 19:01:00,666:INFO:Declaring metric variables
2023-08-10 19:01:00,687:INFO:Importing untrained model
2023-08-10 19:01:00,688:INFO:Declaring custom model
2023-08-10 19:01:00,713:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 19:01:00,749:INFO:Starting cross validation
2023-08-10 19:01:00,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 19:01:43,271:INFO:Calculating mean and std
2023-08-10 19:01:43,274:INFO:Creating metrics dataframe
2023-08-10 19:01:47,891:INFO:Uploading results into container
2023-08-10 19:01:47,894:INFO:Uploading model into container now
2023-08-10 19:01:47,896:INFO:_master_model_container: 18
2023-08-10 19:01:47,896:INFO:_display_container: 12
2023-08-10 19:01:47,909:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:01:47,910:INFO:create_model() successfully completed......................................
2023-08-10 19:01:48,247:INFO:SubProcess create_model() end ==================================
2023-08-10 19:01:48,247:INFO:Creating metrics dataframe
2023-08-10 19:01:48,280:INFO:Initializing custom model Bagging Classifier
2023-08-10 19:01:48,281:INFO:Total runtime is 0.7947832584381103 minutes
2023-08-10 19:01:48,293:INFO:SubProcess create_model() called ==================================
2023-08-10 19:01:48,301:INFO:Initializing create_model()
2023-08-10 19:01:48,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EE5D60070>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 19:01:48,303:INFO:Checking exceptions
2023-08-10 19:01:48,303:INFO:Importing libraries
2023-08-10 19:01:48,303:INFO:Copying training dataset
2023-08-10 19:01:48,320:INFO:Defining folds
2023-08-10 19:01:48,322:INFO:Declaring metric variables
2023-08-10 19:01:48,337:INFO:Importing untrained model
2023-08-10 19:01:48,338:INFO:Declaring custom model
2023-08-10 19:01:48,354:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 19:01:48,380:INFO:Starting cross validation
2023-08-10 19:01:48,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 19:02:39,862:INFO:Calculating mean and std
2023-08-10 19:02:39,869:INFO:Creating metrics dataframe
2023-08-10 19:02:44,149:INFO:Uploading results into container
2023-08-10 19:02:44,152:INFO:Uploading model into container now
2023-08-10 19:02:44,153:INFO:_master_model_container: 19
2023-08-10 19:02:44,154:INFO:_display_container: 12
2023-08-10 19:02:44,161:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:02:44,161:INFO:create_model() successfully completed......................................
2023-08-10 19:02:44,488:INFO:SubProcess create_model() end ==================================
2023-08-10 19:02:44,489:INFO:Creating metrics dataframe
2023-08-10 19:02:44,525:INFO:Initializing custom model Bagging Classifier
2023-08-10 19:02:44,526:INFO:Total runtime is 1.7322017987569174 minutes
2023-08-10 19:02:44,540:INFO:SubProcess create_model() called ==================================
2023-08-10 19:02:44,569:INFO:Initializing create_model()
2023-08-10 19:02:44,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027EE5D60070>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 19:02:44,570:INFO:Checking exceptions
2023-08-10 19:02:44,570:INFO:Importing libraries
2023-08-10 19:02:44,571:INFO:Copying training dataset
2023-08-10 19:02:44,586:INFO:Defining folds
2023-08-10 19:02:44,586:INFO:Declaring metric variables
2023-08-10 19:02:44,598:INFO:Importing untrained model
2023-08-10 19:02:44,600:INFO:Declaring custom model
2023-08-10 19:02:44,624:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 19:02:44,652:INFO:Starting cross validation
2023-08-10 19:02:44,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 19:03:36,935:INFO:Calculating mean and std
2023-08-10 19:03:36,939:INFO:Creating metrics dataframe
2023-08-10 19:03:43,903:INFO:Uploading results into container
2023-08-10 19:03:43,906:INFO:Uploading model into container now
2023-08-10 19:03:43,907:INFO:_master_model_container: 20
2023-08-10 19:03:43,908:INFO:_display_container: 12
2023-08-10 19:03:43,946:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:03:43,947:INFO:create_model() successfully completed......................................
2023-08-10 19:03:44,405:INFO:SubProcess create_model() end ==================================
2023-08-10 19:03:44,406:INFO:Creating metrics dataframe
2023-08-10 19:03:44,590:INFO:Initializing create_model()
2023-08-10 19:03:44,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 19:03:44,591:INFO:Checking exceptions
2023-08-10 19:03:44,604:INFO:Importing libraries
2023-08-10 19:03:44,604:INFO:Copying training dataset
2023-08-10 19:03:44,622:INFO:Defining folds
2023-08-10 19:03:44,622:INFO:Declaring metric variables
2023-08-10 19:03:44,623:INFO:Importing untrained model
2023-08-10 19:03:44,623:INFO:Declaring custom model
2023-08-10 19:03:44,634:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 19:03:44,680:INFO:Cross validation set to False
2023-08-10 19:03:44,682:INFO:Fitting Model
2023-08-10 19:03:51,890:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:03:51,890:INFO:create_model() successfully completed......................................
2023-08-10 19:03:52,469:INFO:Creating Dashboard logs
2023-08-10 19:03:52,501:INFO:Model: Bagging Classifier
2023-08-10 19:03:53,417:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 619, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 19:03:58,810:INFO:Initializing predict_model()
2023-08-10 19:03:58,811:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDF4B80>)
2023-08-10 19:03:58,812:INFO:Checking exceptions
2023-08-10 19:03:58,812:INFO:Preloading libraries
2023-08-10 19:04:00,385:INFO:SubProcess plot_model() called ==================================
2023-08-10 19:04:00,402:INFO:Initializing plot_model()
2023-08-10 19:04:00,403:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpbai0tzpk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:04:00,403:INFO:Checking exceptions
2023-08-10 19:04:00,416:INFO:Preloading libraries
2023-08-10 19:04:00,635:INFO:Copying training dataset
2023-08-10 19:04:00,635:INFO:Plot type: auc
2023-08-10 19:04:02,138:INFO:Fitting Model
2023-08-10 19:04:02,139:INFO:Scoring test/hold-out set
2023-08-10 19:04:02,499:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpbai0tzpk\AUC.png'
2023-08-10 19:04:03,541:INFO:Visual Rendered Successfully
2023-08-10 19:04:04,192:INFO:plot_model() successfully completed......................................
2023-08-10 19:04:05,025:INFO:Initializing plot_model()
2023-08-10 19:04:05,025:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpbai0tzpk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:04:05,025:INFO:Checking exceptions
2023-08-10 19:04:05,034:INFO:Preloading libraries
2023-08-10 19:04:05,062:INFO:Copying training dataset
2023-08-10 19:04:05,063:INFO:Plot type: confusion_matrix
2023-08-10 19:04:05,956:INFO:Fitting Model
2023-08-10 19:04:05,957:INFO:Scoring test/hold-out set
2023-08-10 19:04:06,167:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpbai0tzpk\Confusion Matrix.png'
2023-08-10 19:04:06,599:INFO:Visual Rendered Successfully
2023-08-10 19:04:07,005:INFO:plot_model() successfully completed......................................
2023-08-10 19:04:07,534:INFO:Initializing plot_model()
2023-08-10 19:04:07,534:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpbai0tzpk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:04:07,534:INFO:Checking exceptions
2023-08-10 19:04:07,535:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 19:04:07,535:INFO:SubProcess plot_model() end ==================================
2023-08-10 19:04:22,035:INFO:Creating Dashboard logs
2023-08-10 19:04:22,049:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 19:04:22,853:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 19:04:22,854:INFO:Logged params: {}
2023-08-10 19:04:36,832:INFO:Creating Dashboard logs
2023-08-10 19:04:36,845:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 19:04:37,661:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 19:04:37,661:INFO:Logged params: {}
2023-08-10 19:04:51,963:INFO:_master_model_container: 20
2023-08-10 19:04:51,963:INFO:_display_container: 12
2023-08-10 19:04:51,974:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:04:51,975:INFO:compare_models() successfully completed......................................
2023-08-10 19:08:41,710:INFO:Initializing plot_model()
2023-08-10 19:08:41,712:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=True)
2023-08-10 19:08:41,712:INFO:Checking exceptions
2023-08-10 19:08:41,730:INFO:Preloading libraries
2023-08-10 19:08:44,511:INFO:Copying training dataset
2023-08-10 19:08:44,511:INFO:Plot type: class_report
2023-08-10 19:08:45,431:INFO:Fitting Model
2023-08-10 19:08:45,433:INFO:Scoring test/hold-out set
2023-08-10 19:08:48,469:INFO:Visual Rendered Successfully
2023-08-10 19:08:48,854:INFO:plot_model() successfully completed......................................
2023-08-10 19:09:47,856:INFO:Initializing predict_model()
2023-08-10 19:09:47,856:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECE1B700>)
2023-08-10 19:09:47,857:INFO:Checking exceptions
2023-08-10 19:09:47,858:INFO:Preloading libraries
2023-08-10 19:10:21,261:INFO:Initializing predict_model()
2023-08-10 19:10:21,262:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDCAB80>)
2023-08-10 19:10:21,262:INFO:Checking exceptions
2023-08-10 19:10:21,263:INFO:Preloading libraries
2023-08-10 19:10:30,729:INFO:Initializing predict_model()
2023-08-10 19:10:30,730:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECE1B670>)
2023-08-10 19:10:30,730:INFO:Checking exceptions
2023-08-10 19:10:30,731:INFO:Preloading libraries
2023-08-10 19:10:46,441:INFO:Initializing predict_model()
2023-08-10 19:10:46,442:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECE1BB80>)
2023-08-10 19:10:46,442:INFO:Checking exceptions
2023-08-10 19:10:46,443:INFO:Preloading libraries
2023-08-10 19:11:32,412:INFO:Initializing plot_model()
2023-08-10 19:11:32,413:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=True)
2023-08-10 19:11:32,413:INFO:Checking exceptions
2023-08-10 19:11:32,428:INFO:Preloading libraries
2023-08-10 19:11:32,481:INFO:Copying training dataset
2023-08-10 19:11:32,482:INFO:Plot type: class_report
2023-08-10 19:11:34,199:INFO:Fitting Model
2023-08-10 19:11:34,201:INFO:Scoring test/hold-out set
2023-08-10 19:11:35,464:INFO:Visual Rendered Successfully
2023-08-10 19:11:35,826:INFO:plot_model() successfully completed......................................
2023-08-10 19:13:09,223:INFO:Initializing predict_model()
2023-08-10 19:13:09,224:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EEB7E3A60>)
2023-08-10 19:13:09,224:INFO:Checking exceptions
2023-08-10 19:13:09,224:INFO:Preloading libraries
2023-08-10 19:13:12,736:INFO:Initializing predict_model()
2023-08-10 19:13:12,737:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDA1430>)
2023-08-10 19:13:12,738:INFO:Checking exceptions
2023-08-10 19:13:12,738:INFO:Preloading libraries
2023-08-10 19:13:19,186:INFO:Initializing predict_model()
2023-08-10 19:13:19,186:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EEB7E3A60>)
2023-08-10 19:13:19,186:INFO:Checking exceptions
2023-08-10 19:13:19,187:INFO:Preloading libraries
2023-08-10 19:13:30,955:INFO:Initializing predict_model()
2023-08-10 19:13:30,956:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDCAB80>)
2023-08-10 19:13:30,957:INFO:Checking exceptions
2023-08-10 19:13:30,957:INFO:Preloading libraries
2023-08-10 19:14:10,465:INFO:Initializing plot_model()
2023-08-10 19:14:10,466:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=True)
2023-08-10 19:14:10,466:INFO:Checking exceptions
2023-08-10 19:14:10,481:INFO:Preloading libraries
2023-08-10 19:14:10,490:INFO:Copying training dataset
2023-08-10 19:14:10,490:INFO:Plot type: class_report
2023-08-10 19:14:12,070:INFO:Fitting Model
2023-08-10 19:14:12,071:INFO:Scoring test/hold-out set
2023-08-10 19:14:13,880:INFO:Visual Rendered Successfully
2023-08-10 19:14:14,284:INFO:plot_model() successfully completed......................................
2023-08-10 19:14:45,420:INFO:Initializing predict_model()
2023-08-10 19:14:45,420:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EED0E14C0>)
2023-08-10 19:14:45,421:INFO:Checking exceptions
2023-08-10 19:14:45,421:INFO:Preloading libraries
2023-08-10 19:15:02,470:INFO:Initializing plot_model()
2023-08-10 19:15:02,470:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=True)
2023-08-10 19:15:02,471:INFO:Checking exceptions
2023-08-10 19:15:02,485:INFO:Preloading libraries
2023-08-10 19:15:02,537:INFO:Copying training dataset
2023-08-10 19:15:02,538:INFO:Plot type: class_report
2023-08-10 19:15:04,039:INFO:Fitting Model
2023-08-10 19:15:04,040:INFO:Scoring test/hold-out set
2023-08-10 19:15:05,712:INFO:Visual Rendered Successfully
2023-08-10 19:15:06,114:INFO:plot_model() successfully completed......................................
2023-08-10 19:15:11,102:INFO:Initializing predict_model()
2023-08-10 19:15:11,103:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=50,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=619,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=50, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECF2BC10>)
2023-08-10 19:15:11,104:INFO:Checking exceptions
2023-08-10 19:15:11,104:INFO:Preloading libraries
2023-08-10 19:15:23,527:INFO:Initializing predict_model()
2023-08-10 19:15:23,527:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EE56784C0>)
2023-08-10 19:15:23,528:INFO:Checking exceptions
2023-08-10 19:15:23,528:INFO:Preloading libraries
2023-08-10 19:15:33,237:INFO:Initializing plot_model()
2023-08-10 19:15:33,238:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=True)
2023-08-10 19:15:33,238:INFO:Checking exceptions
2023-08-10 19:15:33,250:INFO:Preloading libraries
2023-08-10 19:15:33,287:INFO:Copying training dataset
2023-08-10 19:15:33,287:INFO:Plot type: class_report
2023-08-10 19:15:34,100:INFO:Fitting Model
2023-08-10 19:15:34,101:INFO:Scoring test/hold-out set
2023-08-10 19:15:35,344:INFO:Visual Rendered Successfully
2023-08-10 19:15:35,728:INFO:plot_model() successfully completed......................................
2023-08-10 19:15:42,259:INFO:Initializing predict_model()
2023-08-10 19:15:42,260:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EECDA1430>)
2023-08-10 19:15:42,260:INFO:Checking exceptions
2023-08-10 19:15:42,261:INFO:Preloading libraries
2023-08-10 19:16:25,461:INFO:Initializing finalize_model()
2023-08-10 19:16:25,462:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-10 19:16:25,475:INFO:Finalizing CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:16:25,508:INFO:Initializing create_model()
2023-08-10 19:16:25,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-10 19:16:25,509:INFO:Checking exceptions
2023-08-10 19:16:25,515:INFO:Importing libraries
2023-08-10 19:16:25,516:INFO:Copying training dataset
2023-08-10 19:16:25,516:INFO:Defining folds
2023-08-10 19:16:25,517:INFO:Declaring metric variables
2023-08-10 19:16:25,517:INFO:Importing untrained model
2023-08-10 19:16:25,518:INFO:Declaring custom model
2023-08-10 19:16:25,527:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 19:16:25,578:INFO:Cross validation set to False
2023-08-10 19:16:25,578:INFO:Fitting Model
2023-08-10 19:16:31,052:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False)
2023-08-10 19:16:31,053:INFO:create_model() successfully completed......................................
2023-08-10 19:16:31,417:INFO:Creating Dashboard logs
2023-08-10 19:16:31,419:INFO:Model: Bagging Classifier
2023-08-10 19:16:32,397:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 619, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 19:16:36,797:INFO:SubProcess plot_model() called ==================================
2023-08-10 19:16:36,854:INFO:Initializing plot_model()
2023-08-10 19:16:36,854:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpeh_ke_25, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:16:36,855:INFO:Checking exceptions
2023-08-10 19:16:36,861:INFO:Preloading libraries
2023-08-10 19:16:36,907:INFO:Copying training dataset
2023-08-10 19:16:36,908:INFO:Plot type: auc
2023-08-10 19:16:37,665:INFO:Fitting Model
2023-08-10 19:16:37,667:INFO:Scoring test/hold-out set
2023-08-10 19:16:37,901:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpeh_ke_25\AUC.png'
2023-08-10 19:16:38,743:INFO:Visual Rendered Successfully
2023-08-10 19:16:39,091:INFO:plot_model() successfully completed......................................
2023-08-10 19:16:40,325:INFO:Initializing plot_model()
2023-08-10 19:16:40,326:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpeh_ke_25, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:16:40,326:INFO:Checking exceptions
2023-08-10 19:16:40,331:INFO:Preloading libraries
2023-08-10 19:16:40,364:INFO:Copying training dataset
2023-08-10 19:16:40,364:INFO:Plot type: confusion_matrix
2023-08-10 19:16:41,109:INFO:Fitting Model
2023-08-10 19:16:41,110:INFO:Scoring test/hold-out set
2023-08-10 19:16:41,323:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpeh_ke_25\Confusion Matrix.png'
2023-08-10 19:16:41,735:INFO:Visual Rendered Successfully
2023-08-10 19:16:42,078:INFO:plot_model() successfully completed......................................
2023-08-10 19:16:42,705:INFO:Initializing plot_model()
2023-08-10 19:16:42,707:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpeh_ke_25, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:16:42,709:INFO:Checking exceptions
2023-08-10 19:16:42,709:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 19:16:42,709:INFO:SubProcess plot_model() end ==================================
2023-08-10 19:16:52,969:INFO:_master_model_container: 20
2023-08-10 19:16:52,970:INFO:_display_container: 24
2023-08-10 19:16:53,012:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False)
2023-08-10 19:16:53,012:INFO:finalize_model() successfully completed......................................
2023-08-10 19:16:59,200:INFO:Initializing finalize_model()
2023-08-10 19:16:59,201:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-10 19:16:59,212:INFO:Finalizing CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False)
2023-08-10 19:16:59,237:INFO:Initializing create_model()
2023-08-10 19:16:59,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=619,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=100, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=619, verbose=0,
                                     warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-10 19:16:59,239:INFO:Checking exceptions
2023-08-10 19:16:59,244:INFO:Importing libraries
2023-08-10 19:16:59,245:INFO:Copying training dataset
2023-08-10 19:16:59,246:INFO:Defining folds
2023-08-10 19:16:59,246:INFO:Declaring metric variables
2023-08-10 19:16:59,247:INFO:Importing untrained model
2023-08-10 19:16:59,247:INFO:Declaring custom model
2023-08-10 19:16:59,253:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 19:16:59,291:INFO:Cross validation set to False
2023-08-10 19:16:59,291:INFO:Fitting Model
2023-08-10 19:16:59,833:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False)
2023-08-10 19:16:59,834:INFO:create_model() successfully completed......................................
2023-08-10 19:17:00,193:INFO:Creating Dashboard logs
2023-08-10 19:17:00,195:INFO:Model: Bagging Classifier
2023-08-10 19:17:01,009:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 619, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 619, 'verbose': 0, 'warm_start': False}
2023-08-10 19:17:05,439:INFO:SubProcess plot_model() called ==================================
2023-08-10 19:17:05,484:INFO:Initializing plot_model()
2023-08-10 19:17:05,485:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmplg7cmfvh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:17:05,486:INFO:Checking exceptions
2023-08-10 19:17:05,492:INFO:Preloading libraries
2023-08-10 19:17:05,528:INFO:Copying training dataset
2023-08-10 19:17:05,528:INFO:Plot type: auc
2023-08-10 19:17:06,795:INFO:Fitting Model
2023-08-10 19:17:06,797:INFO:Scoring test/hold-out set
2023-08-10 19:17:07,512:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmplg7cmfvh\AUC.png'
2023-08-10 19:17:08,666:INFO:Visual Rendered Successfully
2023-08-10 19:17:09,055:INFO:plot_model() successfully completed......................................
2023-08-10 19:17:10,041:INFO:Initializing plot_model()
2023-08-10 19:17:10,042:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmplg7cmfvh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:17:10,042:INFO:Checking exceptions
2023-08-10 19:17:10,048:INFO:Preloading libraries
2023-08-10 19:17:10,109:INFO:Copying training dataset
2023-08-10 19:17:10,109:INFO:Plot type: confusion_matrix
2023-08-10 19:17:11,046:INFO:Fitting Model
2023-08-10 19:17:11,047:INFO:Scoring test/hold-out set
2023-08-10 19:17:11,317:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmplg7cmfvh\Confusion Matrix.png'
2023-08-10 19:17:12,065:INFO:Visual Rendered Successfully
2023-08-10 19:17:12,528:INFO:plot_model() successfully completed......................................
2023-08-10 19:17:13,140:INFO:Initializing plot_model()
2023-08-10 19:17:13,141:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmplg7cmfvh, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=False)
2023-08-10 19:17:13,141:INFO:Checking exceptions
2023-08-10 19:17:13,142:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 19:17:13,142:INFO:SubProcess plot_model() end ==================================
2023-08-10 19:17:21,974:INFO:_master_model_container: 20
2023-08-10 19:17:21,974:INFO:_display_container: 24
2023-08-10 19:17:22,027:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False)
2023-08-10 19:17:22,028:INFO:finalize_model() successfully completed......................................
2023-08-10 19:17:31,422:INFO:Initializing predict_model()
2023-08-10 19:17:31,422:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EEB7E3A60>)
2023-08-10 19:17:31,423:INFO:Checking exceptions
2023-08-10 19:17:31,423:INFO:Preloading libraries
2023-08-10 19:17:31,431:INFO:Set up data.
2023-08-10 19:17:31,458:INFO:Set up index.
2023-08-10 19:18:01,117:INFO:Initializing plot_model()
2023-08-10 19:18:01,118:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=True)
2023-08-10 19:18:01,118:INFO:Checking exceptions
2023-08-10 19:21:36,285:INFO:Initializing plot_model()
2023-08-10 19:21:36,285:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=619,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=100,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=619,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, system=True)
2023-08-10 19:21:36,287:INFO:Checking exceptions
2023-08-10 19:36:43,038:INFO:Initializing create_model()
2023-08-10 19:36:43,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=lr, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 19:36:43,039:INFO:Checking exceptions
2023-08-10 19:36:43,118:INFO:Importing libraries
2023-08-10 19:36:43,119:INFO:Copying training dataset
2023-08-10 19:36:43,154:INFO:Defining folds
2023-08-10 19:36:43,154:INFO:Declaring metric variables
2023-08-10 19:36:43,175:INFO:Importing untrained model
2023-08-10 19:36:43,204:INFO:Logistic Regression Imported successfully
2023-08-10 19:36:43,326:INFO:Cross validation set to False
2023-08-10 19:36:43,327:INFO:Fitting Model
2023-08-10 19:36:48,049:INFO:Initializing predict_model()
2023-08-10 19:36:48,050:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=619,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EF8178550>)
2023-08-10 19:36:48,050:INFO:Checking exceptions
2023-08-10 19:36:48,051:INFO:Preloading libraries
2023-08-10 19:36:48,052:INFO:Set up data.
2023-08-10 19:36:48,242:INFO:Set up index.
2023-08-10 19:36:50,063:INFO:Initializing predict_model()
2023-08-10 19:36:50,063:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=619,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=619,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027EF6530550>)
2023-08-10 19:36:50,065:INFO:Checking exceptions
2023-08-10 19:36:50,066:INFO:Preloading libraries
2023-08-10 19:36:53,012:INFO:_display_container: 26
2023-08-10 19:37:00,344:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=619, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 19:37:00,345:INFO:create_model() successfully completed......................................
2023-08-10 19:38:05,875:INFO:Initializing tune_model()
2023-08-10 19:38:05,875:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=619, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=100, custom_grid=None, optimize=Bal. Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027EE7C1F220>)
2023-08-10 19:38:05,876:INFO:Checking exceptions
2023-08-10 19:38:05,991:INFO:Copying training dataset
2023-08-10 19:38:06,010:INFO:Checking base model
2023-08-10 19:38:06,010:INFO:Base model : Logistic Regression
2023-08-10 19:38:06,065:INFO:Declaring metric variables
2023-08-10 19:38:06,088:INFO:Defining Hyperparameters
2023-08-10 19:38:07,589:INFO:Tuning with n_jobs=-1
2023-08-10 19:38:07,590:INFO:Initializing RandomizedSearchCV
2023-08-10 19:38:49,943:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 19:38:51,155:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 19:38:52,957:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 19:38:54,336:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 19:39:00,520:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 19:39:26,840:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:39:47,657:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:40:21,007:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:43:25,607:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:43:40,846:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 19:45:11,890:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:46:38,619:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-10 19:46:42,989:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:47:12,267:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 19:47:13,831:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-10 19:47:14,697:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 19:47:36,279:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:47:54,074:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:48:04,010:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:48:48,626:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:49:04,063:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:50:48,749:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:51:31,610:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:51:46,542:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:52:09,840:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:54:02,875:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:55:00,804:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:55:49,000:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:56:01,205:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:56:06,751:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:56:30,319:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:58:25,419:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 19:59:10,573:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:00:08,373:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:01:17,341:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:04:30,086:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:04:40,270:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:07:43,537:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:08:43,164:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:09:32,806:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:09:48,963:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:10:25,675:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:11:32,080:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:11:43,463:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:12:32,954:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:14:32,408:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:14:43,763:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:15:11,453:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:15:35,918:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:16:19,616:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:16:30,278:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:16:35,857:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:17:57,298:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:18:04,629:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:18:11,250:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:19:06,420:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:19:21,952:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:20:00,576:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:21:00,534:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:22:01,752:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:23:26,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 20:23:26,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 20:23:26,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 20:23:26,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-10 20:23:57,455:INFO:PyCaret AnomalyExperiment
2023-08-10 20:23:57,456:INFO:Logging name: anomaly-default-name
2023-08-10 20:23:57,457:INFO:ML Usecase: MLUsecase.ANOMALY
2023-08-10 20:23:57,457:INFO:version 3.0.4
2023-08-10 20:23:57,457:INFO:Initializing setup()
2023-08-10 20:23:57,457:INFO:self.USI: 5336
2023-08-10 20:23:57,457:INFO:self._variable_keys: {'data', '_available_plots', 'exp_name_log', 'seed', 'n_jobs_param', 'gpu_param', 'html_param', 'X', 'USI', 'memory', 'logging_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_id', 'pipeline', 'idx', 'log_plots_param'}
2023-08-10 20:23:57,457:INFO:Checking environment
2023-08-10 20:23:57,457:INFO:python_version: 3.9.13
2023-08-10 20:23:57,457:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 20:23:57,458:INFO:machine: AMD64
2023-08-10 20:23:57,458:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 20:23:57,467:INFO:Memory: svmem(total=7480111104, available=1836593152, percent=75.4, used=5643517952, free=1836593152)
2023-08-10 20:23:57,468:INFO:Physical Core: 4
2023-08-10 20:23:57,468:INFO:Logical Core: 4
2023-08-10 20:23:57,468:INFO:Checking libraries
2023-08-10 20:23:57,468:INFO:System:
2023-08-10 20:23:57,468:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 20:23:57,468:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 20:23:57,468:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 20:23:57,468:INFO:PyCaret required dependencies:
2023-08-10 20:23:57,728:INFO:                 pip: 23.1.2
2023-08-10 20:23:57,728:INFO:          setuptools: 58.1.0
2023-08-10 20:23:57,728:INFO:             pycaret: 3.0.4
2023-08-10 20:23:57,728:INFO:             IPython: 8.13.2
2023-08-10 20:23:57,728:INFO:          ipywidgets: 8.0.7
2023-08-10 20:23:57,729:INFO:                tqdm: 4.65.0
2023-08-10 20:23:57,729:INFO:               numpy: 1.23.5
2023-08-10 20:23:57,729:INFO:              pandas: 1.5.3
2023-08-10 20:23:57,729:INFO:              jinja2: 3.1.2
2023-08-10 20:23:57,729:INFO:               scipy: 1.10.1
2023-08-10 20:23:57,729:INFO:              joblib: 1.2.0
2023-08-10 20:23:57,729:INFO:             sklearn: 1.2.2
2023-08-10 20:23:57,729:INFO:                pyod: 1.1.0
2023-08-10 20:23:57,729:INFO:            imblearn: 0.11.0
2023-08-10 20:23:57,729:INFO:   category_encoders: 2.6.1
2023-08-10 20:23:57,730:INFO:            lightgbm: 4.0.0
2023-08-10 20:23:57,730:INFO:               numba: 0.57.1
2023-08-10 20:23:57,730:INFO:            requests: 2.31.0
2023-08-10 20:23:57,730:INFO:          matplotlib: 3.7.1
2023-08-10 20:23:57,730:INFO:          scikitplot: 0.3.7
2023-08-10 20:23:57,730:INFO:         yellowbrick: 1.5
2023-08-10 20:23:57,730:INFO:              plotly: 5.15.0
2023-08-10 20:23:57,731:INFO:    plotly-resampler: Not installed
2023-08-10 20:23:57,731:INFO:             kaleido: 0.2.1
2023-08-10 20:23:57,731:INFO:           schemdraw: 0.15
2023-08-10 20:23:57,731:INFO:         statsmodels: 0.14.0
2023-08-10 20:23:57,731:INFO:              sktime: 0.20.1
2023-08-10 20:23:57,731:INFO:               tbats: 1.1.3
2023-08-10 20:23:57,731:INFO:            pmdarima: 2.0.3
2023-08-10 20:23:57,731:INFO:              psutil: 5.9.5
2023-08-10 20:23:57,731:INFO:          markupsafe: 2.1.3
2023-08-10 20:23:57,731:INFO:             pickle5: Not installed
2023-08-10 20:23:57,732:INFO:         cloudpickle: 2.2.1
2023-08-10 20:23:57,732:INFO:         deprecation: 2.1.0
2023-08-10 20:23:57,732:INFO:              xxhash: 3.2.0
2023-08-10 20:23:57,732:INFO:           wurlitzer: Not installed
2023-08-10 20:23:57,732:INFO:PyCaret optional dependencies:
2023-08-10 20:23:57,777:INFO:                shap: Not installed
2023-08-10 20:23:57,777:INFO:           interpret: 0.4.2
2023-08-10 20:23:57,777:INFO:                umap: 0.5.3
2023-08-10 20:23:57,777:INFO:    pandas_profiling: Not installed
2023-08-10 20:23:57,777:INFO:  explainerdashboard: Not installed
2023-08-10 20:23:57,777:INFO:             autoviz: Not installed
2023-08-10 20:23:57,778:INFO:           fairlearn: Not installed
2023-08-10 20:23:57,778:INFO:          deepchecks: Not installed
2023-08-10 20:23:57,778:INFO:             xgboost: 1.7.6
2023-08-10 20:23:57,778:INFO:            catboost: Not installed
2023-08-10 20:23:57,778:INFO:              kmodes: Not installed
2023-08-10 20:23:57,778:INFO:             mlxtend: 0.22.0
2023-08-10 20:23:57,778:INFO:       statsforecast: Not installed
2023-08-10 20:23:57,778:INFO:        tune_sklearn: Not installed
2023-08-10 20:23:57,778:INFO:                 ray: Not installed
2023-08-10 20:23:57,778:INFO:            hyperopt: Not installed
2023-08-10 20:23:57,779:INFO:              optuna: Not installed
2023-08-10 20:23:57,779:INFO:               skopt: Not installed
2023-08-10 20:23:57,779:INFO:              mlflow: 2.4.2
2023-08-10 20:23:57,779:INFO:              gradio: Not installed
2023-08-10 20:23:57,779:INFO:             fastapi: Not installed
2023-08-10 20:23:57,779:INFO:             uvicorn: Not installed
2023-08-10 20:23:57,779:INFO:              m2cgen: Not installed
2023-08-10 20:23:57,779:INFO:           evidently: Not installed
2023-08-10 20:23:57,779:INFO:               fugue: Not installed
2023-08-10 20:23:57,779:INFO:           streamlit: 1.25.0
2023-08-10 20:23:57,780:INFO:             prophet: Not installed
2023-08-10 20:23:57,780:INFO:None
2023-08-10 20:23:57,780:INFO:Set up data.
2023-08-10 20:23:57,799:INFO:Set up index.
2023-08-10 20:23:57,799:INFO:Assigning column types.
2023-08-10 20:23:57,810:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-08-10 20:24:00,753:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-08-10 20:24:00,760:INFO:Preparing preprocessing pipeline...
2023-08-10 20:24:00,761:INFO:Set up simple imputation.
2023-08-10 20:24:00,767:INFO:Set up encoding of categorical features.
2023-08-10 20:24:00,912:INFO:Finished creating preprocessing pipeline.
2023-08-10 20:24:00,937:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount', 'Churn'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['PreferedOrderCat',
                                             'MaritalStatus'],
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-08-10 20:24:00,937:INFO:Creating final display dataframe.
2023-08-10 20:24:00,987:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  6764
1        Original data shape            (3941, 11)
2     Transformed data shape            (3941, 17)
3           Numeric features                     9
4       Categorical features                     2
5   Rows with missing values                 14.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  anomaly-default-name
16                       USI                  5336
2023-08-10 20:24:00,992:INFO:setup() successfully completed in 8.12s...............
2023-08-10 20:24:00,992:INFO:Initializing create_model()
2023-08-10 20:24:00,992:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000017C2234AE20>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-08-10 20:24:00,993:INFO:Checking exceptions
2023-08-10 20:24:01,032:INFO:Importing untrained model
2023-08-10 20:24:01,034:INFO:Isolation Forest Imported successfully
2023-08-10 20:24:01,037:INFO:Fitting Model
2023-08-10 20:24:03,142:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=6764, verbose=0)
2023-08-10 20:24:03,142:INFO:create_models() successfully completed......................................
2023-08-10 20:24:03,142:INFO:Uploading results into container
2023-08-10 20:24:03,142:INFO:Uploading model into container now
2023-08-10 20:24:03,143:INFO:_master_model_container: 1
2023-08-10 20:24:03,143:INFO:_display_container: 1
2023-08-10 20:24:03,143:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=6764, verbose=0)
2023-08-10 20:24:03,144:INFO:create_model() successfully completed......................................
2023-08-10 20:24:07,690:INFO:Initializing plot_model()
2023-08-10 20:24:07,690:INFO:plot_model(plot=umap, fold=None, verbose=True, display=None, display_format=None, estimator=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=6764, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=0.7, self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000017C2234AE20>, system=True)
2023-08-10 20:24:07,690:INFO:Checking exceptions
2023-08-10 20:24:14,927:INFO:Preloading libraries
2023-08-10 20:24:14,983:INFO:Copying training dataset
2023-08-10 20:24:14,984:INFO:Plot type: umap
2023-08-10 20:24:14,986:INFO:SubProcess assign_model() called ==================================
2023-08-10 20:24:14,989:INFO:Initializing assign_model()
2023-08-10 20:24:14,990:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000017C2234AE20>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=6764, verbose=0), transformation=True, score=False, verbose=False)
2023-08-10 20:24:14,990:INFO:Checking exceptions
2023-08-10 20:24:14,991:INFO:Determining Trained Model
2023-08-10 20:24:14,993:INFO:Trained Model : Isolation Forest
2023-08-10 20:24:14,993:INFO:Copying data
2023-08-10 20:24:15,055:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-08-10 20:24:15,058:INFO:(3941, 18)
2023-08-10 20:24:15,058:INFO:assign_model() successfully completed......................................
2023-08-10 20:24:15,059:INFO:SubProcess assign_model() end ==================================
2023-08-10 20:24:15,075:INFO:Soft dependency imported: umap: 0.5.3
2023-08-10 20:24:34,544:INFO:Fitting UMAP()
2023-08-10 20:25:46,406:INFO:Rendering Visual
2023-08-10 20:25:50,528:INFO:Visual Rendered Successfully
2023-08-10 20:25:50,917:INFO:plot_model() successfully completed......................................
2023-08-10 20:25:51,140:INFO:Initializing assign_model()
2023-08-10 20:25:51,140:INFO:assign_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x0000017C2234AE20>, model=IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=6764, verbose=0), transformation=False, score=True, verbose=True)
2023-08-10 20:25:51,141:INFO:Checking exceptions
2023-08-10 20:25:51,141:INFO:Determining Trained Model
2023-08-10 20:25:51,142:INFO:Trained Model : Isolation Forest
2023-08-10 20:25:51,143:INFO:Copying data
2023-08-10 20:25:51,151:INFO:(3941, 13)
2023-08-10 20:25:51,152:INFO:assign_model() successfully completed......................................
2023-08-10 20:25:58,161:INFO:PyCaret ClassificationExperiment
2023-08-10 20:25:58,162:INFO:Logging name: Customer Churn
2023-08-10 20:25:58,162:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-10 20:25:58,162:INFO:version 3.0.4
2023-08-10 20:25:58,162:INFO:Initializing setup()
2023-08-10 20:25:58,162:INFO:self.USI: 7adc
2023-08-10 20:25:58,162:INFO:self._variable_keys: {'y', 'fold_generator', 'X_train', 'data', '_available_plots', 'exp_name_log', 'seed', 'target_param', 'n_jobs_param', 'gpu_param', 'html_param', 'fold_shuffle_param', 'X', 'fix_imbalance', 'is_multiclass', 'USI', 'y_test', 'memory', 'logging_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_id', 'pipeline', 'idx', 'y_train', 'fold_groups_param', 'X_test', 'log_plots_param'}
2023-08-10 20:25:58,162:INFO:Checking environment
2023-08-10 20:25:58,163:INFO:python_version: 3.9.13
2023-08-10 20:25:58,163:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-10 20:25:58,163:INFO:machine: AMD64
2023-08-10 20:25:58,163:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-10 20:25:58,172:INFO:Memory: svmem(total=7480111104, available=1401085952, percent=81.3, used=6079025152, free=1401085952)
2023-08-10 20:25:58,173:INFO:Physical Core: 4
2023-08-10 20:25:58,173:INFO:Logical Core: 4
2023-08-10 20:25:58,173:INFO:Checking libraries
2023-08-10 20:25:58,173:INFO:System:
2023-08-10 20:25:58,173:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-10 20:25:58,173:INFO:executable: c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-10 20:25:58,174:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-10 20:25:58,174:INFO:PyCaret required dependencies:
2023-08-10 20:25:58,174:INFO:                 pip: 23.1.2
2023-08-10 20:25:58,174:INFO:          setuptools: 58.1.0
2023-08-10 20:25:58,174:INFO:             pycaret: 3.0.4
2023-08-10 20:25:58,174:INFO:             IPython: 8.13.2
2023-08-10 20:25:58,175:INFO:          ipywidgets: 8.0.7
2023-08-10 20:25:58,175:INFO:                tqdm: 4.65.0
2023-08-10 20:25:58,175:INFO:               numpy: 1.23.5
2023-08-10 20:25:58,175:INFO:              pandas: 1.5.3
2023-08-10 20:25:58,175:INFO:              jinja2: 3.1.2
2023-08-10 20:25:58,175:INFO:               scipy: 1.10.1
2023-08-10 20:25:58,175:INFO:              joblib: 1.2.0
2023-08-10 20:25:58,175:INFO:             sklearn: 1.2.2
2023-08-10 20:25:58,175:INFO:                pyod: 1.1.0
2023-08-10 20:25:58,176:INFO:            imblearn: 0.11.0
2023-08-10 20:25:58,176:INFO:   category_encoders: 2.6.1
2023-08-10 20:25:58,176:INFO:            lightgbm: 4.0.0
2023-08-10 20:25:58,176:INFO:               numba: 0.57.1
2023-08-10 20:25:58,176:INFO:            requests: 2.31.0
2023-08-10 20:25:58,176:INFO:          matplotlib: 3.7.1
2023-08-10 20:25:58,176:INFO:          scikitplot: 0.3.7
2023-08-10 20:25:58,176:INFO:         yellowbrick: 1.5
2023-08-10 20:25:58,176:INFO:              plotly: 5.15.0
2023-08-10 20:25:58,176:INFO:    plotly-resampler: Not installed
2023-08-10 20:25:58,177:INFO:             kaleido: 0.2.1
2023-08-10 20:25:58,177:INFO:           schemdraw: 0.15
2023-08-10 20:25:58,177:INFO:         statsmodels: 0.14.0
2023-08-10 20:25:58,177:INFO:              sktime: 0.20.1
2023-08-10 20:25:58,177:INFO:               tbats: 1.1.3
2023-08-10 20:25:58,177:INFO:            pmdarima: 2.0.3
2023-08-10 20:25:58,177:INFO:              psutil: 5.9.5
2023-08-10 20:25:58,177:INFO:          markupsafe: 2.1.3
2023-08-10 20:25:58,177:INFO:             pickle5: Not installed
2023-08-10 20:25:58,177:INFO:         cloudpickle: 2.2.1
2023-08-10 20:25:58,178:INFO:         deprecation: 2.1.0
2023-08-10 20:25:58,178:INFO:              xxhash: 3.2.0
2023-08-10 20:25:58,178:INFO:           wurlitzer: Not installed
2023-08-10 20:25:58,178:INFO:PyCaret optional dependencies:
2023-08-10 20:25:58,178:INFO:                shap: Not installed
2023-08-10 20:25:58,178:INFO:           interpret: 0.4.2
2023-08-10 20:25:58,178:INFO:                umap: 0.5.3
2023-08-10 20:25:58,178:INFO:    pandas_profiling: Not installed
2023-08-10 20:25:58,178:INFO:  explainerdashboard: Not installed
2023-08-10 20:25:58,179:INFO:             autoviz: Not installed
2023-08-10 20:25:58,179:INFO:           fairlearn: Not installed
2023-08-10 20:25:58,179:INFO:          deepchecks: Not installed
2023-08-10 20:25:58,179:INFO:             xgboost: 1.7.6
2023-08-10 20:25:58,179:INFO:            catboost: Not installed
2023-08-10 20:25:58,179:INFO:              kmodes: Not installed
2023-08-10 20:25:58,179:INFO:             mlxtend: 0.22.0
2023-08-10 20:25:58,179:INFO:       statsforecast: Not installed
2023-08-10 20:25:58,179:INFO:        tune_sklearn: Not installed
2023-08-10 20:25:58,179:INFO:                 ray: Not installed
2023-08-10 20:25:58,180:INFO:            hyperopt: Not installed
2023-08-10 20:25:58,180:INFO:              optuna: Not installed
2023-08-10 20:25:58,180:INFO:               skopt: Not installed
2023-08-10 20:25:58,180:INFO:              mlflow: 2.4.2
2023-08-10 20:25:58,180:INFO:              gradio: Not installed
2023-08-10 20:25:58,180:INFO:             fastapi: Not installed
2023-08-10 20:25:58,180:INFO:             uvicorn: Not installed
2023-08-10 20:25:58,180:INFO:              m2cgen: Not installed
2023-08-10 20:25:58,180:INFO:           evidently: Not installed
2023-08-10 20:25:58,180:INFO:               fugue: Not installed
2023-08-10 20:25:58,181:INFO:           streamlit: 1.25.0
2023-08-10 20:25:58,181:INFO:             prophet: Not installed
2023-08-10 20:25:58,181:INFO:None
2023-08-10 20:25:58,181:INFO:Set up data.
2023-08-10 20:25:58,206:INFO:Set up train/test split.
2023-08-10 20:25:58,224:INFO:Set up index.
2023-08-10 20:25:58,224:INFO:Set up folding strategy.
2023-08-10 20:25:58,225:INFO:Assigning column types.
2023-08-10 20:25:58,239:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-10 20:25:58,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 20:25:58,402:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 20:25:58,525:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:25:58,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:25:58,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-10 20:25:58,697:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 20:25:58,795:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:25:58,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:25:58,806:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-10 20:25:58,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 20:25:59,061:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:25:59,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:25:59,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-10 20:25:59,326:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:25:59,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:25:59,339:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-10 20:25:59,592:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:25:59,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:25:59,856:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:25:59,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:25:59,869:INFO:Preparing preprocessing pipeline...
2023-08-10 20:25:59,872:INFO:Set up simple imputation.
2023-08-10 20:25:59,880:INFO:Set up encoding of categorical features.
2023-08-10 20:25:59,881:INFO:Set up removing outliers.
2023-08-10 20:26:00,179:INFO:Finished creating preprocessing pipeline.
2023-08-10 20:26:00,201:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 20:26:00,202:INFO:Creating final display dataframe.
2023-08-10 20:26:04,925:INFO:Setup _display_container:                     Description            Value
0                    Session id             1296
1                        Target            Churn
2                   Target type           Binary
3           Original data shape       (2615, 11)
4        Transformed data shape       (2523, 17)
5   Transformed train set shape       (1738, 17)
6    Transformed test set shape        (785, 17)
7              Numeric features                8
8          Categorical features                2
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15              Remove outliers          iforest
16           Outliers threshold             0.05
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment    DagshubLogger
22              Experiment Name   Customer Churn
23                          USI             7adc
2023-08-10 20:26:05,316:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:26:05,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:26:05,603:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:26:05,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:26:05,617:INFO:Logging experiment in loggers
2023-08-10 20:26:24,977:INFO:SubProcess save_model() called ==================================
2023-08-10 20:26:25,020:INFO:Initializing save_model()
2023-08-10 20:26:25,021:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05)))],
         verbose=False), model_name=C:\Users\HP\AppData\Local\Temp\tmpqmig4t56\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-10 20:26:25,021:INFO:Adding model into prep_pipe
2023-08-10 20:26:25,022:WARNING:Only Model saved as it was a pipeline.
2023-08-10 20:26:25,184:INFO:C:\Users\HP\AppData\Local\Temp\tmpqmig4t56\Transformation Pipeline.pkl saved in current working directory
2023-08-10 20:26:25,203:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 20:26:25,203:INFO:save_model() successfully completed......................................
2023-08-10 20:26:25,555:INFO:SubProcess save_model() end ==================================
2023-08-10 20:26:38,934:INFO:setup() successfully completed in 12.43s...............
2023-08-10 20:26:39,279:INFO:Initializing get_config()
2023-08-10 20:26:39,280:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, variable=pipeline)
2023-08-10 20:26:39,304:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=OneHotEncoder(cols=['PreferedOrderCat',
                                                                    'MaritalStatus'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05)))],
         verbose=False)
2023-08-10 20:26:39,304:INFO:get_config() successfully completed......................................
2023-08-10 20:26:40,602:INFO:gpu_param set to False
2023-08-10 20:26:40,945:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:26:40,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:26:41,260:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-10 20:26:41,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-10 20:26:41,453:INFO:Initializing compare_models()
2023-08-10 20:26:41,454:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, include=['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt', 'nb'], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, 'include': ['ada', 'gbc', 'xgboost', 'rf', 'lr', 'knn', 'dt', 'nb'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 20:26:41,455:INFO:Checking exceptions
2023-08-10 20:26:41,471:INFO:Preparing display monitor
2023-08-10 20:26:41,599:INFO:Initializing Ada Boost Classifier
2023-08-10 20:26:41,599:INFO:Total runtime is 0.0 minutes
2023-08-10 20:26:41,611:INFO:SubProcess create_model() called ==================================
2023-08-10 20:26:41,613:INFO:Initializing create_model()
2023-08-10 20:26:41,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:26:41,615:INFO:Checking exceptions
2023-08-10 20:26:41,616:INFO:Importing libraries
2023-08-10 20:26:41,616:INFO:Copying training dataset
2023-08-10 20:26:41,637:INFO:Defining folds
2023-08-10 20:26:41,637:INFO:Declaring metric variables
2023-08-10 20:26:41,649:INFO:Importing untrained model
2023-08-10 20:26:41,661:INFO:Ada Boost Classifier Imported successfully
2023-08-10 20:26:41,690:INFO:Starting cross validation
2023-08-10 20:26:41,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:26:49,873:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:26:49,885:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:26:49,933:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:26:50,027:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:27:03,501:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:27:03,539:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:27:03,609:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:27:03,749:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:27:07,339:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:27:07,363:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:27:07,375:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:27:07,555:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:27:17,801:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:27:17,939:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-10 20:27:47,838:INFO:Calculating mean and std
2023-08-10 20:27:47,841:INFO:Creating metrics dataframe
2023-08-10 20:27:53,567:INFO:Uploading results into container
2023-08-10 20:27:53,570:INFO:Uploading model into container now
2023-08-10 20:27:53,571:INFO:_master_model_container: 1
2023-08-10 20:27:53,571:INFO:_display_container: 2
2023-08-10 20:27:53,572:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1296)
2023-08-10 20:27:53,573:INFO:create_model() successfully completed......................................
2023-08-10 20:27:53,908:INFO:SubProcess create_model() end ==================================
2023-08-10 20:27:53,909:INFO:Creating metrics dataframe
2023-08-10 20:27:53,947:INFO:Initializing Gradient Boosting Classifier
2023-08-10 20:27:53,948:INFO:Total runtime is 1.2057936708132426 minutes
2023-08-10 20:27:53,960:INFO:SubProcess create_model() called ==================================
2023-08-10 20:27:53,962:INFO:Initializing create_model()
2023-08-10 20:27:53,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:27:53,962:INFO:Checking exceptions
2023-08-10 20:27:53,963:INFO:Importing libraries
2023-08-10 20:27:53,964:INFO:Copying training dataset
2023-08-10 20:27:53,983:INFO:Defining folds
2023-08-10 20:27:53,984:INFO:Declaring metric variables
2023-08-10 20:27:54,003:INFO:Importing untrained model
2023-08-10 20:27:54,020:INFO:Gradient Boosting Classifier Imported successfully
2023-08-10 20:27:54,050:INFO:Starting cross validation
2023-08-10 20:27:54,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:28:48,990:INFO:Calculating mean and std
2023-08-10 20:28:48,995:INFO:Creating metrics dataframe
2023-08-10 20:28:54,468:INFO:Uploading results into container
2023-08-10 20:28:54,470:INFO:Uploading model into container now
2023-08-10 20:28:54,472:INFO:_master_model_container: 2
2023-08-10 20:28:54,473:INFO:_display_container: 2
2023-08-10 20:28:54,476:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1296, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-10 20:28:54,477:INFO:create_model() successfully completed......................................
2023-08-10 20:28:54,809:INFO:SubProcess create_model() end ==================================
2023-08-10 20:28:54,809:INFO:Creating metrics dataframe
2023-08-10 20:28:54,845:INFO:Initializing Extreme Gradient Boosting
2023-08-10 20:28:54,846:INFO:Total runtime is 2.2207769831021626 minutes
2023-08-10 20:28:54,863:INFO:SubProcess create_model() called ==================================
2023-08-10 20:28:54,864:INFO:Initializing create_model()
2023-08-10 20:28:54,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:28:54,864:INFO:Checking exceptions
2023-08-10 20:28:54,865:INFO:Importing libraries
2023-08-10 20:28:54,865:INFO:Copying training dataset
2023-08-10 20:28:54,883:INFO:Defining folds
2023-08-10 20:28:54,884:INFO:Declaring metric variables
2023-08-10 20:28:54,897:INFO:Importing untrained model
2023-08-10 20:28:54,927:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 20:28:54,994:INFO:Starting cross validation
2023-08-10 20:28:55,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:29:47,514:INFO:Calculating mean and std
2023-08-10 20:29:47,518:INFO:Creating metrics dataframe
2023-08-10 20:29:53,174:INFO:Uploading results into container
2023-08-10 20:29:53,178:INFO:Uploading model into container now
2023-08-10 20:29:53,180:INFO:_master_model_container: 3
2023-08-10 20:29:53,181:INFO:_display_container: 2
2023-08-10 20:29:53,183:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 20:29:53,183:INFO:create_model() successfully completed......................................
2023-08-10 20:29:53,514:INFO:SubProcess create_model() end ==================================
2023-08-10 20:29:53,515:INFO:Creating metrics dataframe
2023-08-10 20:29:53,551:INFO:Initializing Random Forest Classifier
2023-08-10 20:29:53,552:INFO:Total runtime is 3.1992103060086565 minutes
2023-08-10 20:29:53,565:INFO:SubProcess create_model() called ==================================
2023-08-10 20:29:53,566:INFO:Initializing create_model()
2023-08-10 20:29:53,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:29:53,567:INFO:Checking exceptions
2023-08-10 20:29:53,568:INFO:Importing libraries
2023-08-10 20:29:53,568:INFO:Copying training dataset
2023-08-10 20:29:53,593:INFO:Defining folds
2023-08-10 20:29:53,593:INFO:Declaring metric variables
2023-08-10 20:29:53,618:INFO:Importing untrained model
2023-08-10 20:29:53,642:INFO:Random Forest Classifier Imported successfully
2023-08-10 20:29:53,698:INFO:Starting cross validation
2023-08-10 20:29:53,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:30:08,134:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:30:08,231:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:30:08,664:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:30:09,276:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:30:09,358:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:30:09,782:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:30:10,565:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:30:51,211:INFO:Calculating mean and std
2023-08-10 20:30:51,215:INFO:Creating metrics dataframe
2023-08-10 20:30:56,861:INFO:Uploading results into container
2023-08-10 20:30:56,863:INFO:Uploading model into container now
2023-08-10 20:30:56,864:INFO:_master_model_container: 4
2023-08-10 20:30:56,864:INFO:_display_container: 2
2023-08-10 20:30:56,868:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1296, verbose=0, warm_start=False)
2023-08-10 20:30:56,870:INFO:create_model() successfully completed......................................
2023-08-10 20:30:57,208:INFO:SubProcess create_model() end ==================================
2023-08-10 20:30:57,208:INFO:Creating metrics dataframe
2023-08-10 20:30:57,246:INFO:Initializing Logistic Regression
2023-08-10 20:30:57,246:INFO:Total runtime is 4.260777052243551 minutes
2023-08-10 20:30:57,261:INFO:SubProcess create_model() called ==================================
2023-08-10 20:30:57,261:INFO:Initializing create_model()
2023-08-10 20:30:57,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:30:57,263:INFO:Checking exceptions
2023-08-10 20:30:57,263:INFO:Importing libraries
2023-08-10 20:30:57,263:INFO:Copying training dataset
2023-08-10 20:30:57,288:INFO:Defining folds
2023-08-10 20:30:57,288:INFO:Declaring metric variables
2023-08-10 20:30:57,305:INFO:Importing untrained model
2023-08-10 20:30:57,319:INFO:Logistic Regression Imported successfully
2023-08-10 20:30:57,346:INFO:Starting cross validation
2023-08-10 20:30:57,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:31:53,365:INFO:Calculating mean and std
2023-08-10 20:31:53,369:INFO:Creating metrics dataframe
2023-08-10 20:31:59,107:INFO:Uploading results into container
2023-08-10 20:31:59,109:INFO:Uploading model into container now
2023-08-10 20:31:59,111:INFO:_master_model_container: 5
2023-08-10 20:31:59,111:INFO:_display_container: 2
2023-08-10 20:31:59,113:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 20:31:59,114:INFO:create_model() successfully completed......................................
2023-08-10 20:31:59,444:INFO:SubProcess create_model() end ==================================
2023-08-10 20:31:59,446:INFO:Creating metrics dataframe
2023-08-10 20:31:59,485:INFO:Initializing K Neighbors Classifier
2023-08-10 20:31:59,485:INFO:Total runtime is 5.298093831539155 minutes
2023-08-10 20:31:59,500:INFO:SubProcess create_model() called ==================================
2023-08-10 20:31:59,500:INFO:Initializing create_model()
2023-08-10 20:31:59,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:31:59,501:INFO:Checking exceptions
2023-08-10 20:31:59,502:INFO:Importing libraries
2023-08-10 20:31:59,502:INFO:Copying training dataset
2023-08-10 20:31:59,521:INFO:Defining folds
2023-08-10 20:31:59,522:INFO:Declaring metric variables
2023-08-10 20:31:59,536:INFO:Importing untrained model
2023-08-10 20:31:59,552:INFO:K Neighbors Classifier Imported successfully
2023-08-10 20:31:59,578:INFO:Starting cross validation
2023-08-10 20:31:59,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:32:54,874:INFO:Calculating mean and std
2023-08-10 20:32:54,880:INFO:Creating metrics dataframe
2023-08-10 20:33:01,281:INFO:Uploading results into container
2023-08-10 20:33:01,283:INFO:Uploading model into container now
2023-08-10 20:33:01,284:INFO:_master_model_container: 6
2023-08-10 20:33:01,285:INFO:_display_container: 2
2023-08-10 20:33:01,286:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-10 20:33:01,286:INFO:create_model() successfully completed......................................
2023-08-10 20:33:01,637:INFO:SubProcess create_model() end ==================================
2023-08-10 20:33:01,638:INFO:Creating metrics dataframe
2023-08-10 20:33:01,700:INFO:Initializing Decision Tree Classifier
2023-08-10 20:33:01,701:INFO:Total runtime is 6.335026872158052 minutes
2023-08-10 20:33:01,718:INFO:SubProcess create_model() called ==================================
2023-08-10 20:33:01,719:INFO:Initializing create_model()
2023-08-10 20:33:01,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:33:01,720:INFO:Checking exceptions
2023-08-10 20:33:01,720:INFO:Importing libraries
2023-08-10 20:33:01,721:INFO:Copying training dataset
2023-08-10 20:33:01,749:INFO:Defining folds
2023-08-10 20:33:01,750:INFO:Declaring metric variables
2023-08-10 20:33:01,764:INFO:Importing untrained model
2023-08-10 20:33:01,804:INFO:Decision Tree Classifier Imported successfully
2023-08-10 20:33:01,840:INFO:Starting cross validation
2023-08-10 20:33:01,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:33:54,317:INFO:Calculating mean and std
2023-08-10 20:33:54,321:INFO:Creating metrics dataframe
2023-08-10 20:34:00,365:INFO:Uploading results into container
2023-08-10 20:34:00,367:INFO:Uploading model into container now
2023-08-10 20:34:00,368:INFO:_master_model_container: 7
2023-08-10 20:34:00,369:INFO:_display_container: 2
2023-08-10 20:34:00,370:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1296, splitter='best')
2023-08-10 20:34:00,370:INFO:create_model() successfully completed......................................
2023-08-10 20:34:00,862:INFO:SubProcess create_model() end ==================================
2023-08-10 20:34:00,863:INFO:Creating metrics dataframe
2023-08-10 20:34:00,912:INFO:Initializing Naive Bayes
2023-08-10 20:34:00,913:INFO:Total runtime is 7.32189372777939 minutes
2023-08-10 20:34:00,927:INFO:SubProcess create_model() called ==================================
2023-08-10 20:34:00,927:INFO:Initializing create_model()
2023-08-10 20:34:00,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C284BBAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:34:00,929:INFO:Checking exceptions
2023-08-10 20:34:00,929:INFO:Importing libraries
2023-08-10 20:34:00,930:INFO:Copying training dataset
2023-08-10 20:34:00,959:INFO:Defining folds
2023-08-10 20:34:00,960:INFO:Declaring metric variables
2023-08-10 20:34:00,977:INFO:Importing untrained model
2023-08-10 20:34:01,002:INFO:Naive Bayes Imported successfully
2023-08-10 20:34:01,061:INFO:Starting cross validation
2023-08-10 20:34:01,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:34:57,493:INFO:Calculating mean and std
2023-08-10 20:34:57,497:INFO:Creating metrics dataframe
2023-08-10 20:35:05,225:INFO:Uploading results into container
2023-08-10 20:35:05,228:INFO:Uploading model into container now
2023-08-10 20:35:05,232:INFO:_master_model_container: 8
2023-08-10 20:35:05,232:INFO:_display_container: 2
2023-08-10 20:35:05,233:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 20:35:05,233:INFO:create_model() successfully completed......................................
2023-08-10 20:35:05,646:INFO:SubProcess create_model() end ==================================
2023-08-10 20:35:05,647:INFO:Creating metrics dataframe
2023-08-10 20:35:05,752:INFO:Initializing create_model()
2023-08-10 20:35:05,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:35:05,754:INFO:Checking exceptions
2023-08-10 20:35:05,762:INFO:Importing libraries
2023-08-10 20:35:05,763:INFO:Copying training dataset
2023-08-10 20:35:05,783:INFO:Defining folds
2023-08-10 20:35:05,783:INFO:Declaring metric variables
2023-08-10 20:35:05,784:INFO:Importing untrained model
2023-08-10 20:35:05,785:INFO:Declaring custom model
2023-08-10 20:35:05,791:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 20:35:05,923:INFO:Cross validation set to False
2023-08-10 20:35:05,923:INFO:Fitting Model
2023-08-10 20:35:12,762:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 20:35:12,762:INFO:create_model() successfully completed......................................
2023-08-10 20:35:13,243:INFO:Creating Dashboard logs
2023-08-10 20:35:13,280:INFO:Model: Extreme Gradient Boosting
2023-08-10 20:35:14,262:INFO:Logged params: {'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': -1, 'num_parallel_tree': None, 'predictor': None, 'random_state': 1296, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2023-08-10 20:35:27,999:INFO:Initializing predict_model()
2023-08-10 20:35:27,999:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C201DD1F0>)
2023-08-10 20:35:27,999:INFO:Checking exceptions
2023-08-10 20:35:27,999:INFO:Preloading libraries
2023-08-10 20:35:29,488:INFO:SubProcess plot_model() called ==================================
2023-08-10 20:35:29,494:INFO:Initializing plot_model()
2023-08-10 20:35:29,494:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpz2255xug, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:35:29,495:INFO:Checking exceptions
2023-08-10 20:35:29,507:INFO:Preloading libraries
2023-08-10 20:35:29,527:INFO:Copying training dataset
2023-08-10 20:35:29,528:INFO:Plot type: auc
2023-08-10 20:35:30,679:INFO:Fitting Model
2023-08-10 20:35:30,682:INFO:Scoring test/hold-out set
2023-08-10 20:35:30,776:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpz2255xug\AUC.png'
2023-08-10 20:35:31,947:INFO:Visual Rendered Successfully
2023-08-10 20:35:32,495:INFO:plot_model() successfully completed......................................
2023-08-10 20:35:33,480:INFO:Initializing plot_model()
2023-08-10 20:35:33,480:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpz2255xug, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:35:33,480:INFO:Checking exceptions
2023-08-10 20:35:33,489:INFO:Preloading libraries
2023-08-10 20:35:33,504:INFO:Copying training dataset
2023-08-10 20:35:33,504:INFO:Plot type: confusion_matrix
2023-08-10 20:35:34,331:INFO:Fitting Model
2023-08-10 20:35:34,334:INFO:Scoring test/hold-out set
2023-08-10 20:35:34,416:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpz2255xug\Confusion Matrix.png'
2023-08-10 20:35:34,983:INFO:Visual Rendered Successfully
2023-08-10 20:35:35,409:INFO:plot_model() successfully completed......................................
2023-08-10 20:35:37,910:INFO:Initializing plot_model()
2023-08-10 20:35:37,911:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpz2255xug, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:35:37,911:INFO:Checking exceptions
2023-08-10 20:35:37,917:INFO:Preloading libraries
2023-08-10 20:35:37,933:INFO:Copying training dataset
2023-08-10 20:35:37,934:INFO:Plot type: feature
2023-08-10 20:35:37,941:WARNING:No coef_ found. Trying feature_importances_
2023-08-10 20:35:38,580:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpz2255xug\Feature Importance.png'
2023-08-10 20:35:40,223:INFO:Visual Rendered Successfully
2023-08-10 20:35:40,915:INFO:plot_model() successfully completed......................................
2023-08-10 20:35:41,575:INFO:SubProcess plot_model() end ==================================
2023-08-10 20:36:09,231:INFO:Creating Dashboard logs
2023-08-10 20:36:09,245:INFO:Model: Naive Bayes
2023-08-10 20:36:10,075:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-08-10 20:36:33,291:INFO:Creating Dashboard logs
2023-08-10 20:36:33,301:INFO:Model: Gradient Boosting Classifier
2023-08-10 20:36:34,142:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1296, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-08-10 20:36:49,518:INFO:Creating Dashboard logs
2023-08-10 20:36:49,530:INFO:Model: Random Forest Classifier
2023-08-10 20:36:50,408:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1296, 'verbose': 0, 'warm_start': False}
2023-08-10 20:37:06,895:INFO:Creating Dashboard logs
2023-08-10 20:37:06,910:INFO:Model: Ada Boost Classifier
2023-08-10 20:37:07,844:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 1296}
2023-08-10 20:37:23,739:INFO:Creating Dashboard logs
2023-08-10 20:37:23,752:INFO:Model: Decision Tree Classifier
2023-08-10 20:37:24,550:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 1296, 'splitter': 'best'}
2023-08-10 20:37:39,915:INFO:Creating Dashboard logs
2023-08-10 20:37:39,926:INFO:Model: Logistic Regression
2023-08-10 20:37:40,753:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1296, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 20:37:56,854:INFO:Creating Dashboard logs
2023-08-10 20:37:56,871:INFO:Model: K Neighbors Classifier
2023-08-10 20:37:57,672:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-08-10 20:38:14,473:INFO:_master_model_container: 8
2023-08-10 20:38:14,474:INFO:_display_container: 2
2023-08-10 20:38:14,479:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 20:38:14,480:INFO:compare_models() successfully completed......................................
2023-08-10 20:38:14,740:INFO:Initializing create_model()
2023-08-10 20:38:14,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=lr, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 20:38:14,741:INFO:Checking exceptions
2023-08-10 20:38:14,797:INFO:Importing libraries
2023-08-10 20:38:14,798:INFO:Copying training dataset
2023-08-10 20:38:14,831:INFO:Defining folds
2023-08-10 20:38:14,831:INFO:Declaring metric variables
2023-08-10 20:38:14,847:INFO:Importing untrained model
2023-08-10 20:38:14,865:INFO:Logistic Regression Imported successfully
2023-08-10 20:38:14,915:INFO:Cross validation set to False
2023-08-10 20:38:14,915:INFO:Fitting Model
2023-08-10 20:38:17,013:INFO:Initializing predict_model()
2023-08-10 20:38:17,014:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1296,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C2601E8B0>)
2023-08-10 20:38:17,014:INFO:Checking exceptions
2023-08-10 20:38:17,014:INFO:Preloading libraries
2023-08-10 20:38:17,015:INFO:Set up data.
2023-08-10 20:38:17,039:INFO:Set up index.
2023-08-10 20:38:17,936:INFO:Initializing predict_model()
2023-08-10 20:38:17,936:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1296,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C2601E8B0>)
2023-08-10 20:38:17,936:INFO:Checking exceptions
2023-08-10 20:38:17,936:INFO:Preloading libraries
2023-08-10 20:38:18,879:INFO:_display_container: 3
2023-08-10 20:38:24,455:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 20:38:24,455:INFO:create_model() successfully completed......................................
2023-08-10 20:38:24,981:INFO:Initializing tune_model()
2023-08-10 20:38:24,981:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Bal. Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>)
2023-08-10 20:38:24,982:INFO:Checking exceptions
2023-08-10 20:38:25,044:INFO:Copying training dataset
2023-08-10 20:38:25,064:INFO:Checking base model
2023-08-10 20:38:25,064:INFO:Base model : Logistic Regression
2023-08-10 20:38:25,078:INFO:Declaring metric variables
2023-08-10 20:38:25,093:INFO:Defining Hyperparameters
2023-08-10 20:38:25,531:INFO:Tuning with n_jobs=-1
2023-08-10 20:38:25,532:INFO:Initializing RandomizedSearchCV
2023-08-10 20:38:56,288:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:39:03,045:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:39:29,713:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:39:48,415:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:40:33,231:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:41:07,723:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:41:27,441:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:41:33,912:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:42:00,658:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:42:06,749:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:42:28,135:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:43:04,431:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:43:10,935:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:43:47,998:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:44:51,768:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:45:25,493:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:45:32,362:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:45:50,917:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:45:56,542:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:46:23,225:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:47:29,561:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:47:46,735:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:48:07,859:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-10 20:49:14,836:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 9.594}
2023-08-10 20:49:14,838:INFO:Hyperparameter search completed
2023-08-10 20:49:14,839:INFO:SubProcess create_model() called ==================================
2023-08-10 20:49:14,841:INFO:Initializing create_model()
2023-08-10 20:49:14,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C25349C70>, model_only=True, return_train_score=True, kwargs={'class_weight': 'balanced', 'C': 9.594})
2023-08-10 20:49:14,844:INFO:Checking exceptions
2023-08-10 20:49:14,844:INFO:Importing libraries
2023-08-10 20:49:14,844:INFO:Copying training dataset
2023-08-10 20:49:14,863:INFO:Defining folds
2023-08-10 20:49:14,863:INFO:Declaring metric variables
2023-08-10 20:49:14,873:INFO:Importing untrained model
2023-08-10 20:49:14,873:INFO:Declaring custom model
2023-08-10 20:49:14,888:INFO:Logistic Regression Imported successfully
2023-08-10 20:49:14,915:INFO:Starting cross validation
2023-08-10 20:49:14,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:50:22,661:INFO:Calculating mean and std
2023-08-10 20:50:22,670:INFO:Creating metrics dataframe
2023-08-10 20:50:22,706:INFO:Finalizing model
2023-08-10 20:50:25,420:INFO:Initializing predict_model()
2023-08-10 20:50:25,420:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C288771F0>)
2023-08-10 20:50:25,421:INFO:Checking exceptions
2023-08-10 20:50:25,422:INFO:Preloading libraries
2023-08-10 20:50:25,424:INFO:Set up data.
2023-08-10 20:50:25,447:INFO:Set up index.
2023-08-10 20:50:34,395:INFO:Uploading results into container
2023-08-10 20:50:34,399:INFO:Uploading model into container now
2023-08-10 20:50:34,409:INFO:_master_model_container: 9
2023-08-10 20:50:34,409:INFO:_display_container: 4
2023-08-10 20:50:34,410:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 20:50:34,411:INFO:create_model() successfully completed......................................
2023-08-10 20:50:34,840:INFO:SubProcess create_model() end ==================================
2023-08-10 20:50:34,840:INFO:choose_better activated
2023-08-10 20:50:34,860:INFO:SubProcess create_model() called ==================================
2023-08-10 20:50:34,863:INFO:Initializing create_model()
2023-08-10 20:50:34,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:50:34,864:INFO:Checking exceptions
2023-08-10 20:50:34,869:INFO:Importing libraries
2023-08-10 20:50:34,869:INFO:Copying training dataset
2023-08-10 20:50:34,894:INFO:Defining folds
2023-08-10 20:50:34,895:INFO:Declaring metric variables
2023-08-10 20:50:34,895:INFO:Importing untrained model
2023-08-10 20:50:34,896:INFO:Declaring custom model
2023-08-10 20:50:34,897:INFO:Logistic Regression Imported successfully
2023-08-10 20:50:34,898:INFO:Starting cross validation
2023-08-10 20:50:34,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:51:55,037:INFO:Calculating mean and std
2023-08-10 20:51:55,039:INFO:Creating metrics dataframe
2023-08-10 20:51:55,045:INFO:Finalizing model
2023-08-10 20:52:05,827:INFO:Uploading results into container
2023-08-10 20:52:05,829:INFO:Uploading model into container now
2023-08-10 20:52:05,830:INFO:_master_model_container: 10
2023-08-10 20:52:05,830:INFO:_display_container: 5
2023-08-10 20:52:05,832:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 20:52:05,833:INFO:create_model() successfully completed......................................
2023-08-10 20:52:06,207:INFO:SubProcess create_model() end ==================================
2023-08-10 20:52:06,208:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Bal. Accuracy is 0.7042
2023-08-10 20:52:06,212:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Bal. Accuracy is 0.8048
2023-08-10 20:52:06,213:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-08-10 20:52:06,213:INFO:choose_better completed
2023-08-10 20:52:06,214:INFO:Creating Dashboard logs
2023-08-10 20:52:06,227:INFO:Model: Logistic Regression
2023-08-10 20:52:07,232:INFO:Logged params: {'C': 9.594, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1296, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 20:52:13,022:INFO:Initializing predict_model()
2023-08-10 20:52:13,023:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C28416310>)
2023-08-10 20:52:13,024:INFO:Checking exceptions
2023-08-10 20:52:13,024:INFO:Preloading libraries
2023-08-10 20:52:25,837:INFO:SubProcess plot_model() called ==================================
2023-08-10 20:52:25,839:INFO:Initializing plot_model()
2023-08-10 20:52:25,839:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp_32bjpcl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:52:25,839:INFO:Checking exceptions
2023-08-10 20:52:25,843:INFO:Preloading libraries
2023-08-10 20:52:25,844:INFO:Copying training dataset
2023-08-10 20:52:25,844:INFO:Plot type: auc
2023-08-10 20:52:26,774:INFO:Fitting Model
2023-08-10 20:52:26,776:INFO:Scoring test/hold-out set
2023-08-10 20:52:26,856:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp_32bjpcl\AUC.png'
2023-08-10 20:52:27,780:INFO:Visual Rendered Successfully
2023-08-10 20:52:28,234:INFO:plot_model() successfully completed......................................
2023-08-10 20:52:28,880:INFO:Initializing plot_model()
2023-08-10 20:52:28,881:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp_32bjpcl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:52:28,882:INFO:Checking exceptions
2023-08-10 20:52:28,889:INFO:Preloading libraries
2023-08-10 20:52:28,889:INFO:Copying training dataset
2023-08-10 20:52:28,889:INFO:Plot type: confusion_matrix
2023-08-10 20:52:29,743:INFO:Fitting Model
2023-08-10 20:52:29,745:INFO:Scoring test/hold-out set
2023-08-10 20:52:29,819:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp_32bjpcl\Confusion Matrix.png'
2023-08-10 20:52:30,289:INFO:Visual Rendered Successfully
2023-08-10 20:52:30,669:INFO:plot_model() successfully completed......................................
2023-08-10 20:52:40,327:INFO:Initializing plot_model()
2023-08-10 20:52:40,328:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp_32bjpcl, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:52:40,328:INFO:Checking exceptions
2023-08-10 20:52:40,335:INFO:Preloading libraries
2023-08-10 20:52:40,336:INFO:Copying training dataset
2023-08-10 20:52:40,336:INFO:Plot type: feature
2023-08-10 20:52:40,838:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp_32bjpcl\Feature Importance.png'
2023-08-10 20:52:41,512:INFO:Visual Rendered Successfully
2023-08-10 20:52:41,838:INFO:plot_model() successfully completed......................................
2023-08-10 20:52:44,507:INFO:SubProcess plot_model() end ==================================
2023-08-10 20:52:55,750:INFO:_master_model_container: 10
2023-08-10 20:52:55,751:INFO:_display_container: 4
2023-08-10 20:52:55,753:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 20:52:55,753:INFO:tune_model() successfully completed......................................
2023-08-10 20:53:06,980:INFO:Initializing create_model()
2023-08-10 20:53:06,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=xgboost, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 20:53:06,981:INFO:Checking exceptions
2023-08-10 20:53:07,041:INFO:Importing libraries
2023-08-10 20:53:07,044:INFO:Copying training dataset
2023-08-10 20:53:07,084:INFO:Defining folds
2023-08-10 20:53:07,084:INFO:Declaring metric variables
2023-08-10 20:53:07,108:INFO:Importing untrained model
2023-08-10 20:53:07,138:INFO:Extreme Gradient Boosting Imported successfully
2023-08-10 20:53:07,305:INFO:Cross validation set to False
2023-08-10 20:53:07,308:INFO:Fitting Model
2023-08-10 20:53:08,525:INFO:Initializing predict_model()
2023-08-10 20:53:08,527:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C2844B790>)
2023-08-10 20:53:08,527:INFO:Checking exceptions
2023-08-10 20:53:08,527:INFO:Preloading libraries
2023-08-10 20:53:08,533:INFO:Set up data.
2023-08-10 20:53:08,586:INFO:Set up index.
2023-08-10 20:53:09,585:INFO:Initializing predict_model()
2023-08-10 20:53:09,586:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C2844B790>)
2023-08-10 20:53:09,586:INFO:Checking exceptions
2023-08-10 20:53:09,586:INFO:Preloading libraries
2023-08-10 20:53:11,186:INFO:_display_container: 5
2023-08-10 20:53:19,080:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-10 20:53:19,080:INFO:create_model() successfully completed......................................
2023-08-10 20:53:19,553:INFO:Initializing ensemble_model()
2023-08-10 20:53:19,553:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 20:53:19,555:INFO:Checking exceptions
2023-08-10 20:53:19,568:INFO:Importing libraries
2023-08-10 20:53:19,568:INFO:Copying training dataset
2023-08-10 20:53:19,568:INFO:Checking base model
2023-08-10 20:53:19,569:INFO:Base model : Extreme Gradient Boosting
2023-08-10 20:53:19,570:INFO:Importing untrained ensembler
2023-08-10 20:53:19,570:INFO:Ensemble method set to Bagging
2023-08-10 20:53:19,570:INFO:SubProcess create_model() called ==================================
2023-08-10 20:53:19,580:INFO:Initializing create_model()
2023-08-10 20:53:19,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=XGBClassifier(base_score=None, booster='gbtree',
                                          callbacks=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None,
                                          early_stopping_rounds=None,
                                          enable_categorical=False,
                                          eval_metric=None, feature_types=None,
                                          gamma=None, gpu_id=None,
                                          grow_policy=No...
                                          max_cat_to_onehot=None,
                                          max_delta_step=None, max_depth=None,
                                          max_leaves=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          n_estimators=100, n_jobs=-1,
                                          num_parallel_tree=None,
                                          objective='binary:logistic',
                                          predictor=None, ...),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=1296, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C29B71190>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 20:53:19,580:INFO:Checking exceptions
2023-08-10 20:53:19,580:INFO:Importing libraries
2023-08-10 20:53:19,581:INFO:Copying training dataset
2023-08-10 20:53:19,596:INFO:Defining folds
2023-08-10 20:53:19,596:INFO:Declaring metric variables
2023-08-10 20:53:19,597:INFO:Importing untrained model
2023-08-10 20:53:19,597:INFO:Declaring custom model
2023-08-10 20:53:19,602:INFO:Bagging Classifier Imported successfully
2023-08-10 20:53:19,603:INFO:Starting cross validation
2023-08-10 20:53:19,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 20:53:47,412:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:54:30,685:INFO:Calculating mean and std
2023-08-10 20:54:30,686:INFO:Creating metrics dataframe
2023-08-10 20:54:30,694:INFO:Finalizing model
2023-08-10 20:54:40,365:INFO:Uploading results into container
2023-08-10 20:54:40,367:INFO:Uploading model into container now
2023-08-10 20:54:40,368:INFO:_master_model_container: 11
2023-08-10 20:54:40,368:INFO:_display_container: 6
2023-08-10 20:54:40,389:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 20:54:40,389:INFO:create_model() successfully completed......................................
2023-08-10 20:54:40,717:INFO:SubProcess create_model() end ==================================
2023-08-10 20:54:40,717:INFO:Creating Dashboard logs
2023-08-10 20:54:40,719:INFO:Model: Bagging Classifier
2023-08-10 20:54:41,651:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 1296, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1296, 'verbose': 0, 'warm_start': False}
2023-08-10 20:54:47,213:INFO:Initializing predict_model()
2023-08-10 20:54:47,213:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C28877310>)
2023-08-10 20:54:47,213:INFO:Checking exceptions
2023-08-10 20:54:47,213:INFO:Preloading libraries
2023-08-10 20:55:03,596:INFO:SubProcess plot_model() called ==================================
2023-08-10 20:55:03,620:INFO:Initializing plot_model()
2023-08-10 20:55:03,620:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpwdhwx2cr, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:55:03,620:INFO:Checking exceptions
2023-08-10 20:55:03,629:INFO:Preloading libraries
2023-08-10 20:55:03,798:INFO:Copying training dataset
2023-08-10 20:55:03,799:INFO:Plot type: auc
2023-08-10 20:55:04,576:INFO:Fitting Model
2023-08-10 20:55:04,578:INFO:Scoring test/hold-out set
2023-08-10 20:55:04,784:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpwdhwx2cr\AUC.png'
2023-08-10 20:55:05,681:INFO:Visual Rendered Successfully
2023-08-10 20:55:06,019:INFO:plot_model() successfully completed......................................
2023-08-10 20:55:14,022:INFO:Initializing plot_model()
2023-08-10 20:55:14,023:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpwdhwx2cr, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:55:14,023:INFO:Checking exceptions
2023-08-10 20:55:14,029:INFO:Preloading libraries
2023-08-10 20:55:14,168:INFO:Copying training dataset
2023-08-10 20:55:14,168:INFO:Plot type: confusion_matrix
2023-08-10 20:55:14,926:INFO:Fitting Model
2023-08-10 20:55:14,927:INFO:Scoring test/hold-out set
2023-08-10 20:55:15,115:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpwdhwx2cr\Confusion Matrix.png'
2023-08-10 20:55:15,540:INFO:Visual Rendered Successfully
2023-08-10 20:55:15,917:INFO:plot_model() successfully completed......................................
2023-08-10 20:55:16,584:INFO:Initializing plot_model()
2023-08-10 20:55:16,584:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpwdhwx2cr, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 20:55:16,584:INFO:Checking exceptions
2023-08-10 20:55:16,592:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 20:55:16,592:INFO:SubProcess plot_model() end ==================================
2023-08-10 20:55:32,701:INFO:_master_model_container: 11
2023-08-10 20:55:32,702:INFO:_display_container: 6
2023-08-10 20:55:32,730:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 20:55:32,730:INFO:ensemble_model() successfully completed......................................
2023-08-10 20:55:33,085:INFO:Initializing tune_model()
2023-08-10 20:55:33,085:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>)
2023-08-10 20:55:33,086:INFO:Checking exceptions
2023-08-10 20:55:33,187:INFO:Copying training dataset
2023-08-10 20:55:33,208:INFO:Checking base model
2023-08-10 20:55:33,209:INFO:Base model : Bagging Classifier
2023-08-10 20:55:33,236:INFO:Declaring metric variables
2023-08-10 20:55:33,256:INFO:Defining Hyperparameters
2023-08-10 20:55:33,758:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 20:55:33,758:INFO:Tuning with n_jobs=-1
2023-08-10 20:55:33,759:INFO:Initializing RandomizedSearchCV
2023-08-10 20:55:36,226:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:55:36,271:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:55:36,407:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:55:36,666:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:56:48,644:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:56:50,574:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:56:57,644:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:57:00,194:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:57:06,564:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:57:08,518:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:57:15,928:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:57:18,627:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:57:39,888:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:57:42,140:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:57:49,624:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:57:51,710:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:57:59,437:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:58:01,493:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:58:08,161:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:58:10,268:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:58:29,975:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:58:31,721:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:58:39,104:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:58:41,151:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:59:17,733:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:59:20,468:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:59:25,259:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:59:28,803:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 20:59:45,514:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:59:55,006:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 20:59:58,266:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:00:42,153:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:00:50,471:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:00:53,564:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:01:08,306:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:01:10,879:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:01:19,013:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:01:22,074:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:01:56,569:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:01:59,109:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:02:06,344:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:02:09,342:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:02:58,346:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:03:03,737:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:03:09,980:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:03:15,040:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:03:50,248:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:04:01,488:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:04:05,781:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:04:56,388:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:05:02,455:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:05:11,536:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:05:16,824:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:05:47,429:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:05:51,058:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:05:59,992:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:06:03,543:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:06:45,362:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:06:49,370:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:06:57,103:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:07:08,790:INFO:best_params: {'actual_estimator__n_estimators': 150}
2023-08-10 21:07:08,791:INFO:Hyperparameter search completed
2023-08-10 21:07:08,792:INFO:SubProcess create_model() called ==================================
2023-08-10 21:07:08,821:INFO:Initializing create_model()
2023-08-10 21:07:08,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C25470CD0>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150})
2023-08-10 21:07:08,822:INFO:Checking exceptions
2023-08-10 21:07:08,822:INFO:Importing libraries
2023-08-10 21:07:08,823:INFO:Copying training dataset
2023-08-10 21:07:08,841:INFO:Defining folds
2023-08-10 21:07:08,841:INFO:Declaring metric variables
2023-08-10 21:07:08,855:INFO:Importing untrained model
2023-08-10 21:07:08,855:INFO:Declaring custom model
2023-08-10 21:07:08,880:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:07:08,916:INFO:Starting cross validation
2023-08-10 21:07:08,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:07:17,103:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:17,191:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:17,209:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:17,321:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:25,430:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:25,582:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:25,630:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:25,681:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:51,306:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:51,784:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:51,911:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:07:52,097:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:01,003:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:01,454:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:01,493:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:01,812:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:27,452:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:27,932:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:34,773:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:35,165:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:08:49,229:INFO:Calculating mean and std
2023-08-10 21:08:49,236:INFO:Creating metrics dataframe
2023-08-10 21:08:49,269:INFO:Finalizing model
2023-08-10 21:09:43,052:INFO:Initializing predict_model()
2023-08-10 21:09:43,053:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                              max_depth=None,
                                                                              max_leaves=None,
                                                                              min_child_weight=None,
                                                                              missing=nan,
                                                                              monotone_constraints=None,
                                                                              n_estimators=100,
                                                                              n_jobs=-1,
                                                                              num_parallel_tree=None,
                                                                              objective='binary:logistic',
                                                                              predictor=None, ...),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=150,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=1296,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C25F87EE0>)
2023-08-10 21:09:43,053:INFO:Checking exceptions
2023-08-10 21:09:43,053:INFO:Preloading libraries
2023-08-10 21:09:43,054:INFO:Set up data.
2023-08-10 21:09:43,073:INFO:Set up index.
2023-08-10 21:09:50,232:INFO:Uploading results into container
2023-08-10 21:09:50,236:INFO:Uploading model into container now
2023-08-10 21:09:50,240:INFO:_master_model_container: 12
2023-08-10 21:09:50,241:INFO:_display_container: 7
2023-08-10 21:09:50,277:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:09:50,277:INFO:create_model() successfully completed......................................
2023-08-10 21:09:50,683:INFO:SubProcess create_model() end ==================================
2023-08-10 21:09:50,684:INFO:choose_better activated
2023-08-10 21:09:50,695:INFO:SubProcess create_model() called ==================================
2023-08-10 21:09:50,727:INFO:Initializing create_model()
2023-08-10 21:09:50,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:09:50,728:INFO:Checking exceptions
2023-08-10 21:09:50,732:INFO:Importing libraries
2023-08-10 21:09:50,732:INFO:Copying training dataset
2023-08-10 21:09:50,754:INFO:Defining folds
2023-08-10 21:09:50,754:INFO:Declaring metric variables
2023-08-10 21:09:50,755:INFO:Importing untrained model
2023-08-10 21:09:50,755:INFO:Declaring custom model
2023-08-10 21:09:50,768:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:09:50,768:INFO:Starting cross validation
2023-08-10 21:09:50,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:10:53,320:INFO:Calculating mean and std
2023-08-10 21:10:53,327:INFO:Creating metrics dataframe
2023-08-10 21:10:53,336:INFO:Finalizing model
2023-08-10 21:11:01,765:INFO:Uploading results into container
2023-08-10 21:11:01,767:INFO:Uploading model into container now
2023-08-10 21:11:01,769:INFO:_master_model_container: 13
2023-08-10 21:11:01,769:INFO:_display_container: 8
2023-08-10 21:11:01,796:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:11:01,798:INFO:create_model() successfully completed......................................
2023-08-10 21:11:02,170:INFO:SubProcess create_model() end ==================================
2023-08-10 21:11:02,197:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) result for Prec. is 0.7483
2023-08-10 21:11:02,219:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) result for Prec. is 0.7483
2023-08-10 21:11:02,243:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) is best model
2023-08-10 21:11:02,244:INFO:choose_better completed
2023-08-10 21:11:02,245:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-10 21:11:02,246:INFO:Creating Dashboard logs
2023-08-10 21:11:02,261:INFO:Model: Bagging Classifier
2023-08-10 21:11:03,679:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__objective': 'binary:logistic', 'estimator__use_label_encoder': None, 'estimator__base_score': None, 'estimator__booster': 'gbtree', 'estimator__callbacks': None, 'estimator__colsample_bylevel': None, 'estimator__colsample_bynode': None, 'estimator__colsample_bytree': None, 'estimator__early_stopping_rounds': None, 'estimator__enable_categorical': False, 'estimator__eval_metric': None, 'estimator__feature_types': None, 'estimator__gamma': None, 'estimator__gpu_id': None, 'estimator__grow_policy': None, 'estimator__importance_type': None, 'estimator__interaction_constraints': None, 'estimator__learning_rate': None, 'estimator__max_bin': None, 'estimator__max_cat_threshold': None, 'estimator__max_cat_to_onehot': None, 'estimator__max_delta_step': None, 'estimator__max_depth': None, 'estimator__max_leaves': None, 'estimator__min_child_weight': None, 'estimator__missing': nan, 'estimator__monotone_constraints': None, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_parallel_tree': None, 'estimator__predictor': None, 'estimator__random_state': 1296, 'estimator__reg_alpha': None, 'estimator__reg_lambda': None, 'estimator__sampling_method': None, 'estimator__scale_pos_weight': None, 'estimator__subsample': None, 'estimator__tree_method': 'auto', 'estimator__validate_parameters': None, 'estimator__verbosity': 0, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1296, 'verbose': 0, 'warm_start': False}
2023-08-10 21:11:14,703:INFO:Initializing predict_model()
2023-08-10 21:11:14,704:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C285CECA0>)
2023-08-10 21:11:14,705:INFO:Checking exceptions
2023-08-10 21:11:14,705:INFO:Preloading libraries
2023-08-10 21:11:16,152:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:11:16,177:INFO:Initializing plot_model()
2023-08-10 21:11:16,177:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp_cb46zkj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:11:16,178:INFO:Checking exceptions
2023-08-10 21:11:16,183:INFO:Preloading libraries
2023-08-10 21:11:16,326:INFO:Copying training dataset
2023-08-10 21:11:16,327:INFO:Plot type: auc
2023-08-10 21:11:17,098:INFO:Fitting Model
2023-08-10 21:11:17,100:INFO:Scoring test/hold-out set
2023-08-10 21:11:17,279:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp_cb46zkj\AUC.png'
2023-08-10 21:11:18,207:INFO:Visual Rendered Successfully
2023-08-10 21:11:18,603:INFO:plot_model() successfully completed......................................
2023-08-10 21:11:19,248:INFO:Initializing plot_model()
2023-08-10 21:11:19,249:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp_cb46zkj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:11:19,249:INFO:Checking exceptions
2023-08-10 21:11:19,255:INFO:Preloading libraries
2023-08-10 21:11:19,412:INFO:Copying training dataset
2023-08-10 21:11:19,412:INFO:Plot type: confusion_matrix
2023-08-10 21:11:20,291:INFO:Fitting Model
2023-08-10 21:11:20,292:INFO:Scoring test/hold-out set
2023-08-10 21:11:20,496:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp_cb46zkj\Confusion Matrix.png'
2023-08-10 21:11:20,987:INFO:Visual Rendered Successfully
2023-08-10 21:11:21,385:INFO:plot_model() successfully completed......................................
2023-08-10 21:11:22,636:INFO:Initializing plot_model()
2023-08-10 21:11:22,636:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp_cb46zkj, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:11:22,636:INFO:Checking exceptions
2023-08-10 21:11:22,637:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 21:11:22,637:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:11:37,539:INFO:_master_model_container: 13
2023-08-10 21:11:37,540:INFO:_display_container: 7
2023-08-10 21:11:37,566:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:11:37,566:INFO:tune_model() successfully completed......................................
2023-08-10 21:11:44,344:INFO:Initializing create_model()
2023-08-10 21:11:44,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=nb, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 21:11:44,345:INFO:Checking exceptions
2023-08-10 21:11:44,398:INFO:Importing libraries
2023-08-10 21:11:44,399:INFO:Copying training dataset
2023-08-10 21:11:44,424:INFO:Defining folds
2023-08-10 21:11:44,425:INFO:Declaring metric variables
2023-08-10 21:11:44,436:INFO:Importing untrained model
2023-08-10 21:11:44,452:INFO:Naive Bayes Imported successfully
2023-08-10 21:11:44,507:INFO:Cross validation set to False
2023-08-10 21:11:44,508:INFO:Fitting Model
2023-08-10 21:11:44,982:INFO:Initializing predict_model()
2023-08-10 21:11:44,983:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C29DB8040>)
2023-08-10 21:11:44,983:INFO:Checking exceptions
2023-08-10 21:11:44,984:INFO:Preloading libraries
2023-08-10 21:11:44,990:INFO:Set up data.
2023-08-10 21:11:45,079:INFO:Set up index.
2023-08-10 21:11:45,642:INFO:Initializing predict_model()
2023-08-10 21:11:45,642:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C29DB8040>)
2023-08-10 21:11:45,642:INFO:Checking exceptions
2023-08-10 21:11:45,642:INFO:Preloading libraries
2023-08-10 21:11:46,598:INFO:_display_container: 8
2023-08-10 21:11:51,611:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-10 21:11:51,611:INFO:create_model() successfully completed......................................
2023-08-10 21:11:52,284:INFO:Initializing ensemble_model()
2023-08-10 21:11:52,285:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 21:11:52,285:INFO:Checking exceptions
2023-08-10 21:11:52,299:INFO:Importing libraries
2023-08-10 21:11:52,299:INFO:Copying training dataset
2023-08-10 21:11:52,299:INFO:Checking base model
2023-08-10 21:11:52,300:INFO:Base model : Naive Bayes
2023-08-10 21:11:52,301:INFO:Importing untrained ensembler
2023-08-10 21:11:52,301:INFO:Ensemble method set to Bagging
2023-08-10 21:11:52,302:INFO:SubProcess create_model() called ==================================
2023-08-10 21:11:52,304:INFO:Initializing create_model()
2023-08-10 21:11:52,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GaussianNB(priors=None, var_smoothing=1e-09),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=1296, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C25B5E130>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:11:52,305:INFO:Checking exceptions
2023-08-10 21:11:52,305:INFO:Importing libraries
2023-08-10 21:11:52,305:INFO:Copying training dataset
2023-08-10 21:11:52,318:INFO:Defining folds
2023-08-10 21:11:52,318:INFO:Declaring metric variables
2023-08-10 21:11:52,319:INFO:Importing untrained model
2023-08-10 21:11:52,319:INFO:Declaring custom model
2023-08-10 21:11:52,321:INFO:Bagging Classifier Imported successfully
2023-08-10 21:11:52,323:INFO:Starting cross validation
2023-08-10 21:11:52,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:12:51,326:INFO:Calculating mean and std
2023-08-10 21:12:51,327:INFO:Creating metrics dataframe
2023-08-10 21:12:51,334:INFO:Finalizing model
2023-08-10 21:12:58,241:INFO:Uploading results into container
2023-08-10 21:12:58,243:INFO:Uploading model into container now
2023-08-10 21:12:58,244:INFO:_master_model_container: 14
2023-08-10 21:12:58,244:INFO:_display_container: 9
2023-08-10 21:12:58,248:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:12:58,249:INFO:create_model() successfully completed......................................
2023-08-10 21:12:58,578:INFO:SubProcess create_model() end ==================================
2023-08-10 21:12:58,579:INFO:Creating Dashboard logs
2023-08-10 21:12:58,580:INFO:Model: Bagging Classifier
2023-08-10 21:12:59,386:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__priors': None, 'estimator__var_smoothing': 1e-09, 'estimator': GaussianNB(priors=None, var_smoothing=1e-09), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1296, 'verbose': 0, 'warm_start': False}
2023-08-10 21:13:04,585:INFO:Initializing predict_model()
2023-08-10 21:13:04,586:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C285DE310>)
2023-08-10 21:13:04,586:INFO:Checking exceptions
2023-08-10 21:13:04,586:INFO:Preloading libraries
2023-08-10 21:13:05,902:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:13:05,909:INFO:Initializing plot_model()
2023-08-10 21:13:05,909:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpxhixt1ei, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:13:05,909:INFO:Checking exceptions
2023-08-10 21:13:05,917:INFO:Preloading libraries
2023-08-10 21:13:05,920:INFO:Copying training dataset
2023-08-10 21:13:05,921:INFO:Plot type: auc
2023-08-10 21:13:06,605:INFO:Fitting Model
2023-08-10 21:13:06,606:INFO:Scoring test/hold-out set
2023-08-10 21:13:06,700:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpxhixt1ei\AUC.png'
2023-08-10 21:13:07,493:INFO:Visual Rendered Successfully
2023-08-10 21:13:07,816:INFO:plot_model() successfully completed......................................
2023-08-10 21:13:08,562:INFO:Initializing plot_model()
2023-08-10 21:13:08,564:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpxhixt1ei, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:13:08,564:INFO:Checking exceptions
2023-08-10 21:13:08,572:INFO:Preloading libraries
2023-08-10 21:13:08,574:INFO:Copying training dataset
2023-08-10 21:13:08,574:INFO:Plot type: confusion_matrix
2023-08-10 21:13:09,290:INFO:Fitting Model
2023-08-10 21:13:09,291:INFO:Scoring test/hold-out set
2023-08-10 21:13:09,392:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpxhixt1ei\Confusion Matrix.png'
2023-08-10 21:13:09,873:INFO:Visual Rendered Successfully
2023-08-10 21:13:10,210:INFO:plot_model() successfully completed......................................
2023-08-10 21:13:10,806:INFO:Initializing plot_model()
2023-08-10 21:13:10,806:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpxhixt1ei, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:13:10,806:INFO:Checking exceptions
2023-08-10 21:13:10,807:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 21:13:10,808:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:13:23,073:INFO:_master_model_container: 14
2023-08-10 21:13:23,073:INFO:_display_container: 9
2023-08-10 21:13:23,078:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:13:23,079:INFO:ensemble_model() successfully completed......................................
2023-08-10 21:13:23,419:INFO:Initializing tune_model()
2023-08-10 21:13:23,420:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>)
2023-08-10 21:13:23,420:INFO:Checking exceptions
2023-08-10 21:13:23,472:INFO:Copying training dataset
2023-08-10 21:13:23,489:INFO:Checking base model
2023-08-10 21:13:23,490:INFO:Base model : Bagging Classifier
2023-08-10 21:13:23,503:INFO:Declaring metric variables
2023-08-10 21:13:23,514:INFO:Defining Hyperparameters
2023-08-10 21:13:23,918:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 21:13:23,919:INFO:Tuning with n_jobs=-1
2023-08-10 21:13:23,919:INFO:Initializing RandomizedSearchCV
2023-08-10 21:15:51,182:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:16:15,694:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:16:35,686:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:16:41,637:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:16:47,419:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:17:26,248:INFO:best_params: {'actual_estimator__n_estimators': 10}
2023-08-10 21:17:26,250:INFO:Hyperparameter search completed
2023-08-10 21:17:26,251:INFO:SubProcess create_model() called ==================================
2023-08-10 21:17:26,260:INFO:Initializing create_model()
2023-08-10 21:17:26,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C2570EF10>, model_only=True, return_train_score=True, kwargs={'n_estimators': 10})
2023-08-10 21:17:26,261:INFO:Checking exceptions
2023-08-10 21:17:26,261:INFO:Importing libraries
2023-08-10 21:17:26,262:INFO:Copying training dataset
2023-08-10 21:17:26,280:INFO:Defining folds
2023-08-10 21:17:26,281:INFO:Declaring metric variables
2023-08-10 21:17:26,292:INFO:Importing untrained model
2023-08-10 21:17:26,293:INFO:Declaring custom model
2023-08-10 21:17:26,315:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:17:26,350:INFO:Starting cross validation
2023-08-10 21:17:26,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:18:32,531:INFO:Calculating mean and std
2023-08-10 21:18:32,537:INFO:Creating metrics dataframe
2023-08-10 21:18:32,561:INFO:Finalizing model
2023-08-10 21:18:32,880:INFO:Initializing predict_model()
2023-08-10 21:18:32,880:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                                        var_smoothing=1e-09),
                                                                                   max_features=1.0,
                                                                                   max_samples=1.0,
                                                                                   n_estimators=10,
                                                                                   n_jobs=None,
                                                                                   oob_score=False,
                                                                                   random_state=1296,
                                                                                   verbose=0,
                                                                                   warm_start=False),
                                                      estimator=GaussianNB(priors=None,
                                                                           var_smoothing=1e-09),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=10,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=1296,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C26086DC0>)
2023-08-10 21:18:32,881:INFO:Checking exceptions
2023-08-10 21:18:32,881:INFO:Preloading libraries
2023-08-10 21:18:32,882:INFO:Set up data.
2023-08-10 21:18:32,904:INFO:Set up index.
2023-08-10 21:18:41,359:INFO:Uploading results into container
2023-08-10 21:18:41,362:INFO:Uploading model into container now
2023-08-10 21:18:41,364:INFO:_master_model_container: 15
2023-08-10 21:18:41,365:INFO:_display_container: 10
2023-08-10 21:18:41,370:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:18:41,371:INFO:create_model() successfully completed......................................
2023-08-10 21:18:41,732:INFO:SubProcess create_model() end ==================================
2023-08-10 21:18:41,732:INFO:choose_better activated
2023-08-10 21:18:41,745:INFO:SubProcess create_model() called ==================================
2023-08-10 21:18:41,753:INFO:Initializing create_model()
2023-08-10 21:18:41,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:18:41,754:INFO:Checking exceptions
2023-08-10 21:18:41,760:INFO:Importing libraries
2023-08-10 21:18:41,760:INFO:Copying training dataset
2023-08-10 21:18:41,777:INFO:Defining folds
2023-08-10 21:18:41,778:INFO:Declaring metric variables
2023-08-10 21:18:41,778:INFO:Importing untrained model
2023-08-10 21:18:41,779:INFO:Declaring custom model
2023-08-10 21:18:41,785:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:18:41,786:INFO:Starting cross validation
2023-08-10 21:18:41,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:19:41,533:INFO:Calculating mean and std
2023-08-10 21:19:41,534:INFO:Creating metrics dataframe
2023-08-10 21:19:41,540:INFO:Finalizing model
2023-08-10 21:19:48,525:INFO:Uploading results into container
2023-08-10 21:19:48,527:INFO:Uploading model into container now
2023-08-10 21:19:48,528:INFO:_master_model_container: 16
2023-08-10 21:19:48,529:INFO:_display_container: 11
2023-08-10 21:19:48,534:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:19:48,534:INFO:create_model() successfully completed......................................
2023-08-10 21:19:48,872:INFO:SubProcess create_model() end ==================================
2023-08-10 21:19:48,876:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) result for Prec. is 0.3199
2023-08-10 21:19:48,882:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) result for Prec. is 0.3199
2023-08-10 21:19:48,887:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) is best model
2023-08-10 21:19:48,887:INFO:choose_better completed
2023-08-10 21:19:48,887:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-10 21:19:48,889:INFO:Creating Dashboard logs
2023-08-10 21:19:48,901:INFO:Model: Bagging Classifier
2023-08-10 21:19:49,683:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__priors': None, 'estimator__var_smoothing': 1e-09, 'estimator': GaussianNB(priors=None, var_smoothing=1e-09), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1296, 'verbose': 0, 'warm_start': False}
2023-08-10 21:19:54,767:INFO:Initializing predict_model()
2023-08-10 21:19:54,767:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C285EA310>)
2023-08-10 21:19:54,767:INFO:Checking exceptions
2023-08-10 21:19:54,768:INFO:Preloading libraries
2023-08-10 21:19:56,104:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:19:56,108:INFO:Initializing plot_model()
2023-08-10 21:19:56,109:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpv_u4qwrc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:19:56,109:INFO:Checking exceptions
2023-08-10 21:19:56,115:INFO:Preloading libraries
2023-08-10 21:19:56,117:INFO:Copying training dataset
2023-08-10 21:19:56,117:INFO:Plot type: auc
2023-08-10 21:19:56,821:INFO:Fitting Model
2023-08-10 21:19:56,823:INFO:Scoring test/hold-out set
2023-08-10 21:19:56,922:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpv_u4qwrc\AUC.png'
2023-08-10 21:19:57,748:INFO:Visual Rendered Successfully
2023-08-10 21:19:58,092:INFO:plot_model() successfully completed......................................
2023-08-10 21:20:02,635:INFO:Initializing plot_model()
2023-08-10 21:20:02,635:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpv_u4qwrc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:20:02,635:INFO:Checking exceptions
2023-08-10 21:20:02,640:INFO:Preloading libraries
2023-08-10 21:20:02,642:INFO:Copying training dataset
2023-08-10 21:20:02,642:INFO:Plot type: confusion_matrix
2023-08-10 21:20:03,354:INFO:Fitting Model
2023-08-10 21:20:03,355:INFO:Scoring test/hold-out set
2023-08-10 21:20:03,450:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpv_u4qwrc\Confusion Matrix.png'
2023-08-10 21:20:03,859:INFO:Visual Rendered Successfully
2023-08-10 21:20:04,207:INFO:plot_model() successfully completed......................................
2023-08-10 21:20:04,721:INFO:Initializing plot_model()
2023-08-10 21:20:04,721:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpv_u4qwrc, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:20:04,721:INFO:Checking exceptions
2023-08-10 21:20:04,723:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 21:20:04,723:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:20:15,991:INFO:_master_model_container: 16
2023-08-10 21:20:15,992:INFO:_display_container: 10
2023-08-10 21:20:16,000:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:20:16,000:INFO:tune_model() successfully completed......................................
2023-08-10 21:20:21,454:INFO:Initializing create_model()
2023-08-10 21:20:21,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=dt, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-08-10 21:20:21,455:INFO:Checking exceptions
2023-08-10 21:20:21,511:INFO:Importing libraries
2023-08-10 21:20:21,512:INFO:Copying training dataset
2023-08-10 21:20:21,531:INFO:Defining folds
2023-08-10 21:20:21,531:INFO:Declaring metric variables
2023-08-10 21:20:21,547:INFO:Importing untrained model
2023-08-10 21:20:21,558:INFO:Decision Tree Classifier Imported successfully
2023-08-10 21:20:21,599:INFO:Cross validation set to False
2023-08-10 21:20:21,600:INFO:Fitting Model
2023-08-10 21:20:21,886:INFO:Initializing predict_model()
2023-08-10 21:20:21,888:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=1296, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C29EC7550>)
2023-08-10 21:20:21,895:INFO:Checking exceptions
2023-08-10 21:20:21,897:INFO:Preloading libraries
2023-08-10 21:20:21,898:INFO:Set up data.
2023-08-10 21:20:21,919:INFO:Set up index.
2023-08-10 21:20:22,405:INFO:Initializing predict_model()
2023-08-10 21:20:22,405:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=1296, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C2844B790>)
2023-08-10 21:20:22,405:INFO:Checking exceptions
2023-08-10 21:20:22,406:INFO:Preloading libraries
2023-08-10 21:20:23,354:INFO:_display_container: 11
2023-08-10 21:20:28,183:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1296, splitter='best')
2023-08-10 21:20:28,184:INFO:create_model() successfully completed......................................
2023-08-10 21:20:28,766:INFO:Initializing ensemble_model()
2023-08-10 21:20:28,766:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1296, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Bal. Accuracy, fit_kwargs=None, groups=None, probability_threshold=0.4, verbose=False, return_train_score=False)
2023-08-10 21:20:28,766:INFO:Checking exceptions
2023-08-10 21:20:28,780:INFO:Importing libraries
2023-08-10 21:20:28,781:INFO:Copying training dataset
2023-08-10 21:20:28,781:INFO:Checking base model
2023-08-10 21:20:28,781:INFO:Base model : Decision Tree Classifier
2023-08-10 21:20:28,782:INFO:Importing untrained ensembler
2023-08-10 21:20:28,782:INFO:Ensemble method set to Bagging
2023-08-10 21:20:28,783:INFO:SubProcess create_model() called ==================================
2023-08-10 21:20:28,786:INFO:Initializing create_model()
2023-08-10 21:20:28,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   random_state=1296,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=1296, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.4, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C29BF4E50>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:20:28,786:INFO:Checking exceptions
2023-08-10 21:20:28,786:INFO:Importing libraries
2023-08-10 21:20:28,786:INFO:Copying training dataset
2023-08-10 21:20:28,802:INFO:Defining folds
2023-08-10 21:20:28,802:INFO:Declaring metric variables
2023-08-10 21:20:28,803:INFO:Importing untrained model
2023-08-10 21:20:28,803:INFO:Declaring custom model
2023-08-10 21:20:28,806:INFO:Bagging Classifier Imported successfully
2023-08-10 21:20:28,807:INFO:Starting cross validation
2023-08-10 21:20:28,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:21:27,750:INFO:Calculating mean and std
2023-08-10 21:21:27,752:INFO:Creating metrics dataframe
2023-08-10 21:21:27,759:INFO:Finalizing model
2023-08-10 21:21:34,992:INFO:Uploading results into container
2023-08-10 21:21:34,994:INFO:Uploading model into container now
2023-08-10 21:21:34,995:INFO:_master_model_container: 17
2023-08-10 21:21:34,995:INFO:_display_container: 12
2023-08-10 21:21:35,003:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:21:35,003:INFO:create_model() successfully completed......................................
2023-08-10 21:21:35,333:INFO:SubProcess create_model() end ==================================
2023-08-10 21:21:35,334:INFO:Creating Dashboard logs
2023-08-10 21:21:35,336:INFO:Model: Bagging Classifier
2023-08-10 21:21:36,136:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1296, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1296, 'verbose': 0, 'warm_start': False}
2023-08-10 21:21:42,533:INFO:Initializing predict_model()
2023-08-10 21:21:42,533:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C25F873A0>)
2023-08-10 21:21:42,533:INFO:Checking exceptions
2023-08-10 21:21:42,533:INFO:Preloading libraries
2023-08-10 21:21:43,893:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:21:43,902:INFO:Initializing plot_model()
2023-08-10 21:21:43,902:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpyhw96qkz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:21:43,902:INFO:Checking exceptions
2023-08-10 21:21:43,910:INFO:Preloading libraries
2023-08-10 21:21:43,914:INFO:Copying training dataset
2023-08-10 21:21:43,914:INFO:Plot type: auc
2023-08-10 21:21:44,624:INFO:Fitting Model
2023-08-10 21:21:44,626:INFO:Scoring test/hold-out set
2023-08-10 21:21:44,714:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpyhw96qkz\AUC.png'
2023-08-10 21:21:45,515:INFO:Visual Rendered Successfully
2023-08-10 21:21:45,844:INFO:plot_model() successfully completed......................................
2023-08-10 21:21:46,611:INFO:Initializing plot_model()
2023-08-10 21:21:46,612:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpyhw96qkz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:21:46,612:INFO:Checking exceptions
2023-08-10 21:21:46,616:INFO:Preloading libraries
2023-08-10 21:21:46,620:INFO:Copying training dataset
2023-08-10 21:21:46,620:INFO:Plot type: confusion_matrix
2023-08-10 21:21:47,336:INFO:Fitting Model
2023-08-10 21:21:47,336:INFO:Scoring test/hold-out set
2023-08-10 21:21:47,417:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpyhw96qkz\Confusion Matrix.png'
2023-08-10 21:21:47,823:INFO:Visual Rendered Successfully
2023-08-10 21:21:48,167:INFO:plot_model() successfully completed......................................
2023-08-10 21:21:52,503:INFO:Initializing plot_model()
2023-08-10 21:21:52,503:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpyhw96qkz, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:21:52,503:INFO:Checking exceptions
2023-08-10 21:21:52,505:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 21:21:52,505:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:22:05,634:INFO:_master_model_container: 17
2023-08-10 21:22:05,634:INFO:_display_container: 12
2023-08-10 21:22:05,647:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:22:05,648:INFO:ensemble_model() successfully completed......................................
2023-08-10 21:22:06,025:INFO:Initializing tune_model()
2023-08-10 21:22:06,025:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150]}, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>)
2023-08-10 21:22:06,025:INFO:Checking exceptions
2023-08-10 21:22:06,090:INFO:Copying training dataset
2023-08-10 21:22:06,102:INFO:Checking base model
2023-08-10 21:22:06,104:INFO:Base model : Bagging Classifier
2023-08-10 21:22:06,123:INFO:Declaring metric variables
2023-08-10 21:22:06,138:INFO:Defining Hyperparameters
2023-08-10 21:22:06,527:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150]}
2023-08-10 21:22:06,527:INFO:Tuning with n_jobs=-1
2023-08-10 21:22:06,527:INFO:Initializing RandomizedSearchCV
2023-08-10 21:24:03,549:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:24:04,940:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:24:54,421:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:25:02,930:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:10,550:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:11,932:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:25:19,668:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:20,949:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:25:26,649:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:27,835:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:25:34,187:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:35,586:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:25:41,530:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:42,896:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:25:48,448:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:49,697:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:25:55,524:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:25:56,938:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:26:02,920:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:26:04,429:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:26:11,863:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-10 21:27:00,569:INFO:best_params: {'actual_estimator__n_estimators': 150}
2023-08-10 21:27:00,575:INFO:Hyperparameter search completed
2023-08-10 21:27:00,576:INFO:SubProcess create_model() called ==================================
2023-08-10 21:27:00,594:INFO:Initializing create_model()
2023-08-10 21:27:00,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C25A58DC0>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150})
2023-08-10 21:27:00,599:INFO:Checking exceptions
2023-08-10 21:27:00,600:INFO:Importing libraries
2023-08-10 21:27:00,600:INFO:Copying training dataset
2023-08-10 21:27:00,627:INFO:Defining folds
2023-08-10 21:27:00,627:INFO:Declaring metric variables
2023-08-10 21:27:00,645:INFO:Importing untrained model
2023-08-10 21:27:00,646:INFO:Declaring custom model
2023-08-10 21:27:00,679:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:27:00,732:INFO:Starting cross validation
2023-08-10 21:27:00,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:27:03,494:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:03,501:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:03,514:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:03,712:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:05,790:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:05,945:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:06,009:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:06,420:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:27,677:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:28,168:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:28,317:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:28,984:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:31,042:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:31,381:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:31,563:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:32,372:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:49,016:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:49,147:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:51,546:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:27:51,601:WARNING:c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-10 21:28:34,947:INFO:Calculating mean and std
2023-08-10 21:28:34,954:INFO:Creating metrics dataframe
2023-08-10 21:28:34,981:INFO:Finalizing model
2023-08-10 21:28:39,941:INFO:Initializing predict_model()
2023-08-10 21:28:39,942:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                                                                       criterion='gini',
                                                                                       max_depth=None,
                                                                                       max_features=None,
                                                                                       max_leaf_nodes=None,
                                                                                       min_impurity_decrease=0.0,
                                                                                       min_samples_leaf=1,
                                                                                       min_samples_split=2,
                                                                                       min_weight_fraction_leaf=0.0,
                                                                                       random_state=1296,
                                                                                       splitter='best'),
                                                      max_features=1.0,
                                                      max_samples=1.0,
                                                      n_estimators=150,
                                                      n_jobs=None,
                                                      oob_score=False,
                                                      probability_threshold=0.4,
                                                      random_state=1296,
                                                      verbose=0,
                                                      warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C285CE940>)
2023-08-10 21:28:39,942:INFO:Checking exceptions
2023-08-10 21:28:39,943:INFO:Preloading libraries
2023-08-10 21:28:39,945:INFO:Set up data.
2023-08-10 21:28:39,981:INFO:Set up index.
2023-08-10 21:28:47,709:INFO:Uploading results into container
2023-08-10 21:28:47,712:INFO:Uploading model into container now
2023-08-10 21:28:47,714:INFO:_master_model_container: 18
2023-08-10 21:28:47,715:INFO:_display_container: 13
2023-08-10 21:28:47,728:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:28:47,729:INFO:create_model() successfully completed......................................
2023-08-10 21:28:48,108:INFO:SubProcess create_model() end ==================================
2023-08-10 21:28:48,108:INFO:choose_better activated
2023-08-10 21:28:48,120:INFO:SubProcess create_model() called ==================================
2023-08-10 21:28:48,129:INFO:Initializing create_model()
2023-08-10 21:28:48,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:28:48,130:INFO:Checking exceptions
2023-08-10 21:28:48,137:INFO:Importing libraries
2023-08-10 21:28:48,138:INFO:Copying training dataset
2023-08-10 21:28:48,156:INFO:Defining folds
2023-08-10 21:28:48,156:INFO:Declaring metric variables
2023-08-10 21:28:48,157:INFO:Importing untrained model
2023-08-10 21:28:48,157:INFO:Declaring custom model
2023-08-10 21:28:48,161:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:28:48,162:INFO:Starting cross validation
2023-08-10 21:28:48,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:29:50,729:INFO:Calculating mean and std
2023-08-10 21:29:50,732:INFO:Creating metrics dataframe
2023-08-10 21:29:50,738:INFO:Finalizing model
2023-08-10 21:29:58,015:INFO:Uploading results into container
2023-08-10 21:29:58,017:INFO:Uploading model into container now
2023-08-10 21:29:58,018:INFO:_master_model_container: 19
2023-08-10 21:29:58,019:INFO:_display_container: 14
2023-08-10 21:29:58,027:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:29:58,027:INFO:create_model() successfully completed......................................
2023-08-10 21:29:58,386:INFO:SubProcess create_model() end ==================================
2023-08-10 21:29:58,396:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) result for Prec. is 0.6115
2023-08-10 21:29:58,406:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) result for Prec. is 0.6715
2023-08-10 21:29:58,417:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False) is best model
2023-08-10 21:29:58,417:INFO:choose_better completed
2023-08-10 21:29:58,418:INFO:Creating Dashboard logs
2023-08-10 21:29:58,433:INFO:Model: Bagging Classifier
2023-08-10 21:29:59,656:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__random_state': 1296, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': 1296, 'verbose': 0, 'warm_start': False}
2023-08-10 21:30:07,809:INFO:Initializing predict_model()
2023-08-10 21:30:07,810:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C285EA310>)
2023-08-10 21:30:07,810:INFO:Checking exceptions
2023-08-10 21:30:07,811:INFO:Preloading libraries
2023-08-10 21:30:10,437:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:30:10,452:INFO:Initializing plot_model()
2023-08-10 21:30:10,453:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmptucharr3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:30:10,453:INFO:Checking exceptions
2023-08-10 21:30:10,459:INFO:Preloading libraries
2023-08-10 21:30:10,507:INFO:Copying training dataset
2023-08-10 21:30:10,507:INFO:Plot type: auc
2023-08-10 21:30:11,239:INFO:Fitting Model
2023-08-10 21:30:11,241:INFO:Scoring test/hold-out set
2023-08-10 21:30:11,533:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmptucharr3\AUC.png'
2023-08-10 21:30:12,374:INFO:Visual Rendered Successfully
2023-08-10 21:30:12,734:INFO:plot_model() successfully completed......................................
2023-08-10 21:30:13,543:INFO:Initializing plot_model()
2023-08-10 21:30:13,544:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmptucharr3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:30:13,544:INFO:Checking exceptions
2023-08-10 21:30:13,552:INFO:Preloading libraries
2023-08-10 21:30:13,601:INFO:Copying training dataset
2023-08-10 21:30:13,601:INFO:Plot type: confusion_matrix
2023-08-10 21:30:14,335:INFO:Fitting Model
2023-08-10 21:30:14,336:INFO:Scoring test/hold-out set
2023-08-10 21:30:14,620:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmptucharr3\Confusion Matrix.png'
2023-08-10 21:30:15,034:INFO:Visual Rendered Successfully
2023-08-10 21:30:15,391:INFO:plot_model() successfully completed......................................
2023-08-10 21:30:17,472:INFO:Initializing plot_model()
2023-08-10 21:30:17,472:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmptucharr3, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:30:17,473:INFO:Checking exceptions
2023-08-10 21:30:17,474:WARNING:Couldn't create plot feature for model, exception below:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 152, in _log_plot
    plot_name = experiment._plot_model(
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 472, in _plot_model
    raise TypeError(
TypeError: Feature Importance and RFE plots not available for estimators that doesnt support coef_ or feature_importances_ attribute.

2023-08-10 21:30:17,474:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:30:43,584:INFO:_master_model_container: 19
2023-08-10 21:30:43,584:INFO:_display_container: 13
2023-08-10 21:30:43,599:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:30:43,599:INFO:tune_model() successfully completed......................................
2023-08-10 21:30:49,736:INFO:Initializing compare_models()
2023-08-10 21:30:49,737:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, include=[CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, 'include': [CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 21:30:49,737:INFO:Checking exceptions
2023-08-10 21:30:49,744:INFO:Preparing display monitor
2023-08-10 21:30:49,860:INFO:Initializing custom model Bagging Classifier
2023-08-10 21:30:49,861:INFO:Total runtime is 6.677707036336263e-05 minutes
2023-08-10 21:30:49,879:INFO:SubProcess create_model() called ==================================
2023-08-10 21:30:49,894:INFO:Initializing create_model()
2023-08-10 21:30:49,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C256CCAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:30:49,895:INFO:Checking exceptions
2023-08-10 21:30:49,895:INFO:Importing libraries
2023-08-10 21:30:49,895:INFO:Copying training dataset
2023-08-10 21:30:49,922:INFO:Defining folds
2023-08-10 21:30:49,923:INFO:Declaring metric variables
2023-08-10 21:30:49,947:INFO:Importing untrained model
2023-08-10 21:30:49,947:INFO:Declaring custom model
2023-08-10 21:30:49,969:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:30:50,022:INFO:Starting cross validation
2023-08-10 21:30:50,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:31:54,568:INFO:Calculating mean and std
2023-08-10 21:31:54,576:INFO:Creating metrics dataframe
2023-08-10 21:32:03,078:INFO:Uploading results into container
2023-08-10 21:32:03,079:INFO:Uploading model into container now
2023-08-10 21:32:03,081:INFO:_master_model_container: 20
2023-08-10 21:32:03,081:INFO:_display_container: 14
2023-08-10 21:32:03,092:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:32:03,092:INFO:create_model() successfully completed......................................
2023-08-10 21:32:03,450:INFO:SubProcess create_model() end ==================================
2023-08-10 21:32:03,451:INFO:Creating metrics dataframe
2023-08-10 21:32:03,491:INFO:Initializing custom model Bagging Classifier
2023-08-10 21:32:03,491:INFO:Total runtime is 1.2272332151730854 minutes
2023-08-10 21:32:03,503:INFO:SubProcess create_model() called ==================================
2023-08-10 21:32:03,510:INFO:Initializing create_model()
2023-08-10 21:32:03,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C256CCAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:32:03,511:INFO:Checking exceptions
2023-08-10 21:32:03,512:INFO:Importing libraries
2023-08-10 21:32:03,512:INFO:Copying training dataset
2023-08-10 21:32:03,532:INFO:Defining folds
2023-08-10 21:32:03,532:INFO:Declaring metric variables
2023-08-10 21:32:03,545:INFO:Importing untrained model
2023-08-10 21:32:03,545:INFO:Declaring custom model
2023-08-10 21:32:03,564:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:32:03,593:INFO:Starting cross validation
2023-08-10 21:32:03,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:33:02,267:INFO:Calculating mean and std
2023-08-10 21:33:02,273:INFO:Creating metrics dataframe
2023-08-10 21:33:09,874:INFO:Uploading results into container
2023-08-10 21:33:09,877:INFO:Uploading model into container now
2023-08-10 21:33:09,879:INFO:_master_model_container: 21
2023-08-10 21:33:09,881:INFO:_display_container: 14
2023-08-10 21:33:09,888:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:33:09,888:INFO:create_model() successfully completed......................................
2023-08-10 21:33:10,265:INFO:SubProcess create_model() end ==================================
2023-08-10 21:33:10,265:INFO:Creating metrics dataframe
2023-08-10 21:33:10,309:INFO:Initializing custom model Bagging Classifier
2023-08-10 21:33:10,310:INFO:Total runtime is 2.340890220801035 minutes
2023-08-10 21:33:10,322:INFO:SubProcess create_model() called ==================================
2023-08-10 21:33:10,353:INFO:Initializing create_model()
2023-08-10 21:33:10,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C256CCAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:33:10,355:INFO:Checking exceptions
2023-08-10 21:33:10,355:INFO:Importing libraries
2023-08-10 21:33:10,355:INFO:Copying training dataset
2023-08-10 21:33:10,380:INFO:Defining folds
2023-08-10 21:33:10,381:INFO:Declaring metric variables
2023-08-10 21:33:10,402:INFO:Importing untrained model
2023-08-10 21:33:10,403:INFO:Declaring custom model
2023-08-10 21:33:10,433:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:33:10,460:INFO:Starting cross validation
2023-08-10 21:33:10,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:34:15,692:INFO:Calculating mean and std
2023-08-10 21:34:15,696:INFO:Creating metrics dataframe
2023-08-10 21:34:22,693:INFO:Uploading results into container
2023-08-10 21:34:22,695:INFO:Uploading model into container now
2023-08-10 21:34:22,696:INFO:_master_model_container: 22
2023-08-10 21:34:22,699:INFO:_display_container: 14
2023-08-10 21:34:22,734:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:34:22,735:INFO:create_model() successfully completed......................................
2023-08-10 21:34:23,096:INFO:SubProcess create_model() end ==================================
2023-08-10 21:34:23,099:INFO:Creating metrics dataframe
2023-08-10 21:34:23,136:INFO:Initializing custom model Logistic Regression
2023-08-10 21:34:23,137:INFO:Total runtime is 3.5546754995981846 minutes
2023-08-10 21:34:23,152:INFO:SubProcess create_model() called ==================================
2023-08-10 21:34:23,153:INFO:Initializing create_model()
2023-08-10 21:34:23,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C256CCAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:34:23,154:INFO:Checking exceptions
2023-08-10 21:34:23,154:INFO:Importing libraries
2023-08-10 21:34:23,155:INFO:Copying training dataset
2023-08-10 21:34:23,176:INFO:Defining folds
2023-08-10 21:34:23,177:INFO:Declaring metric variables
2023-08-10 21:34:23,191:INFO:Importing untrained model
2023-08-10 21:34:23,191:INFO:Declaring custom model
2023-08-10 21:34:23,213:INFO:Logistic Regression Imported successfully
2023-08-10 21:34:23,250:INFO:Starting cross validation
2023-08-10 21:34:23,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:35:25,716:INFO:Calculating mean and std
2023-08-10 21:35:25,719:INFO:Creating metrics dataframe
2023-08-10 21:35:33,523:INFO:Uploading results into container
2023-08-10 21:35:33,525:INFO:Uploading model into container now
2023-08-10 21:35:33,528:INFO:_master_model_container: 23
2023-08-10 21:35:33,530:INFO:_display_container: 14
2023-08-10 21:35:33,531:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 21:35:33,532:INFO:create_model() successfully completed......................................
2023-08-10 21:35:33,903:INFO:SubProcess create_model() end ==================================
2023-08-10 21:35:33,904:INFO:Creating metrics dataframe
2023-08-10 21:35:33,989:INFO:Initializing create_model()
2023-08-10 21:35:33,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:35:33,990:INFO:Checking exceptions
2023-08-10 21:35:33,995:INFO:Importing libraries
2023-08-10 21:35:33,996:INFO:Copying training dataset
2023-08-10 21:35:34,014:INFO:Defining folds
2023-08-10 21:35:34,014:INFO:Declaring metric variables
2023-08-10 21:35:34,014:INFO:Importing untrained model
2023-08-10 21:35:34,015:INFO:Declaring custom model
2023-08-10 21:35:34,016:INFO:Logistic Regression Imported successfully
2023-08-10 21:35:34,051:INFO:Cross validation set to False
2023-08-10 21:35:34,051:INFO:Fitting Model
2023-08-10 21:35:39,242:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 21:35:39,242:INFO:create_model() successfully completed......................................
2023-08-10 21:35:39,621:INFO:Creating Dashboard logs
2023-08-10 21:35:39,650:INFO:Model: Logistic Regression
2023-08-10 21:35:41,965:INFO:Logged params: {'C': 9.594, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1296, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 21:35:52,579:INFO:Initializing predict_model()
2023-08-10 21:35:52,579:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C29F80B80>)
2023-08-10 21:35:52,580:INFO:Checking exceptions
2023-08-10 21:35:52,580:INFO:Preloading libraries
2023-08-10 21:35:54,003:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:35:54,004:INFO:Initializing plot_model()
2023-08-10 21:35:54,005:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp4jqeerr7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:35:54,005:INFO:Checking exceptions
2023-08-10 21:35:54,014:INFO:Preloading libraries
2023-08-10 21:35:54,014:INFO:Copying training dataset
2023-08-10 21:35:54,015:INFO:Plot type: auc
2023-08-10 21:35:54,735:INFO:Fitting Model
2023-08-10 21:35:54,737:INFO:Scoring test/hold-out set
2023-08-10 21:35:54,810:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp4jqeerr7\AUC.png'
2023-08-10 21:35:55,635:INFO:Visual Rendered Successfully
2023-08-10 21:35:55,991:INFO:plot_model() successfully completed......................................
2023-08-10 21:36:00,129:INFO:Initializing plot_model()
2023-08-10 21:36:00,129:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp4jqeerr7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:36:00,129:INFO:Checking exceptions
2023-08-10 21:36:00,135:INFO:Preloading libraries
2023-08-10 21:36:00,136:INFO:Copying training dataset
2023-08-10 21:36:00,136:INFO:Plot type: confusion_matrix
2023-08-10 21:36:00,950:INFO:Fitting Model
2023-08-10 21:36:00,951:INFO:Scoring test/hold-out set
2023-08-10 21:36:01,022:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp4jqeerr7\Confusion Matrix.png'
2023-08-10 21:36:01,457:INFO:Visual Rendered Successfully
2023-08-10 21:36:01,819:INFO:plot_model() successfully completed......................................
2023-08-10 21:36:02,432:INFO:Initializing plot_model()
2023-08-10 21:36:02,433:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmp4jqeerr7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:36:02,433:INFO:Checking exceptions
2023-08-10 21:36:02,438:INFO:Preloading libraries
2023-08-10 21:36:02,439:INFO:Copying training dataset
2023-08-10 21:36:02,439:INFO:Plot type: feature
2023-08-10 21:36:02,935:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmp4jqeerr7\Feature Importance.png'
2023-08-10 21:36:03,655:INFO:Visual Rendered Successfully
2023-08-10 21:36:04,019:INFO:plot_model() successfully completed......................................
2023-08-10 21:36:05,079:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:36:17,125:INFO:Creating Dashboard logs
2023-08-10 21:36:17,136:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 21:36:18,896:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 21:36:18,896:INFO:Logged params: {}
2023-08-10 21:36:38,728:INFO:Creating Dashboard logs
2023-08-10 21:36:38,739:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 21:36:40,605:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 21:36:40,606:INFO:Logged params: {}
2023-08-10 21:37:06,329:INFO:Creating Dashboard logs
2023-08-10 21:37:06,342:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 21:37:08,321:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 21:37:08,322:INFO:Logged params: {}
2023-08-10 21:37:29,131:INFO:_master_model_container: 23
2023-08-10 21:37:29,131:INFO:_display_container: 14
2023-08-10 21:37:29,133:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 21:37:29,134:INFO:compare_models() successfully completed......................................
2023-08-10 21:37:58,640:INFO:Initializing compare_models()
2023-08-10 21:37:58,641:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, include=[CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, cross_validation=True, sort=f2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, 'include': [CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-10 21:37:58,642:INFO:Checking exceptions
2023-08-10 21:37:58,648:INFO:Preparing display monitor
2023-08-10 21:37:58,745:INFO:Initializing custom model Bagging Classifier
2023-08-10 21:37:58,745:INFO:Total runtime is 1.658201217651367e-05 minutes
2023-08-10 21:37:58,759:INFO:SubProcess create_model() called ==================================
2023-08-10 21:37:58,775:INFO:Initializing create_model()
2023-08-10 21:37:58,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C2587BD30>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:37:58,776:INFO:Checking exceptions
2023-08-10 21:37:58,776:INFO:Importing libraries
2023-08-10 21:37:58,776:INFO:Copying training dataset
2023-08-10 21:37:58,800:INFO:Defining folds
2023-08-10 21:37:58,800:INFO:Declaring metric variables
2023-08-10 21:37:58,820:INFO:Importing untrained model
2023-08-10 21:37:58,821:INFO:Declaring custom model
2023-08-10 21:37:58,840:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:37:58,873:INFO:Starting cross validation
2023-08-10 21:37:58,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:39:31,377:INFO:Calculating mean and std
2023-08-10 21:39:31,380:INFO:Creating metrics dataframe
2023-08-10 21:39:38,704:INFO:Uploading results into container
2023-08-10 21:39:38,706:INFO:Uploading model into container now
2023-08-10 21:39:38,708:INFO:_master_model_container: 24
2023-08-10 21:39:38,708:INFO:_display_container: 15
2023-08-10 21:39:38,720:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                                                   class_weight=None,
                                                                                                   criterion='gini',
                                                                                                   max_depth=None,
                                                                                                   max_features=None,
                                                                                                   max_leaf_nodes=None,
                                                                                                   min_impurity_...
                                                                      class_weight=None,
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features=None,
                                                                      max_leaf_nodes=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      random_state=1296,
                                                                      splitter='best'),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=150, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:39:38,721:INFO:create_model() successfully completed......................................
2023-08-10 21:39:39,099:INFO:SubProcess create_model() end ==================================
2023-08-10 21:39:39,100:INFO:Creating metrics dataframe
2023-08-10 21:39:39,138:INFO:Initializing custom model Bagging Classifier
2023-08-10 21:39:39,138:INFO:Total runtime is 1.6732331752777099 minutes
2023-08-10 21:39:39,155:INFO:SubProcess create_model() called ==================================
2023-08-10 21:39:39,162:INFO:Initializing create_model()
2023-08-10 21:39:39,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C2587BD30>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:39:39,162:INFO:Checking exceptions
2023-08-10 21:39:39,163:INFO:Importing libraries
2023-08-10 21:39:39,163:INFO:Copying training dataset
2023-08-10 21:39:39,191:INFO:Defining folds
2023-08-10 21:39:39,192:INFO:Declaring metric variables
2023-08-10 21:39:39,207:INFO:Importing untrained model
2023-08-10 21:39:39,208:INFO:Declaring custom model
2023-08-10 21:39:39,227:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:39:39,279:INFO:Starting cross validation
2023-08-10 21:39:39,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:40:40,093:INFO:Calculating mean and std
2023-08-10 21:40:40,100:INFO:Creating metrics dataframe
2023-08-10 21:40:47,632:INFO:Uploading results into container
2023-08-10 21:40:47,635:INFO:Uploading model into container now
2023-08-10 21:40:47,638:INFO:_master_model_container: 25
2023-08-10 21:40:47,638:INFO:_display_container: 15
2023-08-10 21:40:47,643:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=GaussianNB(priors=None,
                                                                                       var_smoothing=1e-09),
                                                                  max_features=1.0,
                                                                  max_samples=1.0,
                                                                  n_estimators=10,
                                                                  n_jobs=None,
                                                                  oob_score=False,
                                                                  random_state=1296,
                                                                  verbose=0,
                                                                  warm_start=False),
                                     estimator=GaussianNB(priors=None,
                                                          var_smoothing=1e-09),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:40:47,644:INFO:create_model() successfully completed......................................
2023-08-10 21:40:47,992:INFO:SubProcess create_model() end ==================================
2023-08-10 21:40:47,992:INFO:Creating metrics dataframe
2023-08-10 21:40:48,030:INFO:Initializing custom model Bagging Classifier
2023-08-10 21:40:48,030:INFO:Total runtime is 2.8214387059211727 minutes
2023-08-10 21:40:48,043:INFO:SubProcess create_model() called ==================================
2023-08-10 21:40:48,070:INFO:Initializing create_model()
2023-08-10 21:40:48,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C2587BD30>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:40:48,071:INFO:Checking exceptions
2023-08-10 21:40:48,071:INFO:Importing libraries
2023-08-10 21:40:48,071:INFO:Copying training dataset
2023-08-10 21:40:48,089:INFO:Defining folds
2023-08-10 21:40:48,090:INFO:Declaring metric variables
2023-08-10 21:40:48,107:INFO:Importing untrained model
2023-08-10 21:40:48,107:INFO:Declaring custom model
2023-08-10 21:40:48,138:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-10 21:40:48,191:INFO:Starting cross validation
2023-08-10 21:40:48,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:41:49,368:INFO:Calculating mean and std
2023-08-10 21:41:49,372:INFO:Creating metrics dataframe
2023-08-10 21:41:57,227:INFO:Uploading results into container
2023-08-10 21:41:57,230:INFO:Uploading model into container now
2023-08-10 21:41:57,232:INFO:_master_model_container: 26
2023-08-10 21:41:57,232:INFO:_display_container: 15
2023-08-10 21:41:57,267:INFO:CustomProbabilityThresholdClassifier(base_estimator='deprecated',
                                     bootstrap=True, bootstrap_features=False,
                                     classifier=BaggingClassifier(base_estimator='deprecated',
                                                                  bootstrap=True,
                                                                  bootstrap_features=False,
                                                                  estimator=XGBClassifier(base_score=None,
                                                                                          booster='gbtree',
                                                                                          callbacks=None,
                                                                                          colsample_bylevel=None,
                                                                                          colsample_bynode=None,
                                                                                          colsample_bytree=None,
                                                                                          early_sto...
                                                             max_delta_step=None,
                                                             max_depth=None,
                                                             max_leaves=None,
                                                             min_child_weight=None,
                                                             missing=nan,
                                                             monotone_constraints=None,
                                                             n_estimators=100,
                                                             n_jobs=-1,
                                                             num_parallel_tree=None,
                                                             objective='binary:logistic',
                                                             predictor=None, ...),
                                     max_features=1.0, max_samples=1.0,
                                     n_estimators=10, n_jobs=None,
                                     oob_score=False, probability_threshold=0.4,
                                     random_state=1296, verbose=0,
                                     warm_start=False)
2023-08-10 21:41:57,268:INFO:create_model() successfully completed......................................
2023-08-10 21:41:57,620:INFO:SubProcess create_model() end ==================================
2023-08-10 21:41:57,621:INFO:Creating metrics dataframe
2023-08-10 21:41:57,659:INFO:Initializing custom model Logistic Regression
2023-08-10 21:41:57,660:INFO:Total runtime is 3.9819367170333857 minutes
2023-08-10 21:41:57,671:INFO:SubProcess create_model() called ==================================
2023-08-10 21:41:57,673:INFO:Initializing create_model()
2023-08-10 21:41:57,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017C2587BD30>, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:41:57,676:INFO:Checking exceptions
2023-08-10 21:41:57,677:INFO:Importing libraries
2023-08-10 21:41:57,677:INFO:Copying training dataset
2023-08-10 21:41:57,694:INFO:Defining folds
2023-08-10 21:41:57,695:INFO:Declaring metric variables
2023-08-10 21:41:57,718:INFO:Importing untrained model
2023-08-10 21:41:57,718:INFO:Declaring custom model
2023-08-10 21:41:57,739:INFO:Logistic Regression Imported successfully
2023-08-10 21:41:57,782:INFO:Starting cross validation
2023-08-10 21:41:57,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-10 21:43:00,059:INFO:Calculating mean and std
2023-08-10 21:43:00,062:INFO:Creating metrics dataframe
2023-08-10 21:43:07,663:INFO:Uploading results into container
2023-08-10 21:43:07,665:INFO:Uploading model into container now
2023-08-10 21:43:07,667:INFO:_master_model_container: 27
2023-08-10 21:43:07,667:INFO:_display_container: 15
2023-08-10 21:43:07,668:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 21:43:07,669:INFO:create_model() successfully completed......................................
2023-08-10 21:43:08,019:INFO:SubProcess create_model() end ==================================
2023-08-10 21:43:08,019:INFO:Creating metrics dataframe
2023-08-10 21:43:08,109:INFO:Initializing create_model()
2023-08-10 21:43:08,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-10 21:43:08,110:INFO:Checking exceptions
2023-08-10 21:43:08,118:INFO:Importing libraries
2023-08-10 21:43:08,118:INFO:Copying training dataset
2023-08-10 21:43:08,140:INFO:Defining folds
2023-08-10 21:43:08,141:INFO:Declaring metric variables
2023-08-10 21:43:08,141:INFO:Importing untrained model
2023-08-10 21:43:08,141:INFO:Declaring custom model
2023-08-10 21:43:08,143:INFO:Logistic Regression Imported successfully
2023-08-10 21:43:08,200:INFO:Cross validation set to False
2023-08-10 21:43:08,202:INFO:Fitting Model
2023-08-10 21:43:13,485:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 21:43:13,486:INFO:create_model() successfully completed......................................
2023-08-10 21:43:13,839:INFO:Creating Dashboard logs
2023-08-10 21:43:13,878:INFO:Model: Logistic Regression
2023-08-10 21:43:15,409:INFO:Logged params: {'C': 9.594, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1296, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 21:43:25,299:INFO:Initializing predict_model()
2023-08-10 21:43:25,299:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C29F801F0>)
2023-08-10 21:43:25,299:INFO:Checking exceptions
2023-08-10 21:43:25,299:INFO:Preloading libraries
2023-08-10 21:43:34,048:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:43:34,049:INFO:Initializing plot_model()
2023-08-10 21:43:34,050:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpa5a4yi1z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:43:34,050:INFO:Checking exceptions
2023-08-10 21:43:34,057:INFO:Preloading libraries
2023-08-10 21:43:34,058:INFO:Copying training dataset
2023-08-10 21:43:34,058:INFO:Plot type: auc
2023-08-10 21:43:34,855:INFO:Fitting Model
2023-08-10 21:43:34,857:INFO:Scoring test/hold-out set
2023-08-10 21:43:34,949:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpa5a4yi1z\AUC.png'
2023-08-10 21:43:35,793:INFO:Visual Rendered Successfully
2023-08-10 21:43:36,140:INFO:plot_model() successfully completed......................................
2023-08-10 21:43:36,857:INFO:Initializing plot_model()
2023-08-10 21:43:36,857:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpa5a4yi1z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:43:36,857:INFO:Checking exceptions
2023-08-10 21:43:36,864:INFO:Preloading libraries
2023-08-10 21:43:36,864:INFO:Copying training dataset
2023-08-10 21:43:36,864:INFO:Plot type: confusion_matrix
2023-08-10 21:43:38,006:INFO:Fitting Model
2023-08-10 21:43:38,007:INFO:Scoring test/hold-out set
2023-08-10 21:43:38,146:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpa5a4yi1z\Confusion Matrix.png'
2023-08-10 21:43:38,780:INFO:Visual Rendered Successfully
2023-08-10 21:43:39,292:INFO:plot_model() successfully completed......................................
2023-08-10 21:43:40,006:INFO:Initializing plot_model()
2023-08-10 21:43:40,007:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpa5a4yi1z, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:43:40,007:INFO:Checking exceptions
2023-08-10 21:43:40,012:INFO:Preloading libraries
2023-08-10 21:43:40,013:INFO:Copying training dataset
2023-08-10 21:43:40,013:INFO:Plot type: feature
2023-08-10 21:43:41,031:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpa5a4yi1z\Feature Importance.png'
2023-08-10 21:43:42,464:INFO:Visual Rendered Successfully
2023-08-10 21:43:43,067:INFO:plot_model() successfully completed......................................
2023-08-10 21:43:43,800:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:43:59,609:INFO:Creating Dashboard logs
2023-08-10 21:43:59,624:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 21:44:00,879:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 21:44:00,880:INFO:Logged params: {}
2023-08-10 21:44:24,683:INFO:Creating Dashboard logs
2023-08-10 21:44:24,694:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 21:44:25,975:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 21:44:25,975:INFO:Logged params: {}
2023-08-10 21:44:46,853:INFO:Creating Dashboard logs
2023-08-10 21:44:46,863:INFO:Model: CustomProbabilityThresholdClassifier
2023-08-10 21:44:47,706:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
AttributeError: 'NoneType' object has no attribute 'get_all_params'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\HP\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 80, in log_model
    params = params.get_params()
AttributeError: 'NoneType' object has no attribute 'get_params'

2023-08-10 21:44:47,706:INFO:Logged params: {}
2023-08-10 21:45:07,492:INFO:_master_model_container: 27
2023-08-10 21:45:07,493:INFO:_display_container: 15
2023-08-10 21:45:07,497:INFO:LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 21:45:07,498:INFO:compare_models() successfully completed......................................
2023-08-10 21:45:45,093:INFO:Initializing plot_model()
2023-08-10 21:45:45,093:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=True)
2023-08-10 21:45:45,095:INFO:Checking exceptions
2023-08-10 21:45:45,111:INFO:Preloading libraries
2023-08-10 21:45:45,113:INFO:Copying training dataset
2023-08-10 21:45:45,113:INFO:Plot type: class_report
2023-08-10 21:45:46,043:INFO:Fitting Model
2023-08-10 21:45:46,045:INFO:Scoring test/hold-out set
2023-08-10 21:45:47,175:INFO:Visual Rendered Successfully
2023-08-10 21:45:47,558:INFO:plot_model() successfully completed......................................
2023-08-10 21:46:17,175:INFO:Initializing predict_model()
2023-08-10 21:46:17,175:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C25392940>)
2023-08-10 21:46:17,175:INFO:Checking exceptions
2023-08-10 21:46:17,176:INFO:Preloading libraries
2023-08-10 21:46:57,494:INFO:Initializing finalize_model()
2023-08-10 21:46:57,495:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-10 21:46:57,497:INFO:Finalizing LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-10 21:46:57,511:INFO:Initializing create_model()
2023-08-10 21:46:57,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=LogisticRegression(C=9.594, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1296, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-10 21:46:57,512:INFO:Checking exceptions
2023-08-10 21:46:57,517:INFO:Importing libraries
2023-08-10 21:46:57,518:INFO:Copying training dataset
2023-08-10 21:46:57,518:INFO:Defining folds
2023-08-10 21:46:57,519:INFO:Declaring metric variables
2023-08-10 21:46:57,519:INFO:Importing untrained model
2023-08-10 21:46:57,519:INFO:Declaring custom model
2023-08-10 21:46:57,521:INFO:Logistic Regression Imported successfully
2023-08-10 21:46:57,567:INFO:Cross validation set to False
2023-08-10 21:46:57,568:INFO:Fitting Model
2023-08-10 21:47:01,488:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False)
2023-08-10 21:47:01,488:INFO:create_model() successfully completed......................................
2023-08-10 21:47:01,901:INFO:Creating Dashboard logs
2023-08-10 21:47:01,903:INFO:Model: Logistic Regression
2023-08-10 21:47:03,527:INFO:Logged params: {'C': 9.594, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1296, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-08-10 21:47:10,572:INFO:SubProcess plot_model() called ==================================
2023-08-10 21:47:10,594:INFO:Initializing plot_model()
2023-08-10 21:47:10,595:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpr0cxmdka, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:47:10,595:INFO:Checking exceptions
2023-08-10 21:47:10,600:INFO:Preloading libraries
2023-08-10 21:47:10,600:INFO:Copying training dataset
2023-08-10 21:47:10,600:INFO:Plot type: auc
2023-08-10 21:47:11,404:INFO:Fitting Model
2023-08-10 21:47:11,406:INFO:Scoring test/hold-out set
2023-08-10 21:47:11,482:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpr0cxmdka\AUC.png'
2023-08-10 21:47:12,420:INFO:Visual Rendered Successfully
2023-08-10 21:47:12,783:INFO:plot_model() successfully completed......................................
2023-08-10 21:47:14,415:INFO:Initializing plot_model()
2023-08-10 21:47:14,415:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpr0cxmdka, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:47:14,415:INFO:Checking exceptions
2023-08-10 21:47:14,420:INFO:Preloading libraries
2023-08-10 21:47:14,421:INFO:Copying training dataset
2023-08-10 21:47:14,421:INFO:Plot type: confusion_matrix
2023-08-10 21:47:15,234:INFO:Fitting Model
2023-08-10 21:47:15,235:INFO:Scoring test/hold-out set
2023-08-10 21:47:15,310:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpr0cxmdka\Confusion Matrix.png'
2023-08-10 21:47:15,748:INFO:Visual Rendered Successfully
2023-08-10 21:47:16,110:INFO:plot_model() successfully completed......................................
2023-08-10 21:47:20,998:INFO:Initializing plot_model()
2023-08-10 21:47:20,998:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=C:\Users\HP\AppData\Local\Temp\tmpr0cxmdka, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=False)
2023-08-10 21:47:20,998:INFO:Checking exceptions
2023-08-10 21:47:21,003:INFO:Preloading libraries
2023-08-10 21:47:21,003:INFO:Copying training dataset
2023-08-10 21:47:21,004:INFO:Plot type: feature
2023-08-10 21:47:21,519:INFO:Saving 'C:\Users\HP\AppData\Local\Temp\tmpr0cxmdka\Feature Importance.png'
2023-08-10 21:47:22,400:INFO:Visual Rendered Successfully
2023-08-10 21:47:22,760:INFO:plot_model() successfully completed......................................
2023-08-10 21:47:23,457:INFO:SubProcess plot_model() end ==================================
2023-08-10 21:47:38,147:INFO:_master_model_container: 27
2023-08-10 21:47:38,147:INFO:_display_container: 16
2023-08-10 21:47:38,168:INFO:Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False)
2023-08-10 21:47:38,168:INFO:finalize_model() successfully completed......................................
2023-08-10 21:47:51,185:INFO:Initializing predict_model()
2023-08-10 21:47:51,185:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017C288154C0>)
2023-08-10 21:47:51,186:INFO:Checking exceptions
2023-08-10 21:47:51,186:INFO:Preloading libraries
2023-08-10 21:47:51,196:INFO:Set up data.
2023-08-10 21:47:51,226:INFO:Set up index.
2023-08-10 21:50:28,455:INFO:Initializing plot_model()
2023-08-10 21:50:28,455:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\HP\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tenure', 'WarehouseToHome',
                                             'NumberOfDeviceRegistered',
                                             'SatisfactionScore',
                                             'NumberOfAddress', 'Complain',
                                             'DaySinceLastOrder',
                                             'CashbackAmount'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_valu...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1296,
                                                               threshold=0.05))),
                ('actual_estimator',
                 LogisticRegression(C=9.594, class_weight='balanced',
                                    dual=False, fit_intercept=True,
                                    intercept_scaling=1, l1_ratio=None,
                                    max_iter=1000, multi_class='auto',
                                    n_jobs=None, penalty='l2',
                                    random_state=1296, solver='lbfgs',
                                    tol=0.0001, verbose=0, warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017C25795130>, system=True)
2023-08-10 21:50:28,455:INFO:Checking exceptions
2023-08-10 21:50:28,470:INFO:Preloading libraries
2023-08-10 21:50:28,471:INFO:Copying training dataset
2023-08-10 21:50:28,471:INFO:Plot type: feature
2023-08-10 21:50:30,120:INFO:Visual Rendered Successfully
2023-08-10 21:50:30,860:INFO:plot_model() successfully completed......................................
